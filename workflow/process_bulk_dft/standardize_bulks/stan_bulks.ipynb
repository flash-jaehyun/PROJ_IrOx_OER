{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing unit cells of bulk polymorphs\n",
    "---\n",
    "Hopefully cells will be smaller and more symmetric"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "from catkit.gen.symmetry import get_standardized_cell\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_dft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tol = 5e-01\n",
    "# tol = 1e-01\n",
    "tol = 1e-03\n",
    "# tol = 1e-05\n",
    "# tol = 1e-07\n",
    "# tol = 1e-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = get_df_dft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "for bulk_id_i, row_i in df_dft.iterrows():\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    # #####################################################\n",
    "    atoms = row_i.atoms\n",
    "    # #####################################################\n",
    "\n",
    "    num_atoms = atoms.get_global_number_of_atoms()\n",
    "\n",
    "    atoms_stan_prim = get_standardized_cell(atoms, primitive=True, tol=tol)\n",
    "    atoms_stan = get_standardized_cell(atoms, primitive=False, tol=tol)\n",
    "\n",
    "    num_atoms_stan_prim = atoms_stan_prim.get_global_number_of_atoms()\n",
    "    num_atoms_stan = atoms_stan.get_global_number_of_atoms()\n",
    "\n",
    "    num_atoms_lost_0 = num_atoms - num_atoms_stan\n",
    "    num_atoms_lost_1 = num_atoms - num_atoms_stan_prim\n",
    "    # num_atoms - num_atoms_stan_prim\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"id_unique\"] = bulk_id_i\n",
    "    data_dict_i[\"atoms_stan_prim\"] = atoms_stan_prim\n",
    "    data_dict_i[\"atoms_stan\"] = atoms_stan\n",
    "    data_dict_i[\"num_atoms\"] = num_atoms\n",
    "    data_dict_i[\"num_atoms_stan_prim\"] = num_atoms_stan_prim\n",
    "    data_dict_i[\"num_atoms_stan\"] = num_atoms_stan\n",
    "    data_dict_i[\"num_atoms_red__stan\"] = num_atoms_lost_0\n",
    "    data_dict_i[\"num_atoms_red__stan_prim\"] = num_atoms_lost_1\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "# #########################################################\n",
    "df = pd.DataFrame(data_dict_list)\n",
    "df = df.set_index(\"id_unique\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Num atoms total: \",\n",
    "    df.num_atoms.sum(),\n",
    "    \"\\n\",\n",
    "    \"Num atoms reduced: \",\n",
    "    df.num_atoms_red__stan_prim.sum(),\n",
    "    sep=\"\")\n",
    "\n",
    "# df.sort_values(\"num_atoms\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "x = [5e-1, 1e-1, 1e-3, 1e-5, 1e-7, 1e-9, ]\n",
    "y = [4383, 4155, 3141, 1246, 1080, 1080, ]\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x, y=y)\n",
    "fig = go.Figure(data=[trace])\n",
    "fig.update_xaxes(type=\"log\")\n",
    "print(\"Number of atoms purged as a function of tolerance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft_stan = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "dir_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/process_bulk_dft/standardize_bulks\",\n",
    "    \"out_data\")\n",
    "file_name_i = os.path.join(\n",
    "    dir_i, \"df_dft_stan.pickle\")\n",
    "if not os.path.exists(dir_i): os.makedirs(dir_i)\n",
    "with open(os.path.join(dir_i, \"df_dft_stan.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_dft_stan, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "dir_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/process_bulk_dft/standardize_bulks\",\n",
    "    \"out_data\")\n",
    "file_name_i = os.path.join(\n",
    "    dir_i, \"df_dft_stan.pickle\")\n",
    "with open(file_name_i, \"rb\") as fle:\n",
    "    df_dft_stan = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# num_atoms_stan_prim\n",
    "# num_atoms_stan"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
