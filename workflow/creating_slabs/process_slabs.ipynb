{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further process slabs created in `create_slabs.ipynb`\n",
    "---\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "# from pathlib import Path\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# #########################################################\n",
    "from plotting.my_plotly import my_plotly_plot\n",
    "from misc_modules.pandas_methods import reorder_df_columns\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_structure_coord_df\n",
    "from methods import (\n",
    "    get_df_dft,\n",
    "    get_slab_thickness,\n",
    "    get_df_slab,\n",
    "    )\n",
    "\n",
    "from local_methods import (\n",
    "    constrain_slab,\n",
    "    resize_z_slab,\n",
    "    calc_surface_area,\n",
    "    repeat_xy,\n",
    "    )\n",
    "\n",
    "# from local_methods import\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read `df_slab` and `df_dft` dataframes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/\n",
    "\n",
    "# path_i = os.path.join(\n",
    "#     os.environ[\"PROJ_irox_oer\"],\n",
    "#     \"workflow/creating_slabs\",\n",
    "#     \"out_data/df_slab.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab = get_df_slab(mode=\"almost-final\")\n",
    "\n",
    "df_dft = get_df_dft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"status\" in df_slab.columns:\n",
    "    df_slab = df_slab[df_slab.status != \"Took too long\"]\n",
    "else:\n",
    "    print(\"eh\")\n",
    "    df_slab = df_slab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slab[df_slab.bulk_id == \"8l919k6s7p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create directories"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"out_data/final_slabs_1\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "directory = \"out_data/final_slabs_2\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "directory = \"out_data/bulk_structures_temp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main processing slabs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "data_dict_list = []\n",
    "iterator = tqdm(df_slab.index.tolist(), desc=\"1st loop\")\n",
    "for i_cnt, slab_id_i in enumerate(iterator):\n",
    "    row_i = df_slab.loc[slab_id_i]\n",
    "\n",
    "#     if i_cnt > 100:\n",
    "#         break\n",
    "\n",
    "    data_dict_i = dict()\n",
    "    t0 = time.time()\n",
    "\n",
    "    # #####################################################\n",
    "    slab_id = row_i.name\n",
    "    slab = row_i.slab_final\n",
    "    bulk_id_i = row_i.bulk_id\n",
    "    facet_i = row_i.facet\n",
    "    iter_time_i = row_i.iter_time_i\n",
    "    # #####################################################\n",
    "\n",
    "    # slab_constrained = constrain_slab(atoms=slab)\n",
    "    slab_final = resize_z_slab(atoms=slab, vacuum=15)\n",
    "    slab_final.center()\n",
    "    slab_final.wrap()\n",
    "\n",
    "\n",
    "    # Repeat slab if needed\n",
    "    min_len = 6\n",
    "    out_dict = repeat_xy(\n",
    "        atoms=slab_final,\n",
    "        min_len_x=min_len,\n",
    "        min_len_y=min_len)\n",
    "    atoms_repeated = out_dict[\"atoms_repeated\"]\n",
    "    is_repeated = out_dict[\"is_repeated\"]\n",
    "    repeat_list = out_dict[\"repeat_list\"]\n",
    "\n",
    "\n",
    "    num_atoms_i = atoms_repeated.get_global_number_of_atoms()\n",
    "\n",
    "\n",
    "    surf_a_i = calc_surface_area(atoms=atoms_repeated)\n",
    "\n",
    "    slab_final = atoms_repeated  # <-------------------------------------------\n",
    "\n",
    "    cell_mag_x = np.linalg.norm(slab_final.cell.array[0])\n",
    "    cell_mag_y = np.linalg.norm(slab_final.cell.array[1])\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"slab_id\"] = slab_id\n",
    "    data_dict_i[\"bulk_id\"] = bulk_id_i\n",
    "    data_dict_i[\"facet\"] = facet_i\n",
    "    # #################################\n",
    "    data_dict_i[\"slab_final\"] = slab_final\n",
    "    # #################################\n",
    "    data_dict_i[\"num_atoms\"] = num_atoms_i\n",
    "    data_dict_i[\"num_atoms\"] = num_atoms_i\n",
    "    data_dict_i[\"surf_area\"] = surf_a_i\n",
    "    data_dict_i[\"cell_mag_x\"] = cell_mag_x\n",
    "    data_dict_i[\"cell_mag_y\"] = cell_mag_y\n",
    "    # #################################\n",
    "    data_dict_i[\"is_repeated\"] = is_repeated\n",
    "    data_dict_i[\"repeat_list\"] = repeat_list\n",
    "    # #################################\n",
    "    data_dict_i[\"loop_time\"] = time.time() - t0\n",
    "    data_dict_i[\"iter_time_i\"] = iter_time_i\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "    file_name = row_i.bulk_id + \"__\" + row_i.name + \"__\" + row_i.facet + \".cif\"\n",
    "    slab_final.write(\"out_data/final_slabs_1/\" + file_name)\n",
    "\n",
    "    file_name = row_i.bulk_id + \"__\" + row_i.name + \"__\" + row_i.facet + \".traj\"\n",
    "    slab_final.write(\"out_data/final_slabs_1/\" + file_name)\n",
    "\n",
    "# #########################################################\n",
    "df_slab_2 = pd.DataFrame(data_dict_list)\n",
    "# df_slab_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further analysis of slabs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for slab_id_i, row_i in df_slab_2.iterrows():\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "\n",
    "    # #####################################################\n",
    "    slab_final = row_i.slab_final\n",
    "    # #####################################################\n",
    "\n",
    "    slab_thick_i = get_slab_thickness(atoms=slab_final)\n",
    "\n",
    "    data_dict_i[\"slab_thick\"] = slab_thick_i\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "# #########################################################\n",
    "df_slab_info = pd.DataFrame(data_dict_list)\n",
    "df_slab_info = df_slab_info.set_index(\"slab_id\")\n",
    "\n",
    "df_slab_3 = pd.concat([\n",
    "    df_slab_2,\n",
    "    df_slab_info,\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up dataframe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_order = [\n",
    "    \"slab_id\",\n",
    "    \"bulk_id\",\n",
    "    \"facet\",\n",
    "    \"slab_thick\",\n",
    "    \"num_atoms\",\n",
    "    \"slab_final\",\n",
    "    \"loop_time\",\n",
    "    \"iter_time_i\",\n",
    "    ]\n",
    "df_slab_3 = reorder_df_columns(cols_order, df_slab_3)\n",
    "\n",
    "df_slab_final = df_slab_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_slab_final.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_slab_final, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_final[df_slab_final.bulk_id == \"8l919k6s7p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting `df_coord` for final slab\n",
    "\n",
    "Needed because of cell xy repitiion"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slab_final.slab_id.isin([\"wopegiho_38\"]).any()\n",
    "\n",
    "# df_slab_final.slab_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_cnt, row_i in df_slab_final.iterrows():\n",
    "\n",
    "    # #####################################################\n",
    "    slab_final = row_i.slab_final\n",
    "    slab_id = row_i.slab_id\n",
    "    # #####################################################\n",
    "\n",
    "    print(40 * \"*\")\n",
    "    print(\"slab_id:\", slab_id)\n",
    "\n",
    "    file_name_i = slab_id + \"_after_rep\" + \".pickle\"\n",
    "    file_path_i = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"workflow/creating_slabs/out_data/df_coord_files\",\n",
    "        file_name_i)\n",
    "\n",
    "    my_file = Path(file_path_i)\n",
    "    if not my_file.is_file():\n",
    "        df_coord_slab_final = get_structure_coord_df(slab_final)\n",
    "        with open(file_path_i, \"wb\") as fle:\n",
    "            pickle.dump(df_coord_slab_final, fle)\n",
    "    else:\n",
    "        print(\"Already computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking that no slabs are less than 15 A in thickness"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slabs_too_thin = df_slab_3[df_slab_3.slab_thick < 15]\n",
    "\n",
    "print(\"Number of slabs that are too thin:\", \"\\n\", df_slabs_too_thin.shape[0])\n",
    "\n",
    "df_slabs_too_thin[[\"slab_id\", \"bulk_id\", \"facet\"]].to_csv(\"temp_slabs_too_thin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Processing Speed vs Structure Size"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_array = df_slab_2.iter_time_i / 60\n",
    "x_array = df_slab_2.num_atoms\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "    )\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Processing speed vs structure size (num atoms)\",\n",
    "    xaxis=dict(title=dict(text=\"Number of atoms\")),\n",
    "    yaxis=dict(title=dict(text=\"Processing time (min)\")),\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plotly_plot(\n",
    "    figure=fig,\n",
    "    plot_name=\"iter_speed_vs_num_atoms\",\n",
    "    write_html=True,\n",
    "    write_png=False,\n",
    "    png_scale=6.0,\n",
    "    write_pdf=False,\n",
    "    write_svg=False,\n",
    "    try_orca_write=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the structures that are unique octahedras"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################################################################\n",
    "data_path = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs/selecting_bulks\",\n",
    "    \"out_data/data.json\")\n",
    "with open(data_path, \"r\") as fle:\n",
    "    data = json.load(fle)\n",
    "# #######################################################################\n",
    "\n",
    "bulk_ids__octa_unique = data[\"bulk_ids__octa_unique\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_slab_2\n",
    "df_i = df[df.bulk_id.isin(bulk_ids__octa_unique)]\n",
    "\n",
    "file_names_list = []\n",
    "for i_cnt, row_i in df_i.iterrows():\n",
    "    slab = row_i.slab_final\n",
    "\n",
    "    file_name_base = row_i.bulk_id + \"__\" + row_i.slab_id + \"__\" + row_i.facet\n",
    "    file_names_list.append(file_name_base)\n",
    "\n",
    "    file_name = file_name_base + \".cif\"\n",
    "    slab.write(\"out_data/final_slabs_2/\" + file_name)\n",
    "\n",
    "    file_name = file_name_base + \".traj\"\n",
    "    slab.write(\"out_data/final_slabs_2/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_list_i = [i + \".traj\" for i in file_names_list]\n",
    "print(\"ase gui\", *file_names_list_i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
