{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute similarity of constructed *O IrOx slabs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/workflow/creating_slabs/slab_similarity\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "# from StructurePrototypeAnalysisPackage.ccf import struc2ccf\n",
    "# from StructurePrototypeAnalysisPackage.ccf import struc2ccf, cal_ccf_d\n",
    "from StructurePrototypeAnalysisPackage.ccf import cal_ccf_d\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_slab\n",
    "\n",
    "from methods import get_ccf\n",
    "from methods import get_D_ij\n",
    "from methods import get_identical_slabs\n",
    "\n",
    "# #########################################################\n",
    "# from local_methods import get_ccf\n",
    "# from local_methods import get_D_ij\n",
    "# from local_methods import get_identical_slabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "r_cut_off = 10\n",
    "r_vector = np.arange(1, 10, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab = get_df_slab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP | Filtering down `df_slab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slab = df_slab[df_slab.bulk_id ==  \"mjctxrx3zf\"]\n",
    "# df_slab = df_slab[df_slab.bulk_id ==  \"64cg6j9any\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab = df_slab.sort_values([\"bulk_id\", \"facet\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_ids = [\n",
    "    \"64cg6j9any\",\n",
    "    \"9573vicg7f\",\n",
    "    \"b19q9p6k72\",\n",
    "    # \"\",\n",
    "    ]\n",
    "# df_slab = df_slab[\n",
    "#     df_slab.bulk_id.isin(bulk_ids)\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping through slabs and computing CCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_slab.groupby([\"bulk_id\"])\n",
    "for bulk_id_i, group_i in grouped:\n",
    "    for slab_id_j, row_j in group_i.iterrows():\n",
    "        # #####################################################\n",
    "        slab_final_j = row_j.slab_final\n",
    "        # #####################################################\n",
    "\n",
    "        ccf_j = get_ccf(\n",
    "            slab_id=slab_id_j,\n",
    "            slab_final=slab_final_j,\n",
    "            r_cut_off=r_cut_off,\n",
    "            r_vector=r_vector,\n",
    "            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing D_ij matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_local = False\n",
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "grouped = df_slab.groupby([\"bulk_id\"])\n",
    "for bulk_id_i, group_i in grouped:\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "\n",
    "    if verbose_local:\n",
    "        print(\"slab_id:\", bulk_id_i)\n",
    "\n",
    "    D_ij = get_D_ij(group_i, slab_id=bulk_id_i)\n",
    "    ident_slab_pairs_i = get_identical_slabs(D_ij)\n",
    "\n",
    "    # print(\"ident_slab_pairs:\", ident_slab_pairs_i)\n",
    "\n",
    "    ids_to_remove = []\n",
    "    for ident_pair_i in ident_slab_pairs_i:\n",
    "        # Checking if any id already added to `id_to_remove` is in a new pair\n",
    "        for i in ids_to_remove:\n",
    "            if i in ident_pair_i:\n",
    "                print(\"This case needs to be dealt with more carefully\")\n",
    "                break\n",
    "\n",
    "        ident_pair_2 = np.sort(ident_pair_i)\n",
    "        ids_to_remove.append(ident_pair_2[0])\n",
    "\n",
    "    num_ids_to_remove = len(ids_to_remove)\n",
    "\n",
    "    if verbose_local:\n",
    "        print(\"ids_to_remove:\", ids_to_remove)\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"bulk_id\"] = bulk_id_i\n",
    "    data_dict_i[\"slab_ids_to_remove\"] = ids_to_remove\n",
    "    data_dict_i[\"num_ids_to_remove\"] = num_ids_to_remove\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_simil = pd.DataFrame(data_dict_list)\n",
    "\n",
    "df_slab_simil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs/slab_similarity\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_slab_simil.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_slab_simil, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_slab_simil\n",
    "df_slab_simil = get_df_slab_simil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_simil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ident_slab_pairs_i = [\n",
    "#     ['bimamuvo_42', 'hidopiha_44'],\n",
    "#     ['legifipe_18', 'witepote_55'],\n",
    "#     ]\n",
    "\n",
    "# ids_to_remove = []\n",
    "# for ident_pair_i in ident_slab_pairs_i:\n",
    "\n",
    "#     # Checking if any id already added to `id_to_remove` is in a new pair\n",
    "#     for i in ids_to_remove:\n",
    "#         if i in ident_pair_i:\n",
    "#             print(\"This case needs to be dealt with more carefully\")\n",
    "#             break\n",
    "\n",
    "#     ident_pair_2 = np.sort(ident_pair_i)\n",
    "#     ids_to_remove.append(ident_pair_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# identical_pairs_list = [\n",
    "#     [\"a\", \"b\"],\n",
    "#     [\"b\", \"a\"],\n",
    "\n",
    "#     [\"c\", \"d\"],\n",
    "#     ]\n",
    "\n",
    "# # identical_pairs_list_2 = \n",
    "# # list(np.unique(\n",
    "# #     [np.sort(i) for i in identical_pairs_list]\n",
    "# #     ))\n",
    "\n",
    "# np.unique(\n",
    "# [np.sort(i) for i in identical_pairs_list]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# lst = identical_pairs_list\n",
    "# lst.sort()\n",
    "# lst = [list(np.sort(i)) for i in lst]\n",
    "\n",
    "# identical_pairs_list_2 = list(lst for lst, _ in itertools.groupby(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def get_identical_slabs(\n",
    "#     D_ij,\n",
    "\n",
    "#     min_thresh=1e-5,\n",
    "#     ):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     #| - get_identical_slabs\n",
    "\n",
    "#     # #########################################################\n",
    "#     # min_thresh = 1e-5\n",
    "#     # #########################################################\n",
    "\n",
    "#     identical_pairs_list = []\n",
    "#     for slab_id_i in D_ij.index:\n",
    "#         for slab_id_j in D_ij.index:\n",
    "#             if slab_id_i == slab_id_j:\n",
    "#                 continue\n",
    "#             if slab_id_i == slab_id_j:\n",
    "#                 print(\"Not good if this is printed\")\n",
    "\n",
    "#             d_ij = D_ij.loc[slab_id_i, slab_id_j]\n",
    "#             if d_ij < min_thresh:\n",
    "#                 # print(slab_id_i, slab_id_j)\n",
    "#                 identical_pairs_list.append((slab_id_i, slab_id_j))\n",
    "\n",
    "#     # #########################################################\n",
    "#     identical_pairs_list_2 = list(np.unique(\n",
    "#         [np.sort(i) for i in identical_pairs_list]\n",
    "#         ))\n",
    "\n",
    "#     return(identical_pairs_list_2)\n",
    "#     #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # #########################################################\n",
    "# import pickle; import os\n",
    "# path_i = os.path.join(\n",
    "#     os.environ[\"PROJ_irox_oer\"],\n",
    "#     \"workflow/creating_slabs/slab_similarity\",\n",
    "#     \"out_data/df_slab_simil.pickle\")\n",
    "# with open(path_i, \"rb\") as fle:\n",
    "#     df_slab_simil = pickle.load(fle)\n",
    "# # #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# /home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/workflow/creating_slabs/slab_similarity\n",
    "\n",
    "# workflow/creating_slabs/slab_similarity"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
