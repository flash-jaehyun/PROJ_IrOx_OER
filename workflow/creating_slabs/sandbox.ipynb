{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ase import io\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# #########################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "from misc_modules.pandas_methods import drop_columns\n",
    "from misc_modules.misc_methods import GetFriendlyID\n",
    "from ase_modules.ase_methods import view_in_vesta\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_dft, symmetrize_atoms,\n",
    "    get_structure_coord_df, remove_atoms)\n",
    "from proj_data import metal_atom_symbol\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import (\n",
    "    analyse_local_coord_env, check_if_sys_processed,\n",
    "    remove_nonsaturated_surface_metal_atoms,\n",
    "    remove_noncoord_oxygens,\n",
    "    create_slab_from_bulk,\n",
    "    get_slab_thickness,\n",
    "    remove_highest_metal_atoms,\n",
    "    remove_all_atoms_above_cutoff,\n",
    "    create_final_slab_master,\n",
    "    constrain_slab,\n",
    "    )\n",
    "\n",
    "from local_methods import calc_surface_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_slab, get_slab_thickness\n",
    "\n",
    "df_slab = get_df_slab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for slab_id_i, row_i in df_slab.iterrows():\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "\n",
    "    # #####################################################\n",
    "    slab_final = row_i.slab_final\n",
    "    # #####################################################\n",
    "\n",
    "    slab_thick_i = get_slab_thickness(atoms=slab_final)\n",
    "    \n",
    "    data_dict_i[\"slab_thick\"] = slab_thick_i\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "# #########################################################\n",
    "df_slab_info = pd.DataFrame(data_dict_list)\n",
    "df_slab_info = df_slab_info.set_index(\"slab_id\")\n",
    "\n",
    "df_slab = pd.concat([\n",
    "    df_slab,\n",
    "    df_slab_info,\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# DFT dataframe\n",
    "df_dft = get_df_dft()\n",
    "\n",
    "# #########################################################\n",
    "# Previous df_slab dataframe\n",
    "path_i = os.path.join(\n",
    "    \"out_data\",\n",
    "    # \"__old__\",\n",
    "    \"df_slab.pickle\")\n",
    "my_file = Path(path_i)\n",
    "if my_file.is_file():\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_slab_old = pickle.load(fle)\n",
    "else:\n",
    "    df_slab_old = pd.DataFrame()\n",
    "\n",
    "print(\"df_slab_old.shape:\", df_slab_old.shape)\n",
    "\n",
    "# #########################################################\n",
    "# Bulks not to run, manually checked to be erroneous/bad\n",
    "data_path = os.path.join(\n",
    "    \"in_data/bulks_to_not_run.json\")\n",
    "with open(data_path, \"r\") as fle:\n",
    "    bulks_to_not_run = json.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_old = df_slab_old[~df_slab_old.slab_final.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # row_i = df_slab_old.iloc[0]\n",
    "    atoms = row_i.slab_final\n",
    "\n",
    "    num_atoms = atoms.get_number_of_atoms()\n",
    "    return(num_atoms)\n",
    "\n",
    "df_i = df_slab_old\n",
    "df_i[\"num_atoms\"] = df_i.apply(\n",
    "    method,\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "y_array = df_i.iter_time_i / 60\n",
    "x_array = df_i.num_atoms\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "    )\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slab_0 = io.read(\n",
    "    \"out_data/final_slabs_2/zimuby8uzj__fagepuha_94__001.cif\"\n",
    "    # \"out_data/temp_out/slab_1_2.cif\"\n",
    "    )\n",
    "\n",
    "slab_0.write(\"out_data/temp_out/slab_0.cif\")\n",
    "atoms = slab_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_coord_slab_i = get_structure_coord_df(atoms)\n",
    "\n",
    "# #########################################################\n",
    "df_i = df_coord_slab_i[df_coord_slab_i.element == \"O\"]\n",
    "df_i = df_i[df_i.num_neighbors == 0]\n",
    "\n",
    "o_atoms_to_remove = df_i.structure_index.tolist()\n",
    "\n",
    "# #########################################################\n",
    "o_atoms_to_remove_1 = []\n",
    "df_j = df_coord_slab_i[df_coord_slab_i.element == \"O\"]\n",
    "for j_cnt, row_j in  df_j.iterrows():\n",
    "    neighbor_count = row_j.neighbor_count\n",
    "\n",
    "    if neighbor_count.get(\"Ir\", 0) == 0:\n",
    "        if neighbor_count.get(\"O\", 0) == 1:\n",
    "            o_atoms_to_remove_1.append(row_j.structure_index)\n",
    "\n",
    "\n",
    "o_atoms_to_remove = list(set(o_atoms_to_remove + o_atoms_to_remove_1))\n",
    "\n",
    "slab_new = remove_atoms(atoms, atoms_to_remove=o_atoms_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slab_new.write()\n",
    "\n",
    "slab_new.write(\"out_data/temp_out/slab_1.cif\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slab_0 = io.read(\n",
    "    \"out_data/final_slabs_2/zimuby8uzj__fagepuha_94__001.cif\"\n",
    "    # \"out_data/temp_out/slab_1_2.cif\"\n",
    "    )\n",
    "\n",
    "# slab_0.write(\"out_data/temp_out_0/slab_0.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def remove_highest_metal_atoms(\n",
    "# atoms=slab_0\n",
    "# num_atoms_to_remove=num_atoms_to_remove\n",
    "# metal_atomic_number=77\n",
    "# # ):\n",
    "# \"\"\"\n",
    "# \"\"\"\n",
    "# #| - remove_highest_metal_atom\n",
    "# slab_m = atoms[atoms.numbers == metal_atomic_number]\n",
    "\n",
    "# positions_cpy = copy.deepcopy(slab_m.positions)\n",
    "# positions_cpy_sorted = positions_cpy[positions_cpy[:,2].argsort()]\n",
    "\n",
    "\n",
    "# # positions_z = positions_cpy[:, 2]\n",
    "# # positions_z.sort()\n",
    "# # positions_z = np.flip(positions_z)\n",
    "\n",
    "\n",
    "# indices_to_remove = []\n",
    "# for coord_i in positions_cpy_sorted[-2:]:\n",
    "#     for i_cnt, atom in enumerate(atoms):\n",
    "#         if all(atom.position == coord_i):\n",
    "#             print(\"PSIDFJIDSJi\")\n",
    "#             indices_to_remove.append(i_cnt)\n",
    "\n",
    "# slab_new = remove_atoms(\n",
    "#     atoms=atoms,\n",
    "#     atoms_to_remove=indices_to_remove,\n",
    "#     )\n",
    "\n",
    "# # return(slab_new)\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_to_remove = []\n",
    "# for coord_i in positions_cpy_sorted[-2:]:\n",
    "#     for i_cnt, atom in enumerate(atoms):\n",
    "#         if all(atom.position == coord_i):\n",
    "#             print(\"PSIDFJIDSJi\")\n",
    "#             indices_to_remove.append(i_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# slab_new.write(\"out_data/temp_out_0/slab_1.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions_cpy\n",
    "\n",
    "# positions_cpy_sorted = positions_cpy[positions_cpy[:,2].argsort()]\n",
    "\n",
    "# array_tmp = np.array([\n",
    "#     [1, 2, 3],\n",
    "#     [1, 2, 8],\n",
    "#     [1, 2, 1],\n",
    "#     ]\n",
    "#     )\n",
    "# array_tmp[array_tmp[:,2].argsort()]\n",
    "\n",
    "# positions_cpy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# DFT dataframe\n",
    "df_dft = get_df_dft()\n",
    "\n",
    "# #########################################################\n",
    "# Previous df_slab dataframe\n",
    "path_i = os.path.join(\n",
    "    \"out_data\",\n",
    "    # \"__old__\",\n",
    "    \"df_slab.pickle\")\n",
    "my_file = Path(path_i)\n",
    "if my_file.is_file():\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_slab_old = pickle.load(fle)\n",
    "else:\n",
    "    df_slab_old = pd.DataFrame()\n",
    "\n",
    "print(\"df_slab_old.shape:\", df_slab_old.shape)\n",
    "\n",
    "# #######################################################################\n",
    "# Bulks not to run, manually checked to be erroneous/bad\n",
    "data_path = os.path.join(\n",
    "    \"in_data/bulks_to_not_run.json\")\n",
    "with open(data_path, \"r\") as fle:\n",
    "    bulks_to_not_run = json.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [\n",
    "    \"fukebife_19\",\n",
    "    \"karosepo_32\",\n",
    "    \"nepobapa_79\",\n",
    "    \"wuhasulu_74\",\n",
    "    \"wonasofa_20\",\n",
    "    \"fovakevo_63\",\n",
    "    \"vasubaba_10\",\n",
    "    \"tetekuse_50\",\n",
    "    \"tasiluno_60\",\n",
    "    \"henivako_70\",\n",
    "    \"kivesohe_51\",\n",
    "    \"redobodi_26\",\n",
    "    \"vokumemi_16\",\n",
    "    \"tumolubo_46\",\n",
    "    \"lanasahi_54\",\n",
    "    \"magevawo_12\",\n",
    "    \"sorogane_14\",\n",
    "    \"gisasaho_61\",\n",
    "    ]\n",
    "\n",
    "df_i = df_slab_old.loc[bad_ids][[\"bulk_id\", \"facet\"]]\n",
    "\n",
    "data_dict_list = []\n",
    "for i_cnt, row_i in df_i.iterrows():\n",
    "    tmp = 42\n",
    "\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    bulk_id = row_i.bulk_id\n",
    "    facet_str = row_i.facet\n",
    "\n",
    "    facet = (facet_str[0], facet_str[1], facet_str[2])\n",
    "    facet = tuple([int(i) for i in facet])\n",
    "\n",
    "    data_dict_i[\"bulk_id\"] = bulk_id\n",
    "    data_dict_i[\"facet\"] = facet\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "data_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "out_dict = data_dict_list\n",
    "# out_dict[\"TEMP\"] = None\n",
    "\n",
    "import os; import pickle\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"HOME\"],\n",
    "    \"__temp__\",\n",
    "    \"temp.pickle\")\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(out_dict, fle)\n",
    "# #########################################################\n",
    "\n",
    "# #########################################################\n",
    "import pickle; import os\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"HOME\"],\n",
    "    \"__temp__\",\n",
    "    \"temp.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    out_dict = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #######################################################################\n",
    "# # Bulks not to run, manually checked to be erroneous/bad\n",
    "# data_path = os.path.join(\n",
    "#     \"in_data/bulks_to_not_run.json\")\n",
    "# with open(data_path, \"r\") as fle:\n",
    "#     bulks_to_not_run = json.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulks_to_not_run\n",
    "\n",
    "\n",
    "# root_dir = \"out_data\"\n",
    "# for subdir, dirs, files in os.walk(root_dir):\n",
    "#     if \"bulk_structures_temp\" in subdir:\n",
    "#         continue\n",
    "\n",
    "#     for file in files:\n",
    "#         # print(os.path.join(subdir, file))\n",
    "#         file_path = os.path.join(subdir, file)\n",
    "\n",
    "#         for bulk_i in bulks_to_not_run:\n",
    "#             if bulk_i in file:\n",
    "#                 print(file)\n",
    "#                 # os.remove(file_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# DFT dataframe\n",
    "df_dft = get_df_dft()\n",
    "\n",
    "# #########################################################\n",
    "# Previous df_slab dataframe\n",
    "path_i = os.path.join(\n",
    "    \"out_data\",\n",
    "    \"df_slab.pickle\")\n",
    "my_file = Path(path_i)\n",
    "if my_file.is_file():\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_slab_old = pickle.load(fle)\n",
    "else:\n",
    "    df_slab_old = pd.DataFrame()\n",
    "\n",
    "print(\"df_slab_old.shape:\", df_slab_old.shape)\n",
    "\n",
    "# #######################################################################\n",
    "# Bulks not to run, manually checked to be erroneous/bad\n",
    "data_path = os.path.join(\n",
    "    \"in_data/bulks_to_not_run.json\")\n",
    "with open(data_path, \"r\") as fle:\n",
    "    bulks_to_not_run = json.load(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_old.shape\n",
    "\n",
    "# (472, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_old\n",
    "\n",
    "bulks_to_not_run\n",
    "\n",
    "\n",
    "df_slab_old = df_slab_old[~df_slab_old.bulk_id.isin(bulks_to_not_run)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_old\n",
    "\n",
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = \"out_data\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"data_new_new.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_slab_old, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################\n",
    "data_path = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/creating_slabs/selecting_bulks\",\n",
    "    \"out_data/data.json\")\n",
    "with open(data_path, \"r\") as fle:\n",
    "    data = json.load(fle)\n",
    "# ########################################################\n",
    "\n",
    "bulk_ids__octa_unique = data[\"bulk_ids__octa_unique\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\"out_data\", \"df_slab.pickle\")\n",
    "my_file = Path(path_i)\n",
    "if my_file.is_file():\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_slab_old = pickle.load(fle)\n",
    "    print(\"df_slab_old.shape:\", df_slab_old.shape)\n",
    "\n",
    "    row_i = df_slab_old.iloc[1]\n",
    "    df_slab_old.sort_values(\"iter_time_i\", ascending=False)\n",
    "    \n",
    "\n",
    "# df_slab_old.head()\n",
    "df_slab_old.sort_values(\"iter_time_i\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab = df_slab_old\n",
    "\n",
    "row_i = df_slab.loc[\"kupopaba_83\"]\n",
    "\n",
    "atoms = row_i.slab_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_z_slab(atoms=None, vacuum=15):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    z_pos = atoms.positions[:,2]\n",
    "    z_max = np.max(z_pos)\n",
    "    z_min = np.min(z_pos)\n",
    "\n",
    "    new_z_height = z_max - z_min + vacuum\n",
    "\n",
    "    cell = atoms.cell\n",
    "\n",
    "    cell_cpy = cell.copy()\n",
    "    cell_cpy = cell_cpy.tolist()\n",
    "\n",
    "    cell_cpy[2][2] = new_z_height\n",
    "\n",
    "    atoms_cpy = copy.deepcopy(atoms)\n",
    "    atoms_cpy.set_cell(cell_cpy)\n",
    "\n",
    "    return(atoms_cpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms_new = resize_z_slab(atoms=atoms, vacuum=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_i = df_slab_old.iloc[-1]\n",
    "atoms = row_i.slab_final\n",
    "\n",
    "num_atoms = atoms.get_number_of_atoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # row_i = df_slab_old.iloc[0]\n",
    "    atoms = row_i.slab_final\n",
    "\n",
    "    num_atoms = atoms.get_number_of_atoms()\n",
    "    return(num_atoms)\n",
    "\n",
    "df_i = df_slab_old\n",
    "df_i[\"num_atoms\"] = df_i.apply(\n",
    "    method,\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.options.plotting.backend = \"plotly\"\n",
    "# df_i[[\"iter_time_i\", \"num_atoms\"]].plot()\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# x_array = [0, 1, 2, 3]\n",
    "# y_array = [0, 1, 2, 3]\n",
    "\n",
    "y_array = df_i.iter_time_i / 60\n",
    "x_array = df_i.num_atoms\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=x_array,\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "    )\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"out_data/out.log\", 'a') as the_file:\n",
    "#     the_file.write(\"Hello\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import signal\n",
    "# from time import sleep    # only needed for testing\n",
    "\n",
    "# timelimit_seconds = 3    # Must be an integer\n",
    "\n",
    "# # Custom exception for the timeout\n",
    "# class TimeoutException(Exception):\n",
    "#     pass\n",
    "\n",
    "# # Handler function to be called when SIGALRM is received\n",
    "# def sigalrm_handler(signum, frame):\n",
    "#     # We get signal!\n",
    "#     raise TimeoutException()\n",
    "\n",
    "# # Function that takes too long for bananas and oranges\n",
    "# def mix(f):\n",
    "#     if 'n' in f:\n",
    "#         sleep(20)\n",
    "#     else:\n",
    "#         sleep(0.5)\n",
    "\n",
    "# fruits = ['apple', 'banana', 'grape', 'strawberry', 'orange']\n",
    "# for f in fruits:\n",
    "#     # Set up signal handler for SIGALRM, saving previous value\n",
    "#     old_handler = signal.signal(signal.SIGALRM, sigalrm_handler)\n",
    "#     # Start timer\n",
    "#     signal.alarm(timelimit_seconds)\n",
    "#     try:\n",
    "#         mix(f)\n",
    "#         print(f, 'was mixed')\n",
    "#     except TimeoutException:\n",
    "#         print(f, 'took too long to mix')\n",
    "#     finally:\n",
    "#         # Turn off timer\n",
    "#         signal.alarm(0)\n",
    "#         # Restore handler to previous value\n",
    "#         signal.signal(signal.SIGALRM, old_handler)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\"out_data\", \"df_slab.pickle\")\n",
    "my_file = Path(path_i)\n",
    "if my_file.is_file():\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_slab_old = pickle.load(fle)\n",
    "\n",
    "print(\"df_slab_old.shape:\", df_slab_old.shape)\n",
    "\n",
    "row_i = df_slab_old.iloc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slab_old.sort_values(\"iter_time_i\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slab = row_i.slab_final\n",
    "\n",
    "slab_new = constrain_slab(atoms=slab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slab_new.write(\"temp.traj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions = slab.positions\n",
    "\n",
    "# z_pos = positions[:,2]\n",
    "\n",
    "# z_max = np.max(z_pos)\n",
    "# z_min = np.min(z_pos)\n",
    "\n",
    "# # ang_of_slab_to_constrain = (2 / 4) * (z_max - z_min)\n",
    "# ang_of_slab_to_constrain = (z_max - z_min) - 6\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# indices_to_constrain = []\n",
    "# for atom in slab:\n",
    "#     if atom.symbol == metal_atom_symbol:\n",
    "#         if atom.position[2] < (z_min + ang_of_slab_to_constrain):\n",
    "#             indices_to_constrain.append(atom.index)\n",
    "\n",
    "# for atom in slab:\n",
    "#     if atom.position[2] < (z_min + ang_of_slab_to_constrain - 2):\n",
    "#         indices_to_constrain.append(atom.index)\n",
    "\n",
    "# df_coord_slab_i = get_structure_coord_df(slab)\n",
    "\n",
    "# # #########################################################\n",
    "# other_atoms_to_constrain = []\n",
    "# for ind_i in indices_to_constrain:\n",
    "#     row_i = df_coord_slab_i[df_coord_slab_i.structure_index == ind_i]\n",
    "#     row_i = row_i.iloc[0]\n",
    "\n",
    "#     nn_info = row_i.nn_info\n",
    "\n",
    "#     for nn_i in nn_info:\n",
    "#         ind_j = nn_i[\"site_index\"]\n",
    "#         other_atoms_to_constrain.append(ind_j)\n",
    "\n",
    "# print(len(indices_to_constrain))\n",
    "\n",
    "# indices_to_constrain.extend(other_atoms_to_constrain)\n",
    "\n",
    "# print(len(indices_to_constrain))\n",
    "\n",
    "# # #########################################################\n",
    "# constrain_bool_mask = []\n",
    "# for atom in slab:\n",
    "#     if atom.index in indices_to_constrain:\n",
    "#         constrain_bool_mask.append(True)\n",
    "#     else:\n",
    "#         constrain_bool_mask.append(False)\n",
    "\n",
    "# # #########################################################\n",
    "# slab_cpy = copy.deepcopy(slab)\n",
    "\n",
    "# from ase.constraints import FixAtoms\n",
    "# c = FixAtoms(mask=constrain_bool_mask)\n",
    "# slab_cpy.set_constraint(c)\n",
    "\n",
    "# slab_cpy.constraints"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    \"out_data\",\n",
    "    \"df_slab.pickle\")\n",
    "my_file = Path(path_i)\n",
    "if my_file.is_file():\n",
    "    print(\"File exists!\")\n",
    "    with open(path_i, \"rb\") as fle:\n",
    "        df_slab_old = pickle.load(fle)\n",
    "else:\n",
    "    df_slab_old = pd.DataFrame()\n",
    "\n",
    "df_slab = df_slab_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_i = df_slab.loc[\"muniketo_71\"]\n",
    "row_i = df_slab.loc[\"fipohulu_74\"]\n",
    "\n",
    "# row_i = df_slab.iloc[0]\n",
    "\n",
    "slab = row_i.slab_2\n",
    "print(slab.symbols.get_chemical_formula())\n",
    "\n",
    "slab_thickness_i = get_slab_thickness(atoms=slab)\n",
    "print(\"slab_thickness_i:\", slab_thickness_i)\n",
    "\n",
    "slab.write(\"out_data/temp_0.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slab_final = create_final_slab_master(atoms=slab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################################################\n",
    "# slab_thickness_i = get_slab_thickness(atoms=slab)\n",
    "# print(\"slab_thickness_i:\", slab_thickness_i)\n",
    "\n",
    "# slab = remove_all_atoms_above_cutoff(atoms=slab, cutoff_thickness=17)\n",
    "# slab.write(\"out_data/temp_1.cif\")\n",
    "\n",
    "# slab_thickness_i = get_slab_thickness(atoms=slab)\n",
    "# print(\"slab_thickness_i:\", slab_thickness_i)\n",
    "\n",
    "\n",
    "\n",
    "# ###########################################################\n",
    "# slab = remove_nonsaturated_surface_metal_atoms(\n",
    "#     atoms=slab,\n",
    "#     dz=4)\n",
    "\n",
    "# slab.write(\"out_data/temp_2.cif\")\n",
    "# slab_thickness_i = get_slab_thickness(atoms=slab)\n",
    "# print(\"slab_thickness_i:\", slab_thickness_i)\n",
    "\n",
    "# slab = remove_noncoord_oxygens(atoms=slab)\n",
    "\n",
    "# slab.write(\"out_data/temp_3.cif\")\n",
    "# slab_thickness_i = get_slab_thickness(atoms=slab)\n",
    "# print(\"slab_thickness_i:\", slab_thickness_i)\n",
    "\n",
    "\n",
    "\n",
    "# ###########################################################\n",
    "# i_cnt = 3\n",
    "# while slab_thickness_i > 15:\n",
    "#     i_cnt += 1\n",
    "#     print(i_cnt)\n",
    "\n",
    "#     # #####################################################\n",
    "#     # Figuring out how many surface atoms to remove at one time\n",
    "#     # Taken from R-IrO2 (100), which has 8 surface Ir atoms and a surface area of 58 A^2\n",
    "#     surf_area_per_surface_metal = 58 / 8\n",
    "#     surface_area_i = calc_surface_area(atoms=slab)\n",
    "#     ideal_num_surface_atoms = surface_area_i / surf_area_per_surface_metal\n",
    "#     num_atoms_to_remove = ideal_num_surface_atoms / 3\n",
    "#     num_atoms_to_remove = int(np.round(num_atoms_to_remove))\n",
    "#     # #####################################################\n",
    "\n",
    "#     slab_new_0 = remove_highest_metal_atoms(\n",
    "#         atoms=slab,\n",
    "#         num_atoms_to_remove=num_atoms_to_remove,\n",
    "#         metal_atomic_number=77)\n",
    "\n",
    "#     slab_new_1 = remove_nonsaturated_surface_metal_atoms(\n",
    "#         atoms=slab_new_0,\n",
    "#         dz=4)\n",
    "\n",
    "#     slab_new_2 = remove_noncoord_oxygens(atoms=slab_new_1)\n",
    "\n",
    "\n",
    "#     slab_thickness_i = get_slab_thickness(atoms=slab_new_2)\n",
    "#     print(\"slab_thickness_i:\", slab_thickness_i)\n",
    "\n",
    "#     slab_new_2.write(\"out_data/temp_\" + str(i_cnt) + \".cif\")\n",
    "\n",
    "#     slab = slab_new_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf_area_per_surface_metal = 58 / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slab_new = remove_highest_metal_atoms(\n",
    "#     atoms=slab,\n",
    "#     num_atoms_to_remove=3,\n",
    "#     metal_atomic_number=77,\n",
    "#     )\n",
    "\n",
    "# print(slab_new.symbols.get_chemical_formula())\n",
    "# slab_new.write(\"out_data/temp_1.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_highest_metal_atom(\n",
    "#     atoms=None,\n",
    "#     metal_atomic_number=77,\n",
    "#     ):\n",
    "#     # TODO Make this more robust, don't just code in 77\n",
    "#     slab_m = slab[slab.numbers == 77]\n",
    "#     highest_atom_ind = np.argmax(slab_m.positions[:,2])\n",
    "\n",
    "#     iterator = enumerate(slab.positions == slab_m[highest_atom_ind].position)\n",
    "#     for i_cnt, bool_list in iterator:\n",
    "#         if all(bool_list):\n",
    "#             highest_atom_ind_new = i_cnt\n",
    "\n",
    "#     slab_new = copy.deepcopy(slab)\n",
    "\n",
    "#     slab_new.pop(highest_atom_ind_new)\n",
    "\n",
    "#     return(slab_new)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import trange\n",
    "# from time import sleep\n",
    "\n",
    "# for i in trange(4, desc='1st loop'):\n",
    "#     for j in trange(5, desc='2nd loop'):\n",
    "#         for k in trange(50, desc='3rd loop', leave=False):\n",
    "#             sleep(0.01)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# from tqdm import trange, tqdm\n",
    "from time import sleep\n",
    "\n",
    "iterator = tqdm([\"a\", \"b\", \"c\", \"d\"])\n",
    "for i_cnt, bulk_id in enumerate(iterator):\n",
    "    for j in tqdm(range(100), desc='2nd loop'):\n",
    "        sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(10000000)):\n",
    "    tmp = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickling data ###########################################\n",
    "# out_dict = dict()\n",
    "# out_dict[\"TEMP\"] = None\n",
    "\n",
    "# import os; import pickle\n",
    "# path_i = os.path.join(\n",
    "#     os.environ[\"HOME\"],\n",
    "#     \"__temp__\",\n",
    "#     \"temp.pickle\")\n",
    "# with open(path_i, \"wb\") as fle:\n",
    "#     pickle.dump(out_dict, fle)\n",
    "# # #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "import pickle; import os\n",
    "path_i = os.path.join(\n",
    "    os.environ[\"HOME\"],\n",
    "    \"__temp__\",\n",
    "    \"temp.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    out_dict = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = out_dict[\"struct\"]\n",
    "\n",
    "# dir(struct[0])\n",
    "\n",
    "site = struct[-1]\n",
    "\n",
    "# dir(site.species)\n",
    "\n",
    "# site.oxi_state_guesses()\n",
    "# site.species.oxi_state_guesses()\n",
    "\n",
    "\n",
    "# dir(site.specie)\n",
    "# type(site.specie)\n",
    "# site.specie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"type(struct):\", \"\\n\", type(struct))\n",
    "\n",
    "print(\"type(struct[-1]):\", \"\\n\", type(struct[-1]))\n",
    "\n",
    "print(\"type(struct[-1].specie):\", \"\\n\", type(struct[-1].specie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen import Lattice, Structure, Molecule\n",
    "\n",
    "coords = [[0, 0, 0], [0.75,0.5,0.75]]\n",
    "lattice = Lattice.from_parameters(a=3.84, b=3.84, c=3.84, alpha=120,\n",
    "                                  beta=90, gamma=60)\n",
    "struct = Structure(lattice, [\"Si\", \"Si\"], coords)\n",
    "\n",
    "coords = [[0.000000, 0.000000, 0.000000],\n",
    "          [0.000000, 0.000000, 1.089000],\n",
    "          [1.026719, 0.000000, -0.363000],\n",
    "          [-0.513360, -0.889165, -0.363000],\n",
    "          [-0.513360, 0.889165, -0.363000]]\n",
    "methane = Molecule([\"C\", \"H\", \"H\", \"H\", \"H\"], coords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
