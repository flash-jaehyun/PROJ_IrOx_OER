{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the octahedral volume and other geometric quantities\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.options.display.max_colwidth = 100\n",
    "\n",
    "# #########################################################\n",
    "from proj_data import metal_atom_symbol\n",
    "\n",
    "from methods import (\n",
    "    get_df_jobs_anal,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_active_sites,\n",
    "    get_df_coord,\n",
    "    )\n",
    "\n",
    "# #########################################################\n",
    "# from local_methods import get_effective_ox_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "# verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_anal_i = df_jobs_anal\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "\n",
    "df_active_sites = get_df_active_sites()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# #########################################################\n",
    "\n",
    "# TEMP\n",
    "# print(\"TEMP\")\n",
    "# # name_i = ('nersc', 'mubolemu_18', 'o', 'NaN', 1)\n",
    "# # name_i = ('sherlock', 'kagekiha_49', 'o', 'NaN', 1)\n",
    "# name_i = (\"nersc\", \"kalisule_45\", \"o\", \"NaN\", 1)\n",
    "\n",
    "# df_jobs_anal_i = df_jobs_anal_i.loc[[name_i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "\n",
    "# df_index = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "# df_index_i = df_index[\n",
    "#     (df_index.compenv == \"nersc\") & \\\n",
    "#     (df_index.slab_id == \"fosurufu_23\") & \\\n",
    "#     [True for i in range(len(df_index))]\n",
    "#     ]\n",
    "\n",
    "# df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "#     df_index_i.index.tolist()\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal_i =  df_jobs_anal_i[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "df_jobs_anal_i = df_jobs_anal_i.loc[idx[:, :, \"o\", :, :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "for name_i, row_i in df_jobs_anal_i.iterrows():\n",
    "    if verbose:\n",
    "        name_concat_i = \"_\".join([str(i) for i in list(name_i)])\n",
    "        print(40 * \"=\")\n",
    "        print(name_concat_i)\n",
    "\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(\n",
    "        list(df_jobs_anal_i.index.names),\n",
    "        list(name_i)))\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    ads_i = name_i[2]\n",
    "    active_site_i = name_i[3]\n",
    "    att_num_i = name_i[4]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    row_atoms_i = df_atoms_sorted_ind.loc[name_i]\n",
    "    # #####################################################\n",
    "    atoms = row_atoms_i.atoms_sorted_good\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_sites_i = df_active_sites.loc[slab_id_i]\n",
    "    # #####################################################\n",
    "    active_sites_unique_i = row_sites_i.active_sites_unique\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Write atoms to file\n",
    "    file_name_i = \"__\".join([str(i) for i in name_i])\n",
    "    file_name_i += \".cif\"\n",
    "\n",
    "    file_name_j = \"__\".join([str(i) for i in name_i])\n",
    "    file_name_j += \".traj\"\n",
    "\n",
    "    # atoms.write(os.path.join(\"__temp__\", file_name_i))\n",
    "    # atoms.write(os.path.join(\"__temp__\", file_name_j))\n",
    "    \n",
    "    for active_site_j in active_sites_unique_i:\n",
    "        data_dict_j = dict()\n",
    "        if verbose:\n",
    "            print(\"\\t\", \"active_site_j:\", active_site_j)\n",
    "\n",
    "        # #################################################\n",
    "        name_i = (\n",
    "            compenv_i, slab_id_i, ads_i,\n",
    "            active_site_i, att_num_i)\n",
    "        df_coord_i = get_df_coord(\n",
    "            mode=\"post-dft\",\n",
    "            post_dft_name_tuple=name_i)\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        from local_methods import get_octa_vol\n",
    "        vol_i = get_octa_vol(\n",
    "            df_coord_i=df_coord_i,\n",
    "            active_site_j=active_site_j,\n",
    "            verbose=verbose)\n",
    "        # #################################################\n",
    "        from local_methods import get_octa_geom\n",
    "        octa_geom_dict = get_octa_geom(\n",
    "            df_coord_i=df_coord_i,\n",
    "            active_site_j=active_site_j,\n",
    "            atoms=atoms,\n",
    "            verbose=verbose)\n",
    "        # #################################################\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        data_dict_j.update(name_dict_i)\n",
    "        data_dict_j.update(octa_geom_dict)\n",
    "        data_dict_j[\"active_site\"] = active_site_j\n",
    "        data_dict_j[\"octa_vol\"] = vol_i\n",
    "        # #################################################\n",
    "        data_dict_list.append(data_dict_j)\n",
    "        # #################################################\n",
    "\n",
    "# #########################################################\n",
    "df_octa_vol = pd.DataFrame(data_dict_list)\n",
    "# df_octa_vol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_octa_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/feature_engineering/octahedra_volume\")\n",
    "\n",
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = os.path.join(root_path_i, \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "path_i = os.path.join(root_path_i, \"out_data/df_octa_vol.pickle\")\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(df_octa_vol, fle)\n",
    "# #########################################################\n",
    "\n",
    "# #########################################################\n",
    "import pickle; import os\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_octa_vol = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving some data objects to test out elsewhere"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = dict(\n",
    "    df_coord_i=df_coord_i,\n",
    "    active_site_j=active_site_j,\n",
    "    atoms=atoms,\n",
    "    )\n",
    "\n",
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = \"__temp__\"\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"data.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(out_dict, fle)\n",
    "# #########################################################\n",
    "\n",
    "# #########################################################\n",
    "import pickle; import os\n",
    "path_i = os.path.join(\n",
    "    # os.environ[\"\"],\n",
    "    \"__temp__\",\n",
    "    \"data.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    out_data = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# data_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# name_i = ('nersc', 'mubolemu_18', 'o', 'NaN', 1)\n",
    "\n",
    "# # for name_i, row_i in df_jobs_anal_i.iterrows():\n",
    "\n",
    "# df_jobs_anal_i = df_jobs_anal_i.loc[[name_i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_jobs_anal[df_jobs_anal.job_id_max == \"vupihona_68\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_jobs_anal = df_jobs_anal.loc[\n",
    "#     [('nersc', 'galopuba_86', 'o', 'NaN', 1)]\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# print(\"active_site_j:\", active_site_j)\n",
    "\n",
    "# atoms.write(\"__temp__/tmp.cif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# name_i\n",
    "# row_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# file_name_i\n",
    "# active_site_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_index = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "# df_index_i = df_index[\n",
    "#     (df_index.compenv == \"nersc\") & \\\n",
    "#     (df_index.slab_id == \"fosurufu_23\") & \\\n",
    "#     [True for i in range(len(df_index))]\n",
    "#     ]\n",
    "\n",
    "# df_jobs_anal_i = df_jobs_anal_i.loc[\n",
    "#     df_index_i.index.tolist()\n",
    "#     ]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
