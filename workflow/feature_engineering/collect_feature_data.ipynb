{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect feature data into master dataframe\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/workflow/feature_engineering\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_octa_vol, get_df_eff_ox\n",
    "from methods import get_df_dft\n",
    "from methods import get_df_job_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read feature dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_octa_vol = get_df_octa_vol()\n",
    "\n",
    "df_eff_ox = get_df_eff_ox()\n",
    "\n",
    "df_dft = get_df_dft()\n",
    "\n",
    "df_job_ids = get_df_job_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_methods import combine_dfs_with_same_cols\n",
    "\n",
    "df_dict_i = {\n",
    "    \"df_eff_ox\": df_eff_ox,\n",
    "    \"df_octa_vol\": df_octa_vol,\n",
    "    }\n",
    "\n",
    "df_features = combine_dfs_with_same_cols(\n",
    "    df_dict=df_dict_i,\n",
    "    verbose=verbose,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in bulk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    new_column_values_dict = {\n",
    "        \"dH_bulk\": None,\n",
    "        \"volume_pa\": None,\n",
    "        \"bulk_oxid_state\": None,\n",
    "        }\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    slab_id_i = row_i.name[1]\n",
    "    # #####################################################\n",
    "    bulk_ids = df_job_ids[df_job_ids.slab_id == slab_id_i].bulk_id.unique()\n",
    "    mess_i = \"ikjisdjf\"\n",
    "    assert len(bulk_ids) == 1, mess_i\n",
    "    bulk_id_i = bulk_ids[0]\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_dft_i = df_dft.loc[bulk_id_i]\n",
    "    # #####################################################\n",
    "    dH_i = row_dft_i.dH\n",
    "    volume_pa = row_dft_i.volume_pa\n",
    "    stoich_i = row_dft_i.stoich\n",
    "    # #####################################################\n",
    "\n",
    "    if stoich_i == \"AB2\":\n",
    "        bulk_oxid_state_i = +4\n",
    "    elif stoich_i == \"AB3\":\n",
    "        bulk_oxid_state_i = +6\n",
    "    else:\n",
    "        print(\"Uh oh, couldn't parse bulk stoich, not good\")\n",
    "\n",
    "    # #####################################################\n",
    "    new_column_values_dict[\"dH_bulk\"] = dH_i\n",
    "    new_column_values_dict[\"volume_pa\"] = volume_pa\n",
    "    new_column_values_dict[\"bulk_oxid_state\"] = bulk_oxid_state_i\n",
    "    # #####################################################\n",
    "    for key, value in new_column_values_dict.items():\n",
    "        row_i[(\"features\", key)] = value\n",
    "    return(row_i)\n",
    "\n",
    "df_features = df_features.apply(method, axis=1)\n",
    "df_features = df_features.reindex(columns = [\"data\", \"features\", ], level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_features.shape: (1655, 19)\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    print(\"df_features.shape:\", df_features.shape)\n",
    "\n",
    "# df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path_i = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"workflow/feature_engineering\")\n",
    "\n",
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = os.path.join(root_path_i, \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "path_i = os.path.join(root_path_i, \"out_data/df_features.pickle\")\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(df_features, fle)\n",
    "# #########################################################\n",
    "\n",
    "# #########################################################\n",
    "import pickle; import os\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    df_features = pickle.load(fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"11\" halign=\"left\">data</th>\n",
       "      <th colspan=\"8\" halign=\"left\">features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>active_site</th>\n",
       "      <th>ads</th>\n",
       "      <th>att_num</th>\n",
       "      <th>compenv</th>\n",
       "      <th>from_oh</th>\n",
       "      <th>job_id_max</th>\n",
       "      <th>slab_id</th>\n",
       "      <th>active_site_orig</th>\n",
       "      <th>num_missing_Os</th>\n",
       "      <th>orig_slab_good</th>\n",
       "      <th>used_unrelaxed_df_coord</th>\n",
       "      <th>active_o_metal_dist</th>\n",
       "      <th>eff_oxid_state</th>\n",
       "      <th>ir_o_mean</th>\n",
       "      <th>ir_o_std</th>\n",
       "      <th>octa_vol</th>\n",
       "      <th>dH_bulk</th>\n",
       "      <th>volume_pa</th>\n",
       "      <th>bulk_oxid_state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compenv</th>\n",
       "      <th>slab_id</th>\n",
       "      <th>ads</th>\n",
       "      <th>active_site</th>\n",
       "      <th>att_num</th>\n",
       "      <th>from_oh</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">nersc</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">fosurufu_23</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">o</th>\n",
       "      <th>43.0</th>\n",
       "      <th>1</th>\n",
       "      <th>False</th>\n",
       "      <td>43.0</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>nersc</td>\n",
       "      <td>False</td>\n",
       "      <td>wototabi_72</td>\n",
       "      <td>fosurufu_23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.757003</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.952891</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>9.310264</td>\n",
       "      <td>-0.595820</td>\n",
       "      <td>13.422324</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <th>1</th>\n",
       "      <th>False</th>\n",
       "      <td>45.0</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>nersc</td>\n",
       "      <td>False</td>\n",
       "      <td>wototabi_72</td>\n",
       "      <td>fosurufu_23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.751524</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.952891</td>\n",
       "      <td>0.163121</td>\n",
       "      <td>9.310264</td>\n",
       "      <td>-0.595820</td>\n",
       "      <td>13.422324</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>galopuba_86</th>\n",
       "      <th>o</th>\n",
       "      <th>21.0</th>\n",
       "      <th>1</th>\n",
       "      <th>False</th>\n",
       "      <td>21.0</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>nersc</td>\n",
       "      <td>False</td>\n",
       "      <td>fatimuse_24</td>\n",
       "      <td>galopuba_86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.749184</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.985623</td>\n",
       "      <td>0.115797</td>\n",
       "      <td>9.719644</td>\n",
       "      <td>-0.606853</td>\n",
       "      <td>14.047474</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gubufafu_74</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">o</th>\n",
       "      <th>16.0</th>\n",
       "      <th>1</th>\n",
       "      <th>False</th>\n",
       "      <td>16.0</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>nersc</td>\n",
       "      <td>False</td>\n",
       "      <td>nileribu_07</td>\n",
       "      <td>gubufafu_74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.799507</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.872250</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>8.732127</td>\n",
       "      <td>-0.418717</td>\n",
       "      <td>12.740641</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <th>1</th>\n",
       "      <th>False</th>\n",
       "      <td>20.0</td>\n",
       "      <td>o</td>\n",
       "      <td>1</td>\n",
       "      <td>nersc</td>\n",
       "      <td>False</td>\n",
       "      <td>nileribu_07</td>\n",
       "      <td>gubufafu_74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.785505</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.872250</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>8.732127</td>\n",
       "      <td>-0.418717</td>\n",
       "      <td>12.740641</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           data              \\\n",
       "                                                    active_site ads att_num   \n",
       "compenv slab_id     ads active_site att_num from_oh                           \n",
       "nersc   fosurufu_23 o   43.0        1       False          43.0   o       1   \n",
       "                        45.0        1       False          45.0   o       1   \n",
       "        galopuba_86 o   21.0        1       False          21.0   o       1   \n",
       "        gubufafu_74 o   16.0        1       False          16.0   o       1   \n",
       "                        20.0        1       False          20.0   o       1   \n",
       "\n",
       "                                                                     \\\n",
       "                                                    compenv from_oh   \n",
       "compenv slab_id     ads active_site att_num from_oh                   \n",
       "nersc   fosurufu_23 o   43.0        1       False     nersc   False   \n",
       "                        45.0        1       False     nersc   False   \n",
       "        galopuba_86 o   21.0        1       False     nersc   False   \n",
       "        gubufafu_74 o   16.0        1       False     nersc   False   \n",
       "                        20.0        1       False     nersc   False   \n",
       "\n",
       "                                                                               \\\n",
       "                                                      job_id_max      slab_id   \n",
       "compenv slab_id     ads active_site att_num from_oh                             \n",
       "nersc   fosurufu_23 o   43.0        1       False    wototabi_72  fosurufu_23   \n",
       "                        45.0        1       False    wototabi_72  fosurufu_23   \n",
       "        galopuba_86 o   21.0        1       False    fatimuse_24  galopuba_86   \n",
       "        gubufafu_74 o   16.0        1       False    nileribu_07  gubufafu_74   \n",
       "                        20.0        1       False    nileribu_07  gubufafu_74   \n",
       "\n",
       "                                                                      \\\n",
       "                                                    active_site_orig   \n",
       "compenv slab_id     ads active_site att_num from_oh                    \n",
       "nersc   fosurufu_23 o   43.0        1       False                NaN   \n",
       "                        45.0        1       False                NaN   \n",
       "        galopuba_86 o   21.0        1       False                NaN   \n",
       "        gubufafu_74 o   16.0        1       False                NaN   \n",
       "                        20.0        1       False                NaN   \n",
       "\n",
       "                                                                    \\\n",
       "                                                    num_missing_Os   \n",
       "compenv slab_id     ads active_site att_num from_oh                  \n",
       "nersc   fosurufu_23 o   43.0        1       False                0   \n",
       "                        45.0        1       False                0   \n",
       "        galopuba_86 o   21.0        1       False                0   \n",
       "        gubufafu_74 o   16.0        1       False                0   \n",
       "                        20.0        1       False                0   \n",
       "\n",
       "                                                                    \\\n",
       "                                                    orig_slab_good   \n",
       "compenv slab_id     ads active_site att_num from_oh                  \n",
       "nersc   fosurufu_23 o   43.0        1       False             True   \n",
       "                        45.0        1       False             True   \n",
       "        galopuba_86 o   21.0        1       False             True   \n",
       "        gubufafu_74 o   16.0        1       False             True   \n",
       "                        20.0        1       False             True   \n",
       "\n",
       "                                                                             \\\n",
       "                                                    used_unrelaxed_df_coord   \n",
       "compenv slab_id     ads active_site att_num from_oh                           \n",
       "nersc   fosurufu_23 o   43.0        1       False                     False   \n",
       "                        45.0        1       False                     False   \n",
       "        galopuba_86 o   21.0        1       False                     False   \n",
       "        gubufafu_74 o   16.0        1       False                     False   \n",
       "                        20.0        1       False                     False   \n",
       "\n",
       "                                                               features  \\\n",
       "                                                    active_o_metal_dist   \n",
       "compenv slab_id     ads active_site att_num from_oh                       \n",
       "nersc   fosurufu_23 o   43.0        1       False              1.757003   \n",
       "                        45.0        1       False              1.751524   \n",
       "        galopuba_86 o   21.0        1       False              1.749184   \n",
       "        gubufafu_74 o   16.0        1       False              1.799507   \n",
       "                        20.0        1       False              1.785505   \n",
       "\n",
       "                                                                              \\\n",
       "                                                    eff_oxid_state ir_o_mean   \n",
       "compenv slab_id     ads active_site att_num from_oh                            \n",
       "nersc   fosurufu_23 o   43.0        1       False         7.333333  1.952891   \n",
       "                        45.0        1       False         7.333333  1.952891   \n",
       "        galopuba_86 o   21.0        1       False         6.000000  1.985623   \n",
       "        gubufafu_74 o   16.0        1       False         8.000000  1.872250   \n",
       "                        20.0        1       False         8.000000  1.872250   \n",
       "\n",
       "                                                                         \\\n",
       "                                                     ir_o_std  octa_vol   \n",
       "compenv slab_id     ads active_site att_num from_oh                       \n",
       "nersc   fosurufu_23 o   43.0        1       False    0.163121  9.310264   \n",
       "                        45.0        1       False    0.163121  9.310264   \n",
       "        galopuba_86 o   21.0        1       False    0.115797  9.719644   \n",
       "        gubufafu_74 o   16.0        1       False    0.068363  8.732127   \n",
       "                        20.0        1       False    0.068363  8.732127   \n",
       "\n",
       "                                                                          \\\n",
       "                                                      dH_bulk  volume_pa   \n",
       "compenv slab_id     ads active_site att_num from_oh                        \n",
       "nersc   fosurufu_23 o   43.0        1       False   -0.595820  13.422324   \n",
       "                        45.0        1       False   -0.595820  13.422324   \n",
       "        galopuba_86 o   21.0        1       False   -0.606853  14.047474   \n",
       "        gubufafu_74 o   16.0        1       False   -0.418717  12.740641   \n",
       "                        20.0        1       False   -0.418717  12.740641   \n",
       "\n",
       "                                                                     \n",
       "                                                    bulk_oxid_state  \n",
       "compenv slab_id     ads active_site att_num from_oh                  \n",
       "nersc   fosurufu_23 o   43.0        1       False                 4  \n",
       "                        45.0        1       False                 4  \n",
       "        galopuba_86 o   21.0        1       False                 4  \n",
       "        gubufafu_74 o   16.0        1       False                 6  \n",
       "                        20.0        1       False                 6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods import get_df_features\n",
    "get_df_features().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "Run time: 0.485 min\n",
      "collect_feature_data.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"collect_feature_data.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_dict = df_dict_i\n",
    "# verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # def tmp_combine_dfs_with_same_cols_2(\n",
    "# #     df_dict=None,\n",
    "# #     verbose=False,\n",
    "# #     ):\n",
    "# \"\"\"\n",
    "# \"\"\"\n",
    "# #| - tmp_combine_dfs_with_same_cols\n",
    "\n",
    "\n",
    "# #| - I\n",
    "# # df_dict = {\n",
    "# #     \"df_eff_ox\": df_eff_ox,\n",
    "# #     \"df_octa_vol\": df_octa_vol,\n",
    "# #     }\n",
    "\n",
    "# all_data_columns = []\n",
    "# for df_name_i, df_i in df_dict.items():\n",
    "#     all_data_columns.extend(df_i[\"data\"].columns.tolist())\n",
    "\n",
    "# repeated_data_cols = []\n",
    "# count_dict = dict(Counter(all_data_columns))\n",
    "# for key, val in count_dict.items():\n",
    "#     if val > 1:\n",
    "#         repeated_data_cols.append(key)\n",
    "\n",
    "# repated_cols_that_are_identical = []\n",
    "# for col_i in repeated_data_cols:\n",
    "\n",
    "#     if verbose:\n",
    "#         print(20 * \"-\")\n",
    "#         print(\"col_i:\", col_i)\n",
    "\n",
    "#     dfs_with_col = []\n",
    "#     for df_name_i, df_i in df_dict.items():\n",
    "#         if col_i in df_i[\"data\"].columns:\n",
    "#             temp_col_name = col_i + \"__\" + df_name_i\n",
    "#             df_tmp = df_i.rename(columns={col_i: temp_col_name, })\n",
    "#             df_tmp = df_tmp.loc[:, [(\"data\", temp_col_name)]]\n",
    "#             dfs_with_col.append(df_tmp)\n",
    "\n",
    "\n",
    "#     df_one_col_comb = pd.concat(dfs_with_col, axis=1)\n",
    "#     df_one_col_comb = df_one_col_comb[\"data\"]\n",
    "\n",
    "#     # #####################################################\n",
    "#     col_pair_equal_check_list = []\n",
    "#     all_col_pairs = list(combinations(df_one_col_comb.columns.tolist(), 2))\n",
    "#     for col_pair_i in all_col_pairs:\n",
    "#         df_one_col_comb_ij = df_one_col_comb[\n",
    "#             list(col_pair_i)\n",
    "#             ]\n",
    "#         df_one_col_comb_ij = df_one_col_comb_ij.dropna()\n",
    "\n",
    "\n",
    "#         col_vals_0 = df_one_col_comb_ij[\n",
    "#             df_one_col_comb_ij.columns[0]\n",
    "#             ]\n",
    "\n",
    "#         col_vals_1 = df_one_col_comb_ij[\n",
    "#             df_one_col_comb_ij.columns[1]\n",
    "#             ]\n",
    "\n",
    "#         col_comparison = (col_vals_0 == col_vals_1)\n",
    "\n",
    "#         all_values_the_same = col_comparison.all()\n",
    "#         col_pair_equal_check_list.append(all_values_the_same)\n",
    "\n",
    "#     # #####################################################\n",
    "#     all_columns_are_the_same = all(col_pair_equal_check_list)\n",
    "#     if all_columns_are_the_same:\n",
    "#         repated_cols_that_are_identical.append(col_i)\n",
    "#         # print(\n",
    "#         #     \"all_columns_are_the_same:\",\n",
    "#         #     all_columns_are_the_same\n",
    "#         #     )\n",
    "#     else:\n",
    "#         if verbose:\n",
    "#             print(\n",
    "#                 \"The duplicated column \",\n",
    "#                 col_i,\n",
    "#                 \" isn't identical across all dataframes\",\n",
    "#                 sep=\"\")\n",
    "\n",
    "\n",
    "# if verbose:\n",
    "#     print(\n",
    "#         \"\\n\",\n",
    "#         \"repated_cols_that_are_identical:\",\n",
    "#         \"\\n\",\n",
    "#         repated_cols_that_are_identical,\n",
    "#         sep=\"\")\n",
    "# #__|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Renaming non-identical shared columns so that there are no duplicate column names\n",
    "# non_identical_repeated_cols = []\n",
    "# for col_i in repeated_data_cols:\n",
    "#     if col_i not in repated_cols_that_are_identical:\n",
    "#         non_identical_repeated_cols.append(col_i)\n",
    "\n",
    "\n",
    "# # #########################################################\n",
    "# for df_name_i, df_i in df_dict.items():\n",
    "\n",
    "#     new_df_columns = []\n",
    "#     for col_j in df_i.columns:\n",
    "\n",
    "#         if col_j[1] in non_identical_repeated_cols:\n",
    "#             col_new = col_j[1] + \"__\" + df_name_i\n",
    "#             col_new_tuple = (col_j[0], col_new)\n",
    "\n",
    "#             new_df_columns.append(col_new_tuple)\n",
    "#         else:\n",
    "#             new_df_columns.append(col_j)\n",
    "\n",
    "#     idx = pd.MultiIndex.from_tuples(new_df_columns)\n",
    "#     df_i.columns = idx\n",
    "\n",
    "#     df_dict[df_name_i] = df_i\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #| - Collating all data for identical columns\n",
    "# collated_column_series_dict = dict()\n",
    "# for col_i in repated_cols_that_are_identical:\n",
    "#     dfs_with_col = []\n",
    "#     for df_name_i, df_i in df_dict.items():\n",
    "#         if col_i in df_i[\"data\"].columns:\n",
    "#             temp_col_name = col_i + \"__\" + df_name_i\n",
    "#             df_tmp = df_i.rename(columns={col_i: temp_col_name, })\n",
    "#             df_tmp = df_tmp.loc[:, [(\"data\", temp_col_name)]]\n",
    "#             dfs_with_col.append(df_tmp)\n",
    "\n",
    "#     df_one_col_comb = pd.concat(dfs_with_col, axis=1)\n",
    "#     df_one_col_comb = df_one_col_comb[\"data\"]\n",
    "\n",
    "#     dfs = []\n",
    "#     for col_j in df_one_col_comb.columns:\n",
    "#         dfs.append(df_one_col_comb[col_j])\n",
    "\n",
    "#     series_i = reduce(lambda l,r: l.combine_first(r), dfs)\n",
    "\n",
    "#     name_i = series_i.name\n",
    "#     name_orig_i = name_i.split(\"__\")[0]\n",
    "\n",
    "#     series_i.name = name_orig_i\n",
    "\n",
    "#     # print(series_i.shape)\n",
    "#     collated_column_series_dict[col_i] = series_i\n",
    "# #__|\n",
    "\n",
    "\n",
    "# #| - Deleting identical columns from all dataframes\n",
    "# for col_i in repated_cols_that_are_identical:\n",
    "\n",
    "#     found_col_in_df_cnt = 0\n",
    "#     for j_cnt, (df_name_j, df_j) in enumerate(df_dict.items()):\n",
    "\n",
    "#         if col_i in df_j[\"data\"].columns:\n",
    "#             # if found_col_in_df_cnt > 0:\n",
    "#             df_j_new = df_j.drop([(\"data\", col_i)], axis=1)\n",
    "#             df_dict[df_name_j] = df_j_new\n",
    "\n",
    "#             found_col_in_df_cnt += 1\n",
    "# #__|\n",
    "\n",
    "\n",
    "# # Combine dataframes\n",
    "# df_features = pd.concat(\n",
    "#     list(df_dict.values()),\n",
    "#     axis=1)\n",
    "\n",
    "\n",
    "# # Adding backin the processed identical columns\n",
    "# for col_i, series_i in collated_column_series_dict.items():\n",
    "#     # series_i = collated_column_series_dict[\"from_oh\"]\n",
    "#     df_series_i = series_i.to_frame()\n",
    "#     df_series_i.columns = pd.MultiIndex.from_tuples([(\"data\", col_i)])\n",
    "\n",
    "#     df_features = pd.concat([df_features, df_series_i], axis=1)\n",
    "\n",
    "# df_features = df_features.reindex(columns = [\"data\", \"features\", ], level=0)\n",
    "\n",
    "\n",
    "# # Sorting columns\n",
    "# columns_list_new = []\n",
    "# identical_cols = []\n",
    "# for col_i in sorted(df_features.columns):\n",
    "#     if col_i[1] in repated_cols_that_are_identical:\n",
    "#         identical_cols.append(col_i)\n",
    "#     else:\n",
    "#         columns_list_new.append(col_i)\n",
    "\n",
    "# identical_cols.extend(columns_list_new)\n",
    "# df_features = df_features.reindex(identical_cols, axis=1)\n",
    "\n",
    "\n",
    "# # df_features_data =\n",
    "# # df_features_data.reindex(sorted(df_features_data.columns), axis=1)\n",
    "\n",
    "# # sorted(df_features_data.columns)\n",
    "\n",
    "\n",
    "\n",
    "# # return(df_features)\n",
    "# #__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# dfs_with_col[1].shape\n",
    "\n",
    "# dfs_with_col[0].shape\n",
    "\n",
    "# df_tmp = dfs_with_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_tmp.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # df_tmp[df_tmp.index.duplicated()]\n",
    "\n",
    "# df_tmp[\n",
    "#     df_tmp.index.duplicated(keep=False)\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_eff_ox\n",
    "# df_octa_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from local_methods import tmp_combine_dfs_with_same_cols\n",
    "# from local_methods import tmp_combine_dfs_with_same_cols_1\n",
    "# from local_methods import tmp_combine_dfs_with_same_cols_2\n",
    "\n",
    "# df_features_comb = tmp_combine_dfs_with_same_cols(\n",
    "# df_features_comb = tmp_combine_dfs_with_same_cols_1(\n",
    "# df_features_comb = tmp_combine_dfs_with_same_cols_2("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print(222 * \"TEMP | \")\n",
    "# assert False"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
