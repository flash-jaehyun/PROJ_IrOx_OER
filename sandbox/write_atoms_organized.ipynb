{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing data objects to file in a convienent and organized way\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/sandbox\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ase import io\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import (\n",
    "    get_df_jobs_paths,\n",
    "    get_df_dft,\n",
    "    get_df_job_ids,\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_data,\n",
    "    get_df_slab,\n",
    "    get_df_slab_ids,\n",
    "    get_df_jobs_data_clusters,\n",
    "    get_df_jobs_anal,\n",
    "    get_df_slabs_oh,\n",
    "    get_df_init_slabs,\n",
    "    get_df_magmoms,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dft = get_df_dft()\n",
    "df_job_ids = get_df_job_ids()\n",
    "df_jobs = get_df_jobs(exclude_wsl_paths=True)\n",
    "df_jobs_data = get_df_jobs_data(exclude_wsl_paths=True)\n",
    "df_jobs_data_clusters = get_df_jobs_data_clusters()\n",
    "df_slab = get_df_slab()\n",
    "df_slab_ids = get_df_slab_ids()\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_paths = get_df_jobs_paths()\n",
    "df_slabs_oh = get_df_slabs_oh()\n",
    "df_init_slabs = get_df_init_slabs()\n",
    "df_magmoms = get_df_magmoms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing finished *O slabs to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal_i = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "var = \"o\"\n",
    "df_jobs_anal_i = df_jobs_anal_i.query('ads == @var')\n",
    "\n",
    "for i_cnt, (name_i, row_i) in enumerate(df_jobs_anal_i.iterrows()):\n",
    "\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    ads_i = name_i[2]\n",
    "    active_site_i = name_i[3]\n",
    "    att_num_i = name_i[4]\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_paths_i = df_jobs_paths.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    gdrive_path = row_paths_i.gdrive_path\n",
    "    # #####################################################\n",
    "\n",
    "    in_dir = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer_gdrive\"],\n",
    "        gdrive_path)\n",
    "    in_path = os.path.join(in_dir, \"final_with_calculator.traj\")\n",
    "\n",
    "    out_dir = os.path.join(\"out_data/completed_O_slabs\")\n",
    "    # out_file = str(i_cnt).zfill(3) + \"_\" + job_id_max_i + \".traj\"\n",
    "    out_file = str(i_cnt).zfill(3) + \"_\" + compenv_i + \"_\" + slab_id_i + \"_\" + str(att_num_i).zfill(2) + \".traj\"\n",
    "    out_path = os.path.join(out_dir, out_file)\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    shutil.copyfile(\n",
    "        in_path,\n",
    "        out_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write OER sets to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_oer_groups\n",
    "\n",
    "df_oer_groups = get_df_oer_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"vinamepa_43\" in df_oer_groups.slab_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/anaconda3/envs/PROJ_irox_oer/lib/python3.6/site-packages/ase/io/jsonio.py:122: VisibleDeprecationWarning:\n",
      "\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "# #########################################################\n",
    "for name_i, row_i in df_oer_groups.iterrows():\n",
    "\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    active_site_i = name_i[2]\n",
    "    # #####################################################\n",
    "    df_jobs_anal_index_i = row_i.df_jobs_anal_index\n",
    "    # #####################################################\n",
    "\n",
    "    # Create directory\n",
    "    folder_i = compenv_i + \"_\" + slab_id_i + \"_\" + str(int(active_site_i)).zfill(3)\n",
    "    out_dir = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"sandbox\",\n",
    "        \"out_data/oer_sets\",\n",
    "        folder_i)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    df_jobs_anal_i = df_jobs_anal.loc[df_jobs_anal_index_i]\n",
    "    # #####################################################\n",
    "    for name_j, row_j in df_jobs_anal_i.iterrows():\n",
    "\n",
    "        # #################################################\n",
    "        compenv_j = name_j[0]\n",
    "        slab_id_j = name_j[1]\n",
    "        ads_j = name_j[2]\n",
    "        active_site_j = name_j[3]\n",
    "        att_num_j = name_j[4]\n",
    "        # #################################################\n",
    "        job_id_max_i = row_j.job_id_max\n",
    "        # #################################################\n",
    "\n",
    "        # #################################################\n",
    "        row_paths_i =  df_jobs_paths.loc[job_id_max_i]\n",
    "        # #################################################\n",
    "        gdrive_path_i = row_paths_i.gdrive_path\n",
    "        # #################################################\n",
    "\n",
    "        # #################################################\n",
    "        # Copy final_with_calculator.traj to local dirs\n",
    "        in_dir = os.path.join(\n",
    "            os.environ[\"PROJ_irox_oer_gdrive\"],\n",
    "            gdrive_path_i)\n",
    "        in_path = os.path.join(\n",
    "            in_dir,\n",
    "            \"final_with_calculator.traj\")\n",
    "\n",
    "        # file_name_j = ads_j + \"_\" + str(att_num_j).zfill(2) + \".traj\"\n",
    "        file_name_j = ads_j + \"_\" + str(att_num_j).zfill(2)\n",
    "        out_path = os.path.join(\n",
    "            out_dir,\n",
    "            file_name_j + \".traj\")\n",
    "\n",
    "        shutil.copyfile(\n",
    "            in_path,\n",
    "            out_path,\n",
    "            )\n",
    "\n",
    "        # #################################################\n",
    "        # Write .cif version\n",
    "        atoms_i = io.read(in_path)\n",
    "        atoms_i.write(os.path.join(out_dir, file_name_j + \".cif\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# compenv_i = name_i[0]\n",
    "# slab_id_i = name_i[1]\n",
    "# active_site_i = name_i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# group_wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# group_wo.reset_index(level=[\"compenv\", \"slab_id\", \"active_site\", ])\n",
    "\n",
    "# group_wo.reset_index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_jobs_anal_i = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "# # var = \"o\"\n",
    "# # df_jobs_anal_i = df_jobs_anal_i.query('ads == @var')\n",
    "\n",
    "# for i_cnt, (name_i, row_i) in enumerate(df_jobs_anal_i.iterrows()):\n",
    "\n",
    "#     # #####################################################\n",
    "#     compenv_i = name_i[0]\n",
    "#     slab_id_i = name_i[1]\n",
    "#     ads_i = name_i[2]\n",
    "#     active_site_i = name_i[3]\n",
    "#     att_num_i = name_i[4]\n",
    "#     # #####################################################\n",
    "\n",
    "#     # #####################################################\n",
    "#     job_id_max_i = row_i.job_id_max\n",
    "#     # #####################################################\n",
    "\n",
    "#     # #####################################################\n",
    "#     row_paths_i = df_jobs_paths.loc[job_id_max_i]\n",
    "#     # #####################################################\n",
    "#     gdrive_path = row_paths_i.gdrive_path\n",
    "#     # #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_jobs_anal_done = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "# var = \"o\"\n",
    "# df_jobs_anal_i = df_jobs_anal_done.query('ads != @var')\n",
    "\n",
    "# # #########################################################\n",
    "# data_dict_list = []\n",
    "# # #########################################################\n",
    "# grouped = df_jobs_anal_i.groupby([\"compenv\", \"slab_id\", \"active_site\", ])\n",
    "# for name, group in grouped:\n",
    "#     data_dict_i = dict()\n",
    "\n",
    "#     # #####################################################\n",
    "#     compenv_i = name[0]\n",
    "#     slab_id_i = name[1]\n",
    "#     active_site_i = name[2]\n",
    "#     # #####################################################\n",
    "\n",
    "#     idx = pd.IndexSlice\n",
    "#     df_jobs_anal_o = df_jobs_anal_done.loc[\n",
    "#         idx[compenv_i, slab_id_i, \"o\", \"NaN\", :],\n",
    "#         ]\n",
    "\n",
    "#     # #########################################################\n",
    "#     group_wo = pd.concat([\n",
    "#         df_jobs_anal_o,\n",
    "#         group,\n",
    "#         ])\n",
    "\n",
    "#     # display(group_wo)\n",
    "\n",
    "#     # #########################################################\n",
    "#     df_jobs_anal_index = group_wo.index.tolist()\n",
    "\n",
    "\n",
    "#     # #########################################################\n",
    "#     df_index_i = group_wo.index.to_frame()\n",
    "\n",
    "#     ads_list = df_index_i.ads.tolist()\n",
    "#     ads_list_unique = list(set(ads_list))\n",
    "\n",
    "#     o_present = \"o\" in ads_list_unique\n",
    "#     oh_present = \"oh\" in ads_list_unique\n",
    "#     bare_present = \"bare\" in ads_list_unique\n",
    "\n",
    "#     all_ads_present = False\n",
    "#     if o_present and oh_present and bare_present:\n",
    "#         all_ads_present = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # #####################################################\n",
    "#     data_dict_i[\"compenv\"] = compenv_i\n",
    "#     data_dict_i[\"slab_id\"] = slab_id_i\n",
    "#     data_dict_i[\"active_site\"] = active_site_i\n",
    "#     data_dict_i[\"df_jobs_anal_index\"] = df_jobs_anal_index\n",
    "#     data_dict_i[\"ads_list\"] = ads_list\n",
    "#     data_dict_i[\"all_ads_present\"] = all_ads_present\n",
    "#     # data_dict_i[\"\"] = \n",
    "#     # #####################################################\n",
    "#     data_dict_list.append(data_dict_i)\n",
    "#     # #####################################################\n",
    "\n",
    "# # #########################################################\n",
    "# df_oer_groups = pd.DataFrame(data_dict_list)\n",
    "# df_oer_groups = df_oer_groups.set_index([\"compenv\", \"slab_id\", \"active_site\"], drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_oer_groups.head()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
