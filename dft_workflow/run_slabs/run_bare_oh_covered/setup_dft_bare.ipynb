{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/run_slabs/run_bare_oh_covered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import pickle\n",
    "from shutil import copyfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import MultiIndex\n",
    "\n",
    "from ase import io\n",
    "\n",
    "# # from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_slab,\n",
    "    get_df_slabs_to_run,\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_anal,\n",
    "    get_df_jobs_data,\n",
    "    get_df_jobs_paths,\n",
    "    get_df_active_sites,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    )\n",
    "\n",
    "# #########################################################\n",
    "from dft_workflow_methods import get_job_spec_dft_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slac queue to submit to\n",
    "slac_sub_queue_i = \"suncat2\"  # 'suncat', 'suncat2', 'suncat3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_slab = get_df_slab()\n",
    "df_slab = df_slab.set_index(\"slab_id\")\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "# #########################################################\n",
    "df_jobs = get_df_jobs()\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "\n",
    "# #########################################################\n",
    "df_active_sites = get_df_active_sites()\n",
    "\n",
    "# #########################################################\n",
    "df_slabs_to_run = get_df_slabs_to_run()\n",
    "\n",
    "# #########################################################\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"out_data/dft_jobs\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "directory = \"__temp__\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "compenv = os.environ[\"COMPENV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "var = \"o\"\n",
    "df_jobs_anal = df_jobs_anal.query('ads == @var')\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal_completed = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "# df_jobs_anal_completed = df_jobs_anal_completed[\n",
    "#     [\"compenv\", \"slab_id\", \"job_id_max_i\", \"att_num\", ]]\n",
    "\n",
    "df_jobs_anal_completed = df_jobs_anal_completed[[\"job_id_max\", ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index_i = df_jobs_anal_completed.index.to_frame()\n",
    "\n",
    "compenv__slab_id__att_num__tuple = tuple(zip(\n",
    "    df_index_i.compenv,\n",
    "    df_index_i.slab_id,\n",
    "    df_index_i.att_num,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal_completed[\"compenv__slab_id__att_num\"] = compenv__slab_id__att_num__tuple\n",
    "df_jobs_anal_completed = df_jobs_anal_completed.set_index(\"compenv__slab_id__att_num\", drop=False)\n",
    "\n",
    "# #########################################################\n",
    "compenv__slab_id__att_num__tuple = tuple(zip(\n",
    "    df_slabs_to_run.compenv,\n",
    "    df_slabs_to_run.slab_id,\n",
    "    df_slabs_to_run.att_num,\n",
    "    ))\n",
    "\n",
    "df_slabs_to_run[\"compenv__slab_id__att_num\"] = compenv__slab_id__att_num__tuple\n",
    "df_slabs_to_run = df_slabs_to_run.set_index(\"compenv__slab_id__att_num\", drop=False)\n",
    "\n",
    "# #########################################################\n",
    "df_i = pd.concat([\n",
    "    df_slabs_to_run.status,\n",
    "    df_jobs_anal_completed,\n",
    "    ], axis=1)\n",
    "\n",
    "df_i = df_i.sort_index()\n",
    "\n",
    "df_i = df_i[\n",
    "    (df_i.status == \"ok\")\n",
    "    ]\n",
    "\n",
    "ind = MultiIndex.from_tuples(\n",
    "    df_i.index, sortorder=None,\n",
    "    names=[\"compenv\", \"slab_id\", \"att_num\", ])\n",
    "df_i = df_i.set_index(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #########################################################\n",
    "# print(\"TEMP TEMP TEMP\")\n",
    "# # #########################################################\n",
    "\n",
    "# compenv_i, slab_id_i, att_num_i  = ('slac', 'garituna_73', 1)\n",
    "# df_i = df_i.loc[\n",
    "#     [(compenv_i, slab_id_i, att_num_i)]\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nersc', 'gubufafu_74', 1) | 16 | /home/raulf2012/rclone_temp/PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/nersc/7qxq8lce9u/010/bare/active_site__16/01_attempt/_01\n",
      "('nersc', 'gubufafu_74', 1) | 20 | /home/raulf2012/rclone_temp/PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/nersc/7qxq8lce9u/010/bare/active_site__20/01_attempt/_01\n"
     ]
    }
   ],
   "source": [
    "verbose_local = False\n",
    "\n",
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "for name_i, row_i in df_i.iterrows():\n",
    "\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    att_num_i = name_i[2]\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    df_jobs_i = df_jobs[df_jobs.compenv == compenv_i]\n",
    "    row_jobs_i = df_jobs_i[df_jobs_i.job_id == job_id_max_i]\n",
    "    row_jobs_i = row_jobs_i.iloc[0]\n",
    "    # #####################################################\n",
    "    att_num_i = row_jobs_i.att_num\n",
    "    bulk_id_i = row_jobs_i.bulk_id\n",
    "    facet_i = row_jobs_i.facet\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    df_jobs_data_i = df_jobs_data[df_jobs_data.compenv == compenv_i]\n",
    "    row_data_i = df_jobs_data_i[df_jobs_data_i.job_id == job_id_max_i]\n",
    "    row_data_i = row_data_i.iloc[0]\n",
    "    # #####################################################\n",
    "    slab_i = row_data_i.final_atoms\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_active_site_i = df_active_sites[df_active_sites.slab_id == slab_id_i]\n",
    "    row_active_site_i = row_active_site_i.iloc[0]\n",
    "    # #####################################################\n",
    "    active_sites_unique_i = row_active_site_i.active_sites_unique\n",
    "    num_active_sites_unique_i = row_active_site_i.num_active_sites_unique\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    # row_atoms_sorted_i = df_atoms_sorted_ind.loc[(compenv_i, slab_id_i, att_num_i)]\n",
    "    index_atoms_sorted_i = (compenv_i, slab_id_i, \"o\", \"NaN\", att_num_i, )\n",
    "    row_atoms_sorted_i = df_atoms_sorted_ind.loc[index_atoms_sorted_i]\n",
    "    # #####################################################\n",
    "    atoms_sorted_i = row_atoms_sorted_i.atoms_sorted_good\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "    for active_site_j in active_sites_unique_i:\n",
    "        data_dict_i = dict()\n",
    "\n",
    "        if verbose_local:\n",
    "            print(40 * \"=\")\n",
    "            print(\"active_site_j:\", active_site_j)\n",
    "\n",
    "        # #####################################################\n",
    "        rev = 1\n",
    "        path_i = os.path.join(\n",
    "            \"out_data/dft_jobs\", \n",
    "            compenv_i, bulk_id_i, facet_i,\n",
    "            \"bare\", \"active_site__\" + str(active_site_j).zfill(2),\n",
    "            str(att_num_i).zfill(2) + \"_attempt\",  # Attempt\n",
    "            \"_\" + str(rev).zfill(2),  # Revision\n",
    "            )\n",
    "\n",
    "        root_frag = \"dft_workflow/run_slabs/run_bare_oh_covered\"\n",
    "        path_full = os.path.join(\n",
    "            os.environ[\"PROJ_irox_oer_gdrive\"],\n",
    "            root_frag,\n",
    "            path_i)\n",
    "\n",
    "        if not os.path.exists(path_full):\n",
    "            print(name_i, \"|\", active_site_j, \"|\", path_full)\n",
    "            os.makedirs(path_full)\n",
    "\n",
    "            # #############################################\n",
    "            # Copy dft script to job folder\n",
    "            copyfile(\n",
    "                os.path.join(os.environ[\"PROJ_irox_oer\"], \"dft_workflow/dft_scripts/slab_dft.py\"),\n",
    "                os.path.join(path_full, \"model.py\"),\n",
    "                )\n",
    "\n",
    "            # #############################################\n",
    "            # Removing atom to create \n",
    "            atoms_sorted_cpy_i = copy.deepcopy(atoms_sorted_i)\n",
    "            atoms_sorted_cpy_i.pop(i=active_site_j)\n",
    "            slab_bare_i = atoms_sorted_cpy_i\n",
    "\n",
    "            # #############################################\n",
    "            # Copy atoms object to job folder\n",
    "            slab_bare_i.write(\n",
    "                os.path.join(path_full, \"init.traj\")\n",
    "                )\n",
    "            num_atoms_i = slab_bare_i.get_global_number_of_atoms()\n",
    "\n",
    "            # #############################################\n",
    "            data_dict_i[\"compenv\"] = compenv_i\n",
    "            data_dict_i[\"slab_id\"] = slab_id_i\n",
    "            data_dict_i[\"bulk_id\"] = bulk_id_i\n",
    "            data_dict_i[\"att_num\"] = att_num_i\n",
    "            data_dict_i[\"rev_num\"] = rev\n",
    "            data_dict_i[\"active_site\"] = active_site_j\n",
    "            data_dict_i[\"facet\"] = facet_i\n",
    "            data_dict_i[\"slab_bare\"] = slab_bare_i\n",
    "            data_dict_i[\"num_atoms\"] = num_atoms_i\n",
    "            data_dict_i[\"path_i\"] = path_i\n",
    "            data_dict_i[\"path_full\"] = path_full\n",
    "            # #############################################\n",
    "            data_dict_list.append(data_dict_i)\n",
    "            # #############################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_new = pd.DataFrame(data_dict_list)\n",
    "# df_jobs_new = df_jobs_new.set_index(\"slab_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compenv</th>\n",
       "      <th>slab_id</th>\n",
       "      <th>bulk_id</th>\n",
       "      <th>att_num</th>\n",
       "      <th>rev_num</th>\n",
       "      <th>active_site</th>\n",
       "      <th>facet</th>\n",
       "      <th>slab_bare</th>\n",
       "      <th>num_atoms</th>\n",
       "      <th>path_i</th>\n",
       "      <th>path_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nersc</td>\n",
       "      <td>gubufafu_74</td>\n",
       "      <td>7qxq8lce9u</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>010</td>\n",
       "      <td>(Atom('O', [2.7974475, 2.938605, 7.50000000000...</td>\n",
       "      <td>83</td>\n",
       "      <td>out_data/dft_jobs/nersc/7qxq8lce9u/010/bare/ac...</td>\n",
       "      <td>/home/raulf2012/rclone_temp/PROJ_irox_oer/dft_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nersc</td>\n",
       "      <td>gubufafu_74</td>\n",
       "      <td>7qxq8lce9u</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>010</td>\n",
       "      <td>(Atom('O', [2.7974475, 2.938605, 7.50000000000...</td>\n",
       "      <td>83</td>\n",
       "      <td>out_data/dft_jobs/nersc/7qxq8lce9u/010/bare/ac...</td>\n",
       "      <td>/home/raulf2012/rclone_temp/PROJ_irox_oer/dft_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  compenv      slab_id     bulk_id  att_num  rev_num  active_site facet  \\\n",
       "0   nersc  gubufafu_74  7qxq8lce9u        1        1           16   010   \n",
       "1   nersc  gubufafu_74  7qxq8lce9u        1        1           20   010   \n",
       "\n",
       "                                           slab_bare  num_atoms  \\\n",
       "0  (Atom('O', [2.7974475, 2.938605, 7.50000000000...         83   \n",
       "1  (Atom('O', [2.7974475, 2.938605, 7.50000000000...         83   \n",
       "\n",
       "                                              path_i  \\\n",
       "0  out_data/dft_jobs/nersc/7qxq8lce9u/010/bare/ac...   \n",
       "1  out_data/dft_jobs/nersc/7qxq8lce9u/010/bare/ac...   \n",
       "\n",
       "                                           path_full  \n",
       "0  /home/raulf2012/rclone_temp/PROJ_irox_oer/dft_...  \n",
       "1  /home/raulf2012/rclone_temp/PROJ_irox_oer/dft_...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty dataframe with columns if dataframe is empty\n",
    "if df_jobs_new.shape[0] == 0:\n",
    "    df_jobs_new = pd.DataFrame(\n",
    "        columns=[\"compenv\", \"slab_id\", \"att_num\", \"active_site\", ])\n",
    "\n",
    "# df_jobs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_new[\"compenv__slab_id__att_num__active_site\"] = list(zip(\n",
    "    df_jobs_new.compenv,\n",
    "    df_jobs_new.slab_id,\n",
    "    df_jobs_new.att_num,\n",
    "    df_jobs_new.active_site))\n",
    "\n",
    "df_jobs_new = df_jobs_new.set_index(\"compenv__slab_id__att_num__active_site\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "for i_cnt, row_i in df_jobs_new.iterrows():\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    compenv__slab_id__att_num__active_site_i = row_i.name\n",
    "    compenv_i, slab_id_i, att_num_i, active_site_i = row_i.name\n",
    "\n",
    "    compenv_i = row_i.compenv\n",
    "    num_atoms = row_i.num_atoms\n",
    "    path_i = row_i.path_i\n",
    "    path_full = row_i.path_full\n",
    "    # ####################################################\n",
    "    dft_params_i = get_job_spec_dft_params(\n",
    "        compenv=compenv_i,\n",
    "        slac_sub_queue=slac_sub_queue_i,\n",
    "        )\n",
    "    dft_params_i[\"ispin\"] = 2\n",
    "\n",
    "    # #####################################################\n",
    "    with open(os.path.join(path_full, \"dft-params.json\"), \"w+\") as fle:\n",
    "        json.dump(dft_params_i, fle, indent=2, skipkeys=True)\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"compenv\"] = compenv_i\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "    data_dict_i[\"att_num\"] = att_num_i\n",
    "    data_dict_i[\"active_site\"] = active_site_i\n",
    "    data_dict_i[\"compenv__slab_id__att_num__active_site\"] = \\\n",
    "        compenv__slab_id__att_num__active_site_i\n",
    "    data_dict_i[\"dft_params\"] = dft_params_i\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_dft_params = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# Create empty dataframe with columns if dataframe is empty\n",
    "if df_dft_params.shape[0] == 0:\n",
    "    df_dft_params = pd.DataFrame(columns=[\"compenv\", \"slab_id\", \"att_num\", \"active_site\", ])\n",
    "\n",
    "keys = [\"compenv\", \"slab_id\", \"att_num\", \"active_site\"]\n",
    "df_dft_params = df_dft_params.set_index(keys, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "setup_dft.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"setup_dft.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# assert False\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# compenv_i\n",
    "\n",
    "# #     dft_params_i = \n",
    "# get_job_spec_dft_params(\n",
    "#     compenv=compenv_i,\n",
    "#     slac_sub_queue=slac_sub_queue_i,\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
