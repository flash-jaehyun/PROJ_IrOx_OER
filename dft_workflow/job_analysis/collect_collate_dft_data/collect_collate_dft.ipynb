{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect DFT data into *, *O, *OH collections\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.options.display.max_colwidth = 100\n",
    "import numpy as np\n",
    "\n",
    "# #########################################################\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_jobs_anal\n",
    "from methods import get_df_jobs_data\n",
    "from methods import get_df_slabs_to_run\n",
    "from methods import get_df_jobs_oh_anal\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import calc_ads_e\n",
    "from local_methods import get_oer_triplet\n",
    "from local_methods import get_group_w_all_ads, are_any_ads_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_slabs_to_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_anal_i = df_jobs_anal\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "# #########################################################\n",
    "df_slabs_to_run = get_df_slabs_to_run()\n",
    "df_slabs_to_run = df_slabs_to_run.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"att_num\"], drop=False)\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_oh_anal = get_df_jobs_oh_anal()\n",
    "df_jobs_oh_anal = df_jobs_oh_anal.set_index([\"compenv\", \"slab_id\", \"active_site\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs_oh_anal\n",
    "# get_df_jobs_anal()\n",
    "\n",
    "# get_df_jobs_oh_anal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_modules.pandas_methods import drop_columns\n",
    "\n",
    "cols_to_keep = [\n",
    "    'job_id_max',\n",
    "    # 'timed_out',\n",
    "    # 'completed',\n",
    "    # 'brmix_issue',\n",
    "    # 'job_understandable',\n",
    "    # 'decision',\n",
    "    # 'dft_params_new',\n",
    "    'job_completely_done',\n",
    "    ]\n",
    "\n",
    "df_jobs_anal_i = drop_columns(\n",
    "    df=df_jobs_anal_i,\n",
    "    columns=cols_to_keep,\n",
    "    keep_or_drop=\"keep\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafting `pot_e` and `as_is_nan` to dataframe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method(row_i):\n",
    "    # #####################################################\n",
    "    new_column_values_dict = {\n",
    "        \"pot_e\": None,\n",
    "        \"as_is_nan\": None,\n",
    "        }\n",
    "    # #####################################################\n",
    "    compenv_i = row_i.name[0]\n",
    "    slab_id_i = row_i.name[1]\n",
    "    ads_i = row_i.name[2]\n",
    "    active_site_i = row_i.name[3]\n",
    "    att_num_i = row_i.name[4]\n",
    "    # #####################################################\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    job_completely_done_i = row_i.job_completely_done\n",
    "    # #####################################################\n",
    "\n",
    "    as_is_nan = False\n",
    "    if active_site_i == \"NaN\":\n",
    "        as_is_nan = True\n",
    "\n",
    "    # #####################################################\n",
    "    row_data_i = df_jobs_data.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    pot_e_i = row_data_i.pot_e\n",
    "    rerun_from_oh_i = row_data_i.rerun_from_oh\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    new_column_values_dict[\"pot_e\"] = pot_e_i\n",
    "    new_column_values_dict[\"as_is_nan\"] = as_is_nan\n",
    "    new_column_values_dict[\"rerun_from_oh\"] = rerun_from_oh_i\n",
    "    # #####################################################\n",
    "    for key, value in new_column_values_dict.items():\n",
    "        row_i[key] = value\n",
    "    # #####################################################\n",
    "    return(row_i)\n",
    "\n",
    "df_jobs_anal_i = df_jobs_anal_i.apply(\n",
    "    method,\n",
    "    axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# Only completed jobs will be considered\n",
    "df_jobs_anal_i = df_jobs_anal_i[df_jobs_anal_i.job_completely_done == True]\n",
    "\n",
    "# #########################################################\n",
    "# Remove the *O slabs for now\n",
    "# The fact that they have NaN active sites will mess up the groupby\n",
    "ads_list = df_jobs_anal_i.index.get_level_values(\"ads\").tolist()\n",
    "ads_list_no_o = [i for i in list(set(ads_list)) if i != \"o\"]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "df_jobs_anal_no_o = df_jobs_anal_i.loc[idx[:, :, ads_list_no_o, :, :], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "groupby_cols = [\"compenv\", \"slab_id\", \"active_site\", ]\n",
    "grouped = df_jobs_anal_no_o.groupby(groupby_cols)\n",
    "for name_i, group in grouped:\n",
    "\n",
    "# for i in range(1):\n",
    "#     # name_i = ('sherlock', 'vuvunira_55', 73.0)\n",
    "#     # name_i = ('slac', 'waloguhe_35', 65.0)\n",
    "#     name_i = (\"slac\", \"kalisule_45\", 68.0)\n",
    "#     group = grouped.get_group(name_i)\n",
    "\n",
    "    # #####################################################\n",
    "    ads_e_o_i = None\n",
    "    ads_e_oh_i = None\n",
    "    job_id_o_i = None\n",
    "    job_id_oh_i  = None\n",
    "    job_id_bare_i = None\n",
    "    all_jobs_in_group_done = None\n",
    "    any_bare_done = None\n",
    "    any_oh_done = None\n",
    "    any_o_done = None\n",
    "    any_o_done_with_active_sites = None\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(groupby_cols, name_i))\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    active_site_i = name_i[2]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "    out_dict = get_group_w_all_ads(\n",
    "        name=name_i,\n",
    "        group=group,\n",
    "        df_jobs_anal_i=df_jobs_anal_i,\n",
    "        )\n",
    "    group_i = out_dict[\"group_i\"]\n",
    "    any_o_done_with_active_sites = out_dict[\"any_o_done_with_active_sites\"]\n",
    "\n",
    "\n",
    "    all_jobs_in_group_done = group_i.job_completely_done.all()\n",
    "\n",
    "\n",
    "    out_dict = are_any_ads_done(\n",
    "        group=group_i,\n",
    "        )\n",
    "    any_o_done = out_dict[\"any_o_done\"]\n",
    "    any_oh_done = out_dict[\"any_oh_done\"]\n",
    "    any_bare_done = out_dict[\"any_bare_done\"]\n",
    "\n",
    "\n",
    "    # TEMP\n",
    "    for i in group_i.pot_e.tolist():\n",
    "        if type(i) != float:\n",
    "            print(\"8asdihydfsd908f: \", name_i)\n",
    "\n",
    "\n",
    "    oer_trip_i = get_oer_triplet(\n",
    "        name=name_i,\n",
    "        group=group_i,\n",
    "        df_jobs_oh_anal=df_jobs_oh_anal,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Checking if *O is avail and get job id\n",
    "    o_avail = \"o\" in oer_trip_i.index.to_frame()[\"ads\"].tolist()\n",
    "    if o_avail:\n",
    "        idx = pd.IndexSlice\n",
    "        row_o_i = oer_trip_i.loc[idx[:, :, \"o\", :, :], :].iloc[0]\n",
    "        job_id_o_i = row_o_i.job_id_max\n",
    "    else:\n",
    "        ads_e_o_i = None\n",
    "        job_id_o_i = None\n",
    "\n",
    "    # #####################################################\n",
    "    # Checking if *OH is avail and get job id\n",
    "    oh_avail = \"oh\" in oer_trip_i.index.to_frame()[\"ads\"].tolist()\n",
    "    if oh_avail:\n",
    "        idx = pd.IndexSlice\n",
    "        row_oh_i = oer_trip_i.loc[idx[:, :, \"oh\", :, :], :].iloc[0]\n",
    "        job_id_oh_i = row_oh_i.job_id_max\n",
    "    else:\n",
    "        ads_e_oh_i = None\n",
    "        job_id_oh_i = None\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Can only compute adsorption energies if bare (*) is avail\n",
    "    bare_avail = \"bare\" in oer_trip_i.index.to_frame()[\"ads\"].tolist()\n",
    "    if bare_avail:\n",
    "        idx = pd.IndexSlice\n",
    "        row_bare_i = oer_trip_i.loc[idx[:, :, \"bare\", :, :], :].iloc[0]\n",
    "        job_id_bare_i = row_bare_i.job_id_max\n",
    "\n",
    "\n",
    "        df_ads_i = calc_ads_e(oer_trip_i.reset_index())\n",
    "        df_ads_i = df_ads_i.set_index(\"ads\", drop=False)\n",
    "\n",
    "        ads_e_o_i = df_ads_i.loc[\"o\"][\"ads_e\"]\n",
    "\n",
    "        if \"oh\" in df_ads_i.index:\n",
    "            ads_e_oh_i = df_ads_i.loc[\"oh\"][\"ads_e\"]\n",
    "            job_id_oh_i = df_ads_i.loc[\"oh\"][\"job_id_max\"]\n",
    "        else:\n",
    "            ads_e_oh_i = None\n",
    "            job_id_oh_i = None\n",
    "\n",
    "    else:\n",
    "        job_id_bare_i = None\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i.update(name_dict_i)\n",
    "    # #####################################################\n",
    "    data_dict_i[\"g_o\"] = ads_e_o_i\n",
    "    data_dict_i[\"g_oh\"] = ads_e_oh_i\n",
    "    data_dict_i[\"job_id_o\"] = job_id_o_i\n",
    "    data_dict_i[\"job_id_oh\"] = job_id_oh_i \n",
    "    data_dict_i[\"job_id_bare\"] = job_id_bare_i\n",
    "    data_dict_i[\"all_done\"] = all_jobs_in_group_done\n",
    "    data_dict_i[\"any_bare_done\"] = any_bare_done\n",
    "    data_dict_i[\"any_oh_done\"] = any_oh_done\n",
    "    data_dict_i[\"any_o_done\"] = any_o_done\n",
    "    data_dict_i[\"any_o_w_as_done\"] = any_o_done_with_active_sites\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_ads = pd.DataFrame(data_dict_list)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/collect_collate_dft_data\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_ads.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_ads, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_ads\n",
    "\n",
    "df_ads_tmp = get_df_ads()\n",
    "\n",
    "df_ads_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"collect_collate_dft.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
