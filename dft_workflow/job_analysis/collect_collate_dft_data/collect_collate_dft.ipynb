{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect DFT data into *, *O, *OH collections\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/job_analysis/collect_collate_dft_data\n",
      "Divisor is Energy class instance!!!\n",
      "Divisor is Energy class instance!!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.options.display.max_colwidth = 100\n",
    "import numpy as np\n",
    "\n",
    "# #########################################################\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_jobs_anal\n",
    "from methods import get_df_jobs_data\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import calc_ads_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "# verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal = get_df_jobs_anal()\n",
    "\n",
    "df_jobs_data = get_df_jobs_data()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering dataframe for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"TEMP\")\n",
    "\n",
    "# df_index = df_jobs_anal.index.to_frame()\n",
    "\n",
    "# df_jobs_anal = df_jobs_anal.loc[\n",
    "#     df_index[df_index.compenv == \"slac\"].index\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# Only completed jobs will be considered\n",
    "df_jobs_anal_i = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "# #########################################################\n",
    "# Remove the *O slabs for now\n",
    "# The fact that they have NaN active sites will mess up the groupby\n",
    "ads_list = df_jobs_anal_i.index.get_level_values(\"ads\").tolist()\n",
    "ads_list_no_o = [i for i in list(set(ads_list)) if i != \"o\"]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "df_jobs_anal_no_o = df_jobs_anal_i.loc[idx[:, :, ads_list_no_o, :, :], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "('slac', 'fagumoha_68', 63.0)\n",
      "################################################################################\n",
      "\n",
      "****************************************\n",
      "('slac', 'kalisule_45', 62.0)\n",
      "No bare slab available\n",
      "****************************************\n",
      "('slac', 'kalisule_45', 67.0)\n",
      "################################################################################\n",
      "\n",
      "****************************************\n",
      "('slac', 'kalisule_45', 68.0)\n",
      "No bare slab available\n",
      "****************************************\n",
      "('slac', 'kalisule_45', 73.0)\n",
      "################################################################################\n",
      "\n",
      "****************************************\n",
      "('slac', 'mesufagi_19', 32.0)\n",
      "################################################################################\n",
      "\n",
      "****************************************\n",
      "('slac', 'mesufagi_19', 33.0)\n",
      "No bare slab available\n",
      "****************************************\n",
      "('slac', 'pegapali_49', 34.0)\n",
      "No bare slab available\n",
      "****************************************\n",
      "('slac', 'vuraruna_65', 50.0)\n",
      "There is more than 1 row per state here, need a better way to select\n",
      "No bare slab available\n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "verbose_local = True\n",
    "# #########################################################\n",
    "\n",
    "data_dict_list = []\n",
    "groupby_cols = [\"compenv\", \"slab_id\", \"active_site\", ]\n",
    "grouped = df_jobs_anal_no_o.groupby(groupby_cols)\n",
    "for name_i, group in grouped:\n",
    "# for i in range(1):\n",
    "\n",
    "    # group = grouped.get_group(\n",
    "    #     ('slac', 'fagumoha_68', 63.0)\n",
    "    #     )\n",
    "\n",
    "    if verbose_local:\n",
    "        print(40 * \"*\")\n",
    "        print(name_i)\n",
    "\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(groupby_cols, name_i))\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    active_site_i = name_i[2]\n",
    "    # #####################################################\n",
    "\n",
    "    # Selecting the relevent *O slab rows and combining with group\n",
    "    idx = pd.IndexSlice\n",
    "    df_o_slabs = df_jobs_anal_i.loc[idx[compenv_i, slab_id_i, \"o\", :, :], :]\n",
    "\n",
    "    group_i = pd.concat([\n",
    "        df_o_slabs,\n",
    "        group\n",
    "        ])\n",
    "\n",
    "    data_dict_list_j = []\n",
    "    for name_j, row_j in group_i.iterrows():\n",
    "        data_dict_j = dict()\n",
    "\n",
    "        # #################################################\n",
    "        name_dict_j = dict(zip(list(group_i.index.names), name_j))\n",
    "        # #################################################\n",
    "        job_id_max_j = row_j.job_id_max\n",
    "        # #################################################\n",
    "\n",
    "        # #################################################\n",
    "        row_data_j = df_jobs_data.loc[job_id_max_j]\n",
    "        # #################################################\n",
    "        pot_e_j = row_data_j.pot_e\n",
    "        # #################################################\n",
    "\n",
    "        # #################################################\n",
    "        data_dict_j.update(name_dict_j)\n",
    "        data_dict_j[\"pot_e\"] = pot_e_j\n",
    "        data_dict_j[\"job_id_max\"] = job_id_max_j\n",
    "        # #################################################\n",
    "        data_dict_list_j.append(data_dict_j)\n",
    "        # #################################################\n",
    "\n",
    "    df_tmp = pd.DataFrame(data_dict_list_j)\n",
    "    df_tmp = df_tmp.set_index(\n",
    "        [\"compenv\", \"slab_id\", \"ads\", \"active_site\", ],\n",
    "        drop=False)\n",
    "\n",
    "    # #####################################################\n",
    "    df_ads_o = df_tmp[df_tmp.ads == \"o\"]\n",
    "    df_ads_oh = df_tmp[df_tmp.ads == \"oh\"]\n",
    "    df_ads_bare = df_tmp[df_tmp.ads == \"bare\"]\n",
    "\n",
    "    if (df_ads_o.shape[0] > 1) or (df_ads_oh.shape[0] > 1) or (df_ads_bare.shape[0] > 1):\n",
    "        print(\"There is more than 1 row per state here, need a better way to select\")\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # If there isn't a bare * calculation then skip for now\n",
    "    if df_ads_bare.shape[0] == 0:\n",
    "        if verbose_local:\n",
    "            print(\"No bare slab available\")\n",
    "        continue\n",
    "\n",
    "    df_ads_oh = df_ads_oh[df_ads_oh.pot_e == df_ads_oh.pot_e.min()]\n",
    "    df_ads_o = df_ads_o[df_ads_o.pot_e == df_ads_o.pot_e.min()]\n",
    "    df_ads_bare = df_ads_bare[df_ads_bare.pot_e == df_ads_bare.pot_e.min()]\n",
    "\n",
    "    job_id_bare_i = df_ads_bare.iloc[0].job_id_max\n",
    "\n",
    "    df_ads_i = pd.concat([\n",
    "        df_ads_o,\n",
    "        df_ads_oh,\n",
    "        df_ads_bare])\n",
    "    df_ads_i = calc_ads_e(df_ads_i)\n",
    "\n",
    "\n",
    "\n",
    "    # #########################################################\n",
    "    row_oh_i = df_ads_i[df_ads_i.ads == \"oh\"]\n",
    "    if row_oh_i.shape[0] == 1:\n",
    "        row_oh_i = row_oh_i.iloc[0]\n",
    "        # #####################################################\n",
    "        ads_e_oh_i = row_oh_i.ads_e\n",
    "        job_id_oh_i = row_oh_i.job_id_max\n",
    "        # #####################################################\n",
    "    else:\n",
    "        ads_e_oh_i = None\n",
    "        job_id_oh_i = None\n",
    "\n",
    "    # #########################################################\n",
    "    row_o_i = df_ads_i[df_ads_i.ads == \"o\"]\n",
    "    if row_o_i.shape[0] == 1:\n",
    "        row_o_i = row_o_i.iloc[0]\n",
    "        # #####################################################\n",
    "        ads_e_o_i = row_o_i.ads_e\n",
    "        job_id_o_i = row_o_i.job_id_max\n",
    "        # #####################################################\n",
    "    else:\n",
    "        ads_e_o_i = None\n",
    "        job_id_o_i = None\n",
    "\n",
    "\n",
    "\n",
    "    print(80 * \"#\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i.update(name_dict_i)\n",
    "    data_dict_i[\"g_o\"] = ads_e_o_i\n",
    "    data_dict_i[\"g_oh\"] = ads_e_oh_i\n",
    "    data_dict_i[\"job_id_o\"] = job_id_o_i\n",
    "    data_dict_i[\"job_id_oh\"] = job_id_oh_i \n",
    "    data_dict_i[\"job_id_bare\"] = job_id_bare_i\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # display(df_tmp_1)\n",
    "    # if df_ads_i.shape[0] == 3:\n",
    "    #     break\n",
    "\n",
    "\n",
    "    if verbose_local:\n",
    "        print(\"\")\n",
    "\n",
    "# #########################################################\n",
    "df_ads = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# df_ads.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads_i = df_ads[~df_ads.g_oh.isnull()]\n",
    "print(df_ads_i.shape)\n",
    "\n",
    "df_ads_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/collect_collate_dft_data\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_ads.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_ads, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_ads\n",
    "\n",
    "df_ads_tmp = get_df_ads()\n",
    "\n",
    "df_ads_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"analyse_jobs.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_ads\n",
    "\n",
    "# assert False"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
