{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# #########################################################\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs_anal,\n",
    "    get_df_jobs_data,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_init_slabs,\n",
    "    )\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import (\n",
    "    read_magmom_comp_data,\n",
    "    save_magmom_comp_data,\n",
    "    process_group_magmom_comp,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "redo_all_jobs = False\n",
    "# redo_all_jobs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "df_jobs_anal = get_df_jobs_anal()\n",
    "\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "\n",
    "df_init_slabs = get_df_init_slabs()\n",
    "\n",
    "magmom_data_dict = read_magmom_comp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# Only completed jobs will be considered\n",
    "df_jobs_anal_i = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "# #########################################################\n",
    "# Dropping rows that failed atoms sort, now it's just one job that blew up \n",
    "# job_id = \"dubegupi_27\"\n",
    "df_failed_to_sort = df_atoms_sorted_ind[\n",
    "    df_atoms_sorted_ind.failed_to_sort == True]\n",
    "df_jobs_anal_i = df_jobs_anal_i.drop(labels=df_failed_to_sort.index)\n",
    "\n",
    "# #########################################################\n",
    "# Remove the *O slabs for now\n",
    "# The fact that they have NaN active sites will mess up the groupby\n",
    "ads_list = df_jobs_anal_i.index.get_level_values(\"ads\").tolist()\n",
    "ads_list_no_o = [i for i in list(set(ads_list)) if i != \"o\"]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "df_jobs_anal_no_o = df_jobs_anal_i.loc[idx[:, :, ads_list_no_o, :, :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "indices_to_keep = []\n",
    "groupby_cols = [\"compenv\", \"slab_id\", \"active_site\", ]\n",
    "grouped = df_jobs_anal_no_o.groupby(groupby_cols)\n",
    "for name_i, group in grouped:\n",
    "    group_index = group.index.to_frame()\n",
    "    ads_list = list(group_index.ads.unique())\n",
    "    oh_present = \"oh\" in ads_list\n",
    "    bare_present = \"bare\" in ads_list\n",
    "    all_req_ads_present = oh_present and bare_present\n",
    "    if all_req_ads_present:\n",
    "        indices_to_keep.extend(group.index.tolist())\n",
    "\n",
    "df_jobs_anal_no_o_all_ads_pres = df_jobs_anal_no_o.loc[\n",
    "    indices_to_keep    \n",
    "    ]\n",
    "df_i = df_jobs_anal_no_o_all_ads_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20 * \"TEMP \\n\")\n",
    "# name_i = ('slac', 'relovalu_12', 24.0)\n",
    "# name_i = ('sherlock', 'vevarehu_32', 63.0)\n",
    "name_i = ('slac', 'votafefa_68', 38.0)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "df_i = df_i.loc[idx[name_i[0], name_i[1], :, name_i[2], :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "groups_to_process = []\n",
    "# #########################################################\n",
    "groupby_cols = [\"compenv\", \"slab_id\", \"active_site\", ]\n",
    "grouped = df_i.groupby(groupby_cols)\n",
    "# #########################################################\n",
    "iterator = tqdm(grouped, desc=\"1st loop\")\n",
    "for i_cnt, (name_i, group) in enumerate(iterator):\n",
    "    print(name_i)\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    active_site_i = name_i[2]\n",
    "    # #####################################################\n",
    "\n",
    "    df_index = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "    df_index_i = df_index[\n",
    "        (df_index.compenv == compenv_i) & \\\n",
    "        (df_index.slab_id == slab_id_i) & \\\n",
    "        (df_index.ads == \"o\") & \\\n",
    "        [True for i in range(len(df_index))]\n",
    "        ]\n",
    "\n",
    "    row_o_i = df_jobs_anal_i.loc[\n",
    "        df_index_i.index    \n",
    "        ]\n",
    "\n",
    "    group_w_o = pd.concat([group, row_o_i, ], axis=0)\n",
    "    # #####################################################\n",
    "    job_ids_list = group_w_o.job_id_max.tolist()\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Deciding whether to reprocess the job or not\n",
    "    # #####################################################\n",
    "    out_dict_i = magmom_data_dict.get(name_i, None)\n",
    "    # #####################################################\n",
    "    if out_dict_i is None:\n",
    "        run_job = True\n",
    "    else:\n",
    "        run_job = False\n",
    "        job_ids_prev = out_dict_i.get(\"job_ids\", None)\n",
    "        if job_ids_prev is None:\n",
    "            run_job = True\n",
    "        else:\n",
    "            if list(np.sort(job_ids_prev)) != list(np.sort(job_ids_list)):\n",
    "                run_job = True\n",
    "\n",
    "    if redo_all_jobs:\n",
    "        run_job = True\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    if run_job:\n",
    "\n",
    "        groups_to_process.append(name_i)\n",
    "\n",
    "        # COMMENT THIS OUT TO RUN PARALLEL!!!!!!!\n",
    "\n",
    "#         out_dict_i = process_group_magmom_comp(\n",
    "#             name=name_i,\n",
    "#             group=group_w_o,\n",
    "#             write_atoms_objects=False,\n",
    "#             verbose=False,\n",
    "#             )\n",
    "\n",
    "        # # save_magmom_comp_data(name_i, out_dict_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| - Import Modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from methods import (\n",
    "    get_magmom_diff_data,\n",
    "    get_df_jobs,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_job_ids,\n",
    "    CountFrequency,\n",
    "    )\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = name_i\n",
    "group = group_w_o\n",
    "write_atoms_objects = False\n",
    "verbose = True\n",
    "\n",
    "# def process_group_magmom_comp(\n",
    "#     name=None,\n",
    "#     group=None,\n",
    "#     write_atoms_objects=False,\n",
    "#     verbose=False,\n",
    "#     ):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#| - process_group_magmom_comp\n",
    "# #####################################################\n",
    "group_w_o = group\n",
    "\n",
    "# #####################################################\n",
    "out_dict = dict()\n",
    "out_dict[\"df_magmoms_comp\"] = None\n",
    "out_dict[\"good_triplet_comb\"] = None\n",
    "out_dict[\"job_ids\"] = None\n",
    "# out_dict[\"\"] =\n",
    "\n",
    "job_ids_list = list(set(group.job_id_max.tolist()))\n",
    "\n",
    "\n",
    "#| - Reading data\n",
    "# #########################################################\n",
    "df_jobs = get_df_jobs()\n",
    "\n",
    "# #########################################################\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "df_atoms_sorted_ind = df_atoms_sorted_ind.set_index(\"job_id\")\n",
    "\n",
    "# #########################################################\n",
    "df_job_ids = get_df_job_ids()\n",
    "df_job_ids = df_job_ids.set_index(\"job_id\")\n",
    "\n",
    "from methods import read_magmom_comp_data\n",
    "\n",
    "assert name != None, \"Must pass name to read previous data\"\n",
    "\n",
    "magmom_comp_data_prev = read_magmom_comp_data(name=name)\n",
    "if magmom_comp_data_prev is not None:\n",
    "    pair_wise_magmom_comp_data_prev = \\\n",
    "        magmom_comp_data_prev[\"pair_wise_magmom_comp_data\"]\n",
    "#__|\n",
    "\n",
    "if write_atoms_objects:\n",
    "    #| - Write atoms objects\n",
    "    df_i = pd.concat([\n",
    "        df_job_ids,\n",
    "        df_atoms_sorted_ind.loc[\n",
    "            group_w_o.job_id_max.tolist()\n",
    "            ]\n",
    "        ], axis=1, join=\"inner\")\n",
    "\n",
    "    # #########################################################\n",
    "    df_index_i = group_w_o.index.to_frame()\n",
    "    compenv_i = df_index_i.compenv.unique()[0]\n",
    "    slab_id_i = df_index_i.slab_id.unique()[0]\n",
    "\n",
    "    active_sites = [i for i in df_index_i.active_site.unique() if i != \"NaN\"]\n",
    "    active_site_i = active_sites[0]\n",
    "\n",
    "    folder_name = compenv_i + \"__\" + slab_id_i + \"__\" + str(int(active_site_i))\n",
    "    # #########################################################\n",
    "\n",
    "\n",
    "    for job_id_i, row_i in df_i.iterrows():\n",
    "        tmp = 42\n",
    "\n",
    "        job_id = row_i.name\n",
    "        atoms = row_i.atoms_sorted_good\n",
    "        ads = row_i.ads\n",
    "\n",
    "        file_name = ads + \"_\" + job_id + \".traj\"\n",
    "\n",
    "        root_file_path = os.path.join(\"__temp__\", folder_name)\n",
    "        if not os.path.exists(root_file_path):\n",
    "            os.makedirs(root_file_path)\n",
    "\n",
    "        file_path = os.path.join(root_file_path, file_name)\n",
    "\n",
    "        atoms.write(file_path)\n",
    "    #__|\n",
    "\n",
    "# #####################################################\n",
    "#| - Getting good triplet combinations\n",
    "all_triplet_comb = list(itertools.combinations(\n",
    "    group_w_o.job_id_max.tolist(), 3))\n",
    "\n",
    "good_triplet_comb = []\n",
    "for tri_i in all_triplet_comb:\n",
    "    df_jobs_i = df_jobs.loc[list(tri_i)]\n",
    "\n",
    "    # Triplet must not contain duplicate ads\n",
    "    # Must strictly be a *O, *OH, and *bare triplet\n",
    "    ads_freq_dict = CountFrequency(df_jobs_i.ads.tolist())\n",
    "\n",
    "    tmp_list = list(ads_freq_dict.values())\n",
    "    any_repeat_ads = [True if i > 1 else False for i in tmp_list]\n",
    "\n",
    "    if not any(any_repeat_ads):\n",
    "        good_triplet_comb.append(tri_i)\n",
    "#__|\n",
    "\n",
    "# #####################################################\n",
    "#| - MAIN LOOP\n",
    "if verbose:\n",
    "    print(\n",
    "        \"Number of viable triplet combinations:\",\n",
    "        len(good_triplet_comb)\n",
    "        )\n",
    "\n",
    "data_dict_list = []\n",
    "pair_wise_magmom_comp_data = dict()\n",
    "\n",
    "print(\"TEMP\")\n",
    "good_triplet_comb = [\n",
    "    ('hetenehu_72', 'dituruvi_75', 'gigowifu_35'),\n",
    "    ]\n",
    "\n",
    "for tri_i in good_triplet_comb:\n",
    "    #| - Process triplets\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"tri_i:\", tri_i)\n",
    "\n",
    "    all_pairs = list(itertools.combinations(tri_i, 2))\n",
    "\n",
    "    df_jobs_i = df_jobs.loc[list(tri_i)]\n",
    "\n",
    "    sum_norm_abs_magmom_diff = 0.\n",
    "\n",
    "    print(\"TEMP\")\n",
    "    all_pairs = [\n",
    "        # ('hetenehu_72', 'dituruvi_75'),\n",
    "        ('hetenehu_72', 'gigowifu_35'),\n",
    "        # ('dituruvi_75', 'gigowifu_35'),\n",
    "        ]\n",
    "\n",
    "    for pair_i in all_pairs:\n",
    "\n",
    "        # # if pair_i in list(pair_wise_magmom_comp_data_prev.keys()):\n",
    "        # if (magmom_comp_data_prev is not None) and \\\n",
    "        #    (pair_i in list(pair_wise_magmom_comp_data_prev.keys())):\n",
    "        #     magmom_data_out = pair_wise_magmom_comp_data_prev[pair_i]\n",
    "        # else:\n",
    "\n",
    "        # print(\"Need to run manually\")\n",
    "        # print(\"pair_i:\", pair_i)\n",
    "        #| - Process pairs\n",
    "        row_jobs_0 = df_jobs.loc[pair_i[0]]\n",
    "        row_jobs_1 = df_jobs.loc[pair_i[1]]\n",
    "\n",
    "        ads_0 = row_jobs_0.ads\n",
    "        ads_1 = row_jobs_1.ads\n",
    "\n",
    "        # #############################################\n",
    "        if set([ads_0, ads_1]) == set([\"o\", \"oh\"]):\n",
    "            job_id_0 = df_jobs_i[df_jobs_i.ads == \"o\"].iloc[0].job_id\n",
    "            job_id_1 = df_jobs_i[df_jobs_i.ads == \"oh\"].iloc[0].job_id\n",
    "        elif set([ads_0, ads_1]) == set([\"o\", \"bare\"]):\n",
    "            job_id_0 = df_jobs_i[df_jobs_i.ads == \"bare\"].iloc[0].job_id\n",
    "            job_id_1 = df_jobs_i[df_jobs_i.ads == \"o\"].iloc[0].job_id\n",
    "        elif set([ads_0, ads_1]) == set([\"oh\", \"bare\"]):\n",
    "            job_id_0 = df_jobs_i[df_jobs_i.ads == \"bare\"].iloc[0].job_id\n",
    "            job_id_1 = df_jobs_i[df_jobs_i.ads == \"oh\"].iloc[0].job_id\n",
    "        else:\n",
    "            print(\"Woops something went wrong here\")\n",
    "\n",
    "\n",
    "        # #############################################\n",
    "        row_atoms_i = df_atoms_sorted_ind.loc[job_id_0]\n",
    "        # #############################################\n",
    "        atoms_0 = row_atoms_i.atoms_sorted_good\n",
    "        magmoms_sorted_good_0 = row_atoms_i.magmoms_sorted_good\n",
    "        was_sorted_0 = row_atoms_i.was_sorted\n",
    "        # #############################################\n",
    "\n",
    "        # #############################################\n",
    "        row_atoms_i = df_atoms_sorted_ind.loc[job_id_1]\n",
    "        # #############################################\n",
    "        atoms_1 = row_atoms_i.atoms_sorted_good\n",
    "        magmoms_sorted_good_1 = row_atoms_i.magmoms_sorted_good\n",
    "        was_sorted_1 = row_atoms_i.was_sorted\n",
    "        # #############################################\n",
    "\n",
    "\n",
    "        #############################################\n",
    "        magmom_data_out = get_magmom_diff_data(\n",
    "            ads_atoms=atoms_1,\n",
    "            slab_atoms=atoms_0,\n",
    "            ads_magmoms=magmoms_sorted_good_1,\n",
    "            slab_magmoms=magmoms_sorted_good_0,\n",
    "            )\n",
    "        # __|\n",
    "\n",
    "        pair_wise_magmom_comp_data[pair_i] = magmom_data_out\n",
    "\n",
    "        tot_abs_magmom_diff = magmom_data_out[\"tot_abs_magmom_diff\"]\n",
    "        norm_abs_magmom_diff = magmom_data_out[\"norm_abs_magmom_diff\"]\n",
    "        if verbose:\n",
    "            print(\"    \", \"pair_i: \", pair_i, \": \", np.round(norm_abs_magmom_diff, 3), sep=\"\")\n",
    "\n",
    "        print(\"norm_abs_magmom_diff:\", norm_abs_magmom_diff)\n",
    "        sum_norm_abs_magmom_diff += norm_abs_magmom_diff\n",
    "\n",
    "    # #################################################\n",
    "    data_dict_i[\"job_ids_tri\"] = set(tri_i)\n",
    "    data_dict_i[\"sum_norm_abs_magmom_diff\"] = sum_norm_abs_magmom_diff\n",
    "    # #################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #################################################\n",
    "\n",
    "    #__|\n",
    "\n",
    "#__|\n",
    "\n",
    "# #####################################################\n",
    "df_magmoms_i = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# #####################################################\n",
    "out_dict[\"df_magmoms_comp\"] = df_magmoms_i\n",
    "out_dict[\"good_triplet_comb\"] = good_triplet_comb\n",
    "out_dict[\"pair_wise_magmom_comp_data\"] = pair_wise_magmom_comp_data\n",
    "out_dict[\"job_ids\"] = job_ids_list\n",
    "# #####################################################\n",
    "\n",
    "# return(out_dict)\n",
    "# __|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | - Import Modules\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import filecmp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ase.atoms import Atoms\n",
    "from ase.io import read\n",
    "\n",
    "from pymatgen.core.sites import PeriodicSite\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "# __|\n",
    "\n",
    "# from methods_magmom_comp import *\n",
    "from methods_magmom_comp import _get_magmom_diff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_atoms = atoms_1\n",
    "slab_atoms = atoms_0\n",
    "ads_magmoms = magmoms_sorted_good_1\n",
    "slab_magmoms = magmoms_sorted_good_0\n",
    "\n",
    "\n",
    "# def get_magmom_diff_data(\n",
    "#     ads_atoms=None,\n",
    "#     slab_atoms=None,\n",
    "#     ads_magmoms=None,\n",
    "#     slab_magmoms=None,\n",
    "#     ):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#| - get_magmom_diff_data\n",
    "\n",
    "# #########################################################\n",
    "out_dict__no_flipped = _get_magmom_diff_data(\n",
    "    ads_atoms, slab_atoms,\n",
    "    flip_spin_sign=False,\n",
    "    ads_magmoms=ads_magmoms,\n",
    "    slab_magmoms=slab_magmoms,\n",
    "    )\n",
    "tot_abs_magmom_diff__no_flip = out_dict__no_flipped[\"tot_abs_magmom_diff\"]\n",
    "# #########################################################\n",
    "out_dict__yes_flipped = _get_magmom_diff_data(\n",
    "    ads_atoms, slab_atoms,\n",
    "    flip_spin_sign=True,\n",
    "    ads_magmoms=ads_magmoms,\n",
    "    slab_magmoms=slab_magmoms,\n",
    "    )\n",
    "tot_abs_magmom_diff__yes_flip = out_dict__yes_flipped[\"tot_abs_magmom_diff\"]\n",
    "\n",
    "# #########################################################\n",
    "if tot_abs_magmom_diff__yes_flip < tot_abs_magmom_diff__no_flip:\n",
    "    # print(\"Need to use the flipped spin solution\")\n",
    "    out_dict = out_dict__yes_flipped\n",
    "else:\n",
    "    out_dict = out_dict__no_flipped\n",
    "\n",
    "\n",
    "# return(out_dict)\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pair_wise_magmom_comp_data.keys())\n",
    "\n",
    "pair_magmom_comp_i = out_dict\n",
    "# pair_magmom_comp_i = pair_wise_magmom_comp_data[\n",
    "#     ('hetenehu_72', 'dituruvi_75')\n",
    "#     # ('hetenehu_72', 'gigowifu_35')\n",
    "#     # ('dituruvi_75', 'gigowifu_35')\n",
    "#     ]\n",
    "\n",
    "list(pair_magmom_comp_i.keys())\n",
    "\n",
    "delta_magmoms_i = pair_magmom_comp_i[\"delta_magmoms\"]\n",
    "tot_abs_magmom_diff_i = pair_magmom_comp_i[\"tot_abs_magmom_diff\"]\n",
    "norm_abs_magmom_diff_i = pair_magmom_comp_i[\"norm_abs_magmom_diff\"]\n",
    "delta_magmoms_unsorted_i = pair_magmom_comp_i[\"norm_abs_magmom_diff\"]\n",
    "\n",
    "\n",
    "# delta_magmoms_unsorted_i\n",
    "tot_abs_magmom_diff_i\n",
    "norm_abs_magmom_diff_i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.72 / 38\n",
    "\n",
    "676 - 380\n",
    "\n",
    "296 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_i = pd.DataFrame(\n",
    "    delta_magmoms_i,\n",
    "    columns=[\"index\", \"diff\", ],\n",
    "    )\n",
    "df_tmp_i[\"diff_abs\"] = np.abs(df_tmp_i[\"diff\"])\n",
    "\n",
    "# df_tmp_i.diff_abs.sum()\n",
    "df_tmp_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "variables_dict = dict(\n",
    "    kwarg_0=\"kwarg_0\",\n",
    "    kwarg_1=\"kwarg_1\",\n",
    "    kwarg_2=\"kwarg_2\",\n",
    "    )\n",
    "\n",
    "def method_wrap(\n",
    "    input_dict,\n",
    "\n",
    "    kwarg_0=None,\n",
    "    kwarg_1=None,\n",
    "    kwarg_2=None,\n",
    "    ):\n",
    "    input_var_0 = input_dict[\"input_var_0\"]\n",
    "    input_var_1 = input_dict[\"input_var_1\"]\n",
    "    input_var_2 = input_dict[\"input_var_2\"]\n",
    "\n",
    "    print(\n",
    "        \"input_var_0:\", str(input_var_0),\n",
    "        \"input_var_1:\", str(input_var_1),\n",
    "        \"input_var_2:\", str(input_var_2),\n",
    "        )\n",
    "\n",
    "\n",
    "input_list = []\n",
    "for i in range(10):\n",
    "    input_dict_i = dict(\n",
    "        input_var_0=i + 0,\n",
    "        input_var_1=i + 1,\n",
    "        input_var_2=i + 2,\n",
    "        )\n",
    "    input_list.append(input_dict_i)\n",
    "\n",
    "traces_all = Pool().map(\n",
    "    partial(\n",
    "        method_wrap,  # METHOD\n",
    "        **variables_dict,  # KWARGS\n",
    "        ),\n",
    "    input_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# #########################################################\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_jobs_anal\n",
    "from methods import get_df_jobs_data\n",
    "from methods import get_df_atoms_sorted_ind\n",
    "from methods import get_df_init_slabs\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import read_magmom_comp_data, save_magmom_comp_data\n",
    "from local_methods import process_group_magmom_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# verbose = False\n",
    "# verbose = True\n",
    "\n",
    "redo_all_jobs = False\n",
    "# redo_all_jobs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "df_jobs_anal = get_df_jobs_anal()\n",
    "\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "\n",
    "df_init_slabs = get_df_init_slabs()\n",
    "\n",
    "magmom_data_dict = read_magmom_comp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "# Only completed jobs will be considered\n",
    "df_jobs_anal_i = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "# #########################################################\n",
    "# Remove the *O slabs for now\n",
    "# The fact that they have NaN active sites will mess up the groupby\n",
    "ads_list = df_jobs_anal_i.index.get_level_values(\"ads\").tolist()\n",
    "ads_list_no_o = [i for i in list(set(ads_list)) if i != \"o\"]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "df_jobs_anal_no_o = df_jobs_anal_i.loc[idx[:, :, ads_list_no_o, :, :], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "indices_to_keep = []\n",
    "groupby_cols = [\"compenv\", \"slab_id\", \"active_site\", ]\n",
    "grouped = df_jobs_anal_no_o.groupby(groupby_cols)\n",
    "for name_i, group in grouped:\n",
    "    group_index = group.index.to_frame()\n",
    "    ads_list = list(group_index.ads.unique())\n",
    "    oh_present = \"oh\" in ads_list\n",
    "    bare_present = \"bare\" in ads_list\n",
    "    all_req_ads_present = oh_present and bare_present\n",
    "    if all_req_ads_present:\n",
    "        indices_to_keep.extend(group.index.tolist())\n",
    "\n",
    "df_jobs_anal_no_o_all_ads_pres = df_jobs_anal_no_o.loc[\n",
    "    indices_to_keep    \n",
    "    ]\n",
    "df_i = df_jobs_anal_no_o_all_ads_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5 * \"When new *O and * jobs come through (from rerunning *OH) make sure to rerun the magmom comparison routine\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "groupby_cols = [\"compenv\", \"slab_id\", \"active_site\", ]\n",
    "grouped = df_i.groupby(groupby_cols)\n",
    "# #########################################################\n",
    "# iterator = tqdm(grouped, desc=\"1st loop\")\n",
    "# for i_cnt, (name_i, group) in enumerate(iterator):\n",
    "if True:\n",
    "    # TEMP\n",
    "    print(20 * \"TEMP | \")\n",
    "    name_i = ('slac', 'wiwiwetu_44', 19.0)\n",
    "    group = grouped.get_group(name_i)\n",
    "\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    active_site_i = name_i[2]\n",
    "    # #####################################################\n",
    "\n",
    "    df_index = df_jobs_anal_i.index.to_frame()\n",
    "\n",
    "    df_index_i = df_index[\n",
    "        (df_index.compenv == compenv_i) & \\\n",
    "        (df_index.slab_id == slab_id_i) & \\\n",
    "        (df_index.ads == \"o\") & \\\n",
    "        [True for i in range(len(df_index))]\n",
    "        ]\n",
    "\n",
    "    row_o_i = df_jobs_anal_i.loc[\n",
    "        df_index_i.index    \n",
    "        ]\n",
    "\n",
    "    group_w_o = pd.concat([group, row_o_i, ], axis=0)\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # Deciding whether to reprocess the job or not\n",
    "    # #####################################################\n",
    "    out_dict_i = magmom_data_dict.get(name_i, None)\n",
    "    # #####################################################\n",
    "    if out_dict_i is None:\n",
    "        run_job = True\n",
    "    else:\n",
    "        run_job = False\n",
    "        job_ids_i = out_dict_i.get(\"job_ids\", None)\n",
    "        if job_ids_i is None:\n",
    "            run_job = True\n",
    "    if redo_all_jobs:\n",
    "        run_job = True\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    if run_job:\n",
    "        out_dict_i = process_group_magmom_comp(\n",
    "            group=group_w_o,\n",
    "            write_atoms_objects=False,\n",
    "            verbose=False,\n",
    "            )\n",
    "\n",
    "        save_magmom_comp_data(name_i, out_dict_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dict_i = process_group_magmom_comp(\n",
    "#     group=group_w_o,\n",
    "#     write_atoms_objects=False,\n",
    "#     verbose=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "#| - Import Modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from methods import (\n",
    "    get_magmom_diff_data,\n",
    "    get_df_jobs,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    get_df_job_ids,\n",
    "    CountFrequency,\n",
    "    )\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = group_w_o\n",
    "write_atoms_objects = False\n",
    "verbose = True\n",
    "\n",
    "# def process_group_magmom_comp(\n",
    "#     group=None,\n",
    "#     write_atoms_objects=False,\n",
    "#     verbose=False,\n",
    "#     ):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#| - process_group_magmom_comp\n",
    "# #####################################################\n",
    "group_w_o = group\n",
    "\n",
    "# #####################################################\n",
    "out_dict = dict()\n",
    "out_dict[\"df_magmoms_comp\"] = None\n",
    "out_dict[\"good_triplet_comb\"] = None\n",
    "out_dict[\"job_ids\"] = None\n",
    "# out_dict[\"\"] =\n",
    "\n",
    "job_ids_list = list(set(group.job_id_max.tolist()))\n",
    "\n",
    "\n",
    "#| - Reading data\n",
    "# #########################################################\n",
    "df_jobs = get_df_jobs()\n",
    "\n",
    "# #########################################################\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "df_atoms_sorted_ind = df_atoms_sorted_ind.set_index(\"job_id\")\n",
    "\n",
    "# #########################################################\n",
    "df_job_ids = get_df_job_ids()\n",
    "df_job_ids = df_job_ids.set_index(\"job_id\")\n",
    "#__|\n",
    "\n",
    "if write_atoms_objects:\n",
    "    #| - Write atoms objects\n",
    "    df_i = pd.concat([\n",
    "        df_job_ids,\n",
    "        df_atoms_sorted_ind.loc[\n",
    "            group_w_o.job_id_max.tolist()\n",
    "            ]\n",
    "        ], axis=1, join=\"inner\")\n",
    "\n",
    "    # #########################################################\n",
    "    df_index_i = group_w_o.index.to_frame()\n",
    "    compenv_i = df_index_i.compenv.unique()[0]\n",
    "    slab_id_i = df_index_i.slab_id.unique()[0]\n",
    "\n",
    "    active_sites = [i for i in df_index_i.active_site.unique() if i != \"NaN\"]\n",
    "    active_site_i = active_sites[0]\n",
    "\n",
    "    folder_name = compenv_i + \"__\" + slab_id_i + \"__\" + str(int(active_site_i))\n",
    "    # #########################################################\n",
    "\n",
    "\n",
    "    for job_id_i, row_i in df_i.iterrows():\n",
    "        tmp = 42\n",
    "\n",
    "        job_id = row_i.name\n",
    "        atoms = row_i.atoms_sorted_good\n",
    "        ads = row_i.ads\n",
    "\n",
    "        file_name = ads + \"_\" + job_id + \".traj\"\n",
    "\n",
    "        root_file_path = os.path.join(\"__temp__\", folder_name)\n",
    "        if not os.path.exists(root_file_path):\n",
    "            os.makedirs(root_file_path)\n",
    "\n",
    "        file_path = os.path.join(root_file_path, file_name)\n",
    "\n",
    "        atoms.write(file_path)\n",
    "    #__|\n",
    "\n",
    "# #####################################################\n",
    "#| - Getting good triplet combinations\n",
    "all_triplet_comb = list(itertools.combinations(\n",
    "    group_w_o.job_id_max.tolist(), 3))\n",
    "\n",
    "good_triplet_comb = []\n",
    "for tri_i in all_triplet_comb:\n",
    "    df_jobs_i = df_jobs.loc[list(tri_i)]\n",
    "\n",
    "    ads_freq_dict = CountFrequency(df_jobs_i.ads.tolist())\n",
    "\n",
    "    tmp_list = list(ads_freq_dict.values())\n",
    "    any_repeat_ads = [True if i > 1 else False for i in tmp_list]\n",
    "\n",
    "    if not any(any_repeat_ads):\n",
    "        good_triplet_comb.append(tri_i)\n",
    "#__|\n",
    "\n",
    "print(\n",
    "    \"Number of viable triplet combinations:\",\n",
    "    len(good_triplet_comb)\n",
    "    )\n",
    "\n",
    "good_triplet_comb = [\n",
    "    ('gubipugu_00', 'himesabi_01', 'setubuha_11'),\n",
    "    ('gubipugu_00', 'himesabi_01', 'wubitiko_11'),\n",
    "    ('gubipugu_00', 'ribipuhu_00', 'setubuha_11'),\n",
    "    ('gubipugu_00', 'ribipuhu_00', 'wubitiko_11'),\n",
    "    ]\n",
    "\n",
    "# #####################################################\n",
    "# #####################################################\n",
    "#| - MAIN LOOP\n",
    "data_dict_list = []\n",
    "pair_wise_magmom_comp_data = dict()\n",
    "for tri_i in good_triplet_comb:\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    print(\"\")\n",
    "    if verbose:\n",
    "        print(\"tri_i:\", tri_i)\n",
    "\n",
    "    all_pairs = list(itertools.combinations(tri_i, 2))\n",
    "\n",
    "    df_jobs_i = df_jobs.loc[list(tri_i)]\n",
    "\n",
    "    sum_norm_abs_magmom_diff = 0.\n",
    "    for pair_i in all_pairs:\n",
    "\n",
    "        # if verbose:\n",
    "        #     print(\"pair_i:\", pair_i)\n",
    "\n",
    "        row_jobs_0 = df_jobs.loc[pair_i[0]]\n",
    "        row_jobs_1 = df_jobs.loc[pair_i[1]]\n",
    "\n",
    "        ads_0 = row_jobs_0.ads\n",
    "        ads_1 = row_jobs_1.ads\n",
    "\n",
    "        # #############################################\n",
    "        if set([ads_0, ads_1]) == set([\"o\", \"oh\"]):\n",
    "            job_id_0 = df_jobs_i[df_jobs_i.ads == \"o\"].iloc[0].job_id\n",
    "            job_id_1 = df_jobs_i[df_jobs_i.ads == \"oh\"].iloc[0].job_id\n",
    "        elif set([ads_0, ads_1]) == set([\"o\", \"bare\"]):\n",
    "            job_id_0 = df_jobs_i[df_jobs_i.ads == \"bare\"].iloc[0].job_id\n",
    "            job_id_1 = df_jobs_i[df_jobs_i.ads == \"o\"].iloc[0].job_id\n",
    "        elif set([ads_0, ads_1]) == set([\"oh\", \"bare\"]):\n",
    "            job_id_0 = df_jobs_i[df_jobs_i.ads == \"bare\"].iloc[0].job_id\n",
    "            job_id_1 = df_jobs_i[df_jobs_i.ads == \"oh\"].iloc[0].job_id\n",
    "        else:\n",
    "            print(\"Woops something went wrong here\")\n",
    "\n",
    "\n",
    "        # #############################################\n",
    "        row_atoms_i = df_atoms_sorted_ind.loc[job_id_0]\n",
    "        # #############################################\n",
    "        atoms_0 = row_atoms_i.atoms_sorted_good\n",
    "        magmoms_sorted_good_0 = row_atoms_i.magmoms_sorted_good\n",
    "        was_sorted_0 = row_atoms_i.was_sorted\n",
    "        # #############################################\n",
    "\n",
    "\n",
    "        # #############################################\n",
    "        row_atoms_i = df_atoms_sorted_ind.loc[job_id_1]\n",
    "        # #############################################\n",
    "        atoms_1 = row_atoms_i.atoms_sorted_good\n",
    "        magmoms_sorted_good_1 = row_atoms_i.magmoms_sorted_good\n",
    "        was_sorted_1 = row_atoms_i.was_sorted\n",
    "        # #############################################\n",
    "\n",
    "\n",
    "        print(\"1111\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        # #############################################\n",
    "        magmom_data_out = get_magmom_diff_data(\n",
    "            ads_atoms=atoms_1,\n",
    "            slab_atoms=atoms_0,\n",
    "            ads_magmoms=magmoms_sorted_good_1,\n",
    "            slab_magmoms=magmoms_sorted_good_0,\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            \"2222\",\n",
    "            \" | \",\n",
    "            np.abs(t0 - time.time())\n",
    "            )\n",
    "\n",
    "        pair_wise_magmom_comp_data[pair_i] = magmom_data_out\n",
    "\n",
    "        tot_abs_magmom_diff = magmom_data_out[\"tot_abs_magmom_diff\"]\n",
    "        # print(\"    \", pair_i, \": \", np.round(tot_abs_magmom_diff, 2), sep=\"\")\n",
    "        norm_abs_magmom_diff = magmom_data_out[\"norm_abs_magmom_diff\"]\n",
    "        if verbose:\n",
    "            print(\"    \", \"pair_i: \", pair_i, \": \", np.round(norm_abs_magmom_diff, 3), sep=\"\")\n",
    "\n",
    "        sum_norm_abs_magmom_diff += norm_abs_magmom_diff\n",
    "\n",
    "\n",
    "    # #################################################\n",
    "    data_dict_i[\"job_ids_tri\"] = set(tri_i)\n",
    "    data_dict_i[\"sum_norm_abs_magmom_diff\"] = sum_norm_abs_magmom_diff\n",
    "    # #################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #################################################\n",
    "\n",
    "    # print(\"\")\n",
    "#__|\n",
    "\n",
    "\n",
    "# #####################################################\n",
    "df_magmoms_i = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# #####################################################\n",
    "out_dict[\"df_magmoms_comp\"] = df_magmoms_i\n",
    "out_dict[\"good_triplet_comb\"] = good_triplet_comb\n",
    "out_dict[\"pair_wise_magmom_comp_data\"] = pair_wise_magmom_comp_data\n",
    "out_dict[\"job_ids\"] = job_ids_list\n",
    "# #####################################################\n",
    "\n",
    "# return(out_dict)\n",
    "#__|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_triplet_comb[0:4]\n",
    "\n",
    "# good_triplet_comb = [\n",
    "#     ('gubipugu_00', 'himesabi_01', 'setubuha_11'),\n",
    "#     ('gubipugu_00', 'himesabi_01', 'wubitiko_11'),\n",
    "#     ('gubipugu_00', 'ribipuhu_00', 'setubuha_11'),\n",
    "#     ('gubipugu_00', 'ribipuhu_00', 'wubitiko_11'),\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     \"Number of viable triplet combinations:\",\n",
    "#     len(good_triplet_comb)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_w_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from methods import (\n",
    "    get_magmom_diff_data,\n",
    "    # _get_magmom_diff_data,\n",
    "    )\n",
    "\n",
    "from methods import get_df_jobs\n",
    "from methods import CountFrequency\n",
    "from methods import get_df_atoms_sorted_ind\n",
    "from methods import get_df_job_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #########################################################\n",
    "# df_jobs = get_df_jobs()\n",
    "\n",
    "# # #########################################################\n",
    "# df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "# df_atoms_sorted_ind = df_atoms_sorted_ind.set_index(\"job_id\")\n",
    "\n",
    "# # #########################################################\n",
    "# df_job_ids = get_df_job_ids()\n",
    "# df_job_ids = df_job_ids.set_index(\"job_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "import pickle; import os\n",
    "directory = os.path.join(\n",
    "    os.environ[\"HOME\"],\n",
    "    \"__temp__\")\n",
    "path_i = os.path.join(directory, \"temp_data.pickle\")\n",
    "with open(path_i, \"rb\") as fle:\n",
    "    data = pickle.load(fle)\n",
    "# #########################################################\n",
    "\n",
    "group_w_o = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_atoms_objets = True\n",
    "\n",
    "from local_methods import process_group_magmom_comp\n",
    "\n",
    "out_dict = process_group_magmom_comp(\n",
    "    group=group_w_o,\n",
    "    # df_jobs=None,\n",
    "    write_atoms_objects=False,\n",
    "    verbose=False,\n",
    "    )\n",
    "# out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "out_dict.keys()\n",
    "\n",
    "# list(out_dict[\"pair_wise_magmom_comp_data\"].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# job_id_0 = \n",
    "\n",
    "# df_jobs_i[df_jobs_i.ads == \"bare\"].iloc[0].job_id\n",
    "\n",
    "# df_jobs_i[df_jobs_i.ads == \"bare\"]\n",
    "\n",
    "# df_jobs_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# magmom_data_out[\"tot_abs_magmom_diff\"]\n",
    "\n",
    "# magmom_data_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# if write_atoms_objets:\n",
    "\n",
    "#     df_i = pd.concat([\n",
    "#         df_job_ids,\n",
    "#         df_atoms_sorted_ind.loc[\n",
    "#             group_w_o.job_id_max.tolist()\n",
    "#             ]\n",
    "#         ], axis=1, join=\"inner\")\n",
    "\n",
    "#     # #########################################################\n",
    "#     df_index_i = group_w_o.index.to_frame()\n",
    "#     compenv_i = df_index_i.compenv.unique()[0]\n",
    "#     slab_id_i = df_index_i.slab_id.unique()[0]\n",
    "\n",
    "#     active_sites = [i for i in df_index_i.active_site.unique() if i != \"NaN\"]\n",
    "#     active_site_i = active_sites[0]\n",
    "\n",
    "#     folder_name = compenv_i + \"__\" + slab_id_i + \"__\" + str(int(active_site_i))\n",
    "#     # #########################################################\n",
    "\n",
    "\n",
    "#     for job_id_i, row_i in df_i.iterrows():\n",
    "#         tmp = 42\n",
    "\n",
    "#         job_id = row_i.name\n",
    "#         atoms = row_i.atoms_sorted_good\n",
    "#         ads = row_i.ads\n",
    "\n",
    "#         file_name = ads + \"_\" + job_id + \".traj\"\n",
    "\n",
    "#         root_file_path = os.path.join(\"__temp__\", folder_name)\n",
    "#         if not os.path.exists(root_file_path):\n",
    "#             os.makedirs(root_file_path)\n",
    "\n",
    "#         file_path = os.path.join(root_file_path, file_name)\n",
    "\n",
    "#         atoms.write(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# all_triplet_comb = list(itertools.combinations(\n",
    "#     group_w_o.job_id_max.tolist(), 3))\n",
    "\n",
    "# good_triplet_comb = []\n",
    "# for tri_i in all_triplet_comb:\n",
    "#     df_jobs_i = df_jobs.loc[list(tri_i)]\n",
    "\n",
    "#     ads_freq_dict = CountFrequency(df_jobs_i.ads.tolist())\n",
    "\n",
    "#     tmp_list = list(ads_freq_dict.values())\n",
    "#     any_repeat_ads = [True if i > 1 else False for i in tmp_list]\n",
    "\n",
    "#     if not any(any_repeat_ads):\n",
    "#         good_triplet_comb.append(tri_i)\n",
    "\n",
    "# # good_triplet_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# data_dict_list = []\n",
    "# for tri_i in good_triplet_comb:\n",
    "#     data_dict_i = dict()\n",
    "\n",
    "#     # print(\"tri_i:\", tri_i)\n",
    "#     all_pairs = list(itertools.combinations(tri_i, 2))\n",
    "\n",
    "#     df_jobs_i = df_jobs.loc[list(tri_i)]\n",
    "    \n",
    "#     sum_norm_abs_magmom_diff = 0.\n",
    "#     for pair_i in all_pairs:\n",
    "\n",
    "#         row_jobs_0 = df_jobs.loc[pair_i[0]]\n",
    "#         row_jobs_1 = df_jobs.loc[pair_i[1]]\n",
    "\n",
    "#         ads_0 = row_jobs_0.ads\n",
    "#         ads_1 = row_jobs_1.ads\n",
    "\n",
    "#         # #########################################################\n",
    "#         if set([ads_0, ads_1]) == set([\"o\", \"oh\"]):\n",
    "#             job_id_0 = df_jobs_i[df_jobs_i.ads == \"o\"].iloc[0].job_id\n",
    "#             job_id_1 = df_jobs_i[df_jobs_i.ads == \"oh\"].iloc[0].job_id\n",
    "#         elif set([ads_0, ads_1]) == set([\"o\", \"bare\"]):\n",
    "#             job_id_0 = df_jobs_i[df_jobs_i.ads == \"bare\"].iloc[0].job_id\n",
    "#             job_id_1 = df_jobs_i[df_jobs_i.ads == \"o\"].iloc[0].job_id\n",
    "#         elif set([ads_0, ads_1]) == set([\"oh\", \"bare\"]):\n",
    "#             job_id_0 = df_jobs_i[df_jobs_i.ads == \"bare\"].iloc[0].job_id\n",
    "#             job_id_1 = df_jobs_i[df_jobs_i.ads == \"oh\"].iloc[0].job_id\n",
    "#         else:\n",
    "#             print(\"Woops something went wrong here\")\n",
    "\n",
    "\n",
    "#         # #########################################################\n",
    "#         row_atoms_i = df_atoms_sorted_ind.loc[job_id_0]\n",
    "#         # #########################################################\n",
    "#         atoms_0 = row_atoms_i.atoms_sorted_good\n",
    "#         magmoms_sorted_good_0 = row_atoms_i.magmoms_sorted_good\n",
    "#         was_sorted_0 = row_atoms_i.was_sorted\n",
    "#         # #########################################################\n",
    "\n",
    "#         # #########################################################\n",
    "#         row_atoms_i = df_atoms_sorted_ind.loc[job_id_1]\n",
    "#         # #########################################################\n",
    "#         atoms_1 = row_atoms_i.atoms_sorted_good\n",
    "#         magmoms_sorted_good_1 = row_atoms_i.magmoms_sorted_good\n",
    "#         was_sorted_1 = row_atoms_i.was_sorted\n",
    "#         # #########################################################\n",
    "\n",
    "\n",
    "#         # #########################################################\n",
    "#         magmom_data_out = get_magmom_diff_data(\n",
    "#             ads_atoms=atoms_1,\n",
    "#             slab_atoms=atoms_0,\n",
    "#             ads_magmoms=magmoms_sorted_good_1,\n",
    "#             slab_magmoms=magmoms_sorted_good_0,\n",
    "#             )\n",
    "\n",
    "#         # list(magmom_data_out.keys())\n",
    "\n",
    "#         tot_abs_magmom_diff = magmom_data_out[\"tot_abs_magmom_diff\"]\n",
    "#         # print(\"    \", pair_i, \": \", np.round(tot_abs_magmom_diff, 2), sep=\"\")\n",
    "#         norm_abs_magmom_diff = magmom_data_out[\"norm_abs_magmom_diff\"]\n",
    "#         print(\"    \", pair_i, \": \", np.round(norm_abs_magmom_diff, 3), sep=\"\")\n",
    "        \n",
    "#         sum_norm_abs_magmom_diff += norm_abs_magmom_diff\n",
    "\n",
    "#     # #####################################################\n",
    "#     data_dict_i[\"job_ids_tri\"] = set(tri_i)\n",
    "#     data_dict_i[\"sum_norm_abs_magmom_diff\"] = sum_norm_abs_magmom_diff\n",
    "#     # #####################################################\n",
    "#     data_dict_list.append(data_dict_i)\n",
    "#     # #####################################################\n",
    "\n",
    "#     # print(\"TEMP\")\n",
    "#     # break\n",
    "\n",
    "#     print(\"\")\n",
    "\n",
    "#         # #########################################################\n",
    "\n",
    "# df_magmoms_i = pd.DataFrame(data_dict_list)\n",
    "# # df_magmoms_i"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_IrOx_Active_Learning_OER]",
   "language": "python",
   "name": "conda-env-PROJ_IrOx_Active_Learning_OER-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
