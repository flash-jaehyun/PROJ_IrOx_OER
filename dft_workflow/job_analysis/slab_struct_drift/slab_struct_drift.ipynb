{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural similarity of before/after relaxation\n",
    "---\n",
    "This will allow us to quantify the degree of structural drift"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import copy\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ase import io\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from StructurePrototypeAnalysisPackage.ccf import cal_ccf_d\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_df_jobs, get_df_jobs_data\n",
    "from methods import get_df_init_slabs\n",
    "from methods import get_df_jobs_anal\n",
    "from methods import get_df_jobs_paths\n",
    "from methods import get_df_atoms_sorted_ind\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import get_ccf\n",
    "from local_methods import get_all_ccf_data\n",
    "from local_methods import remove_constrained_atoms\n",
    "from local_methods import check_ccf_data_present\n",
    "from local_methods import get_ave_drift\n",
    "from local_methods import get_ave_drift__wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cut_off = 10\n",
    "r_vector = np.arange(0.06, 10, 0.02)\n",
    "\n",
    "# r_cut_off = 10\n",
    "# r_vector = np.arange(1, 10, 0.005)\n",
    "\n",
    "# r_cut_off = 30\n",
    "# r_vector = np.arange(0, 30, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = get_df_jobs()\n",
    "df_jobs_i = df_jobs\n",
    "\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "df_init_slabs = get_df_init_slabs()\n",
    "\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "\n",
    "df_jobs_paths = get_df_jobs_paths()\n",
    "\n",
    "\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_i = df_jobs_i.drop(columns=[\n",
    "    \"job_id\",\n",
    "    \"facet\",\n",
    "    \"num_revs\",\n",
    "    \"compenv_origin\",\n",
    "    \"submitted\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP\n",
    "\n",
    "# # ('sherlock', 'kesekodi_38', 'o', 'NaN', 1)\n",
    "\n",
    "# # Exploded job\n",
    "# # name_i = (\"slac\", \"relovalu_12\", \"oh\", 24.0, 2, )\n",
    "\n",
    "# # name_i = (\"nersc\", \"kalisule_45\", \"bare\", 73.0, 1, )\n",
    "\n",
    "# # Most disimilar slab, not the one that exploded weirdly enough\n",
    "# # name_i = (\"nersc\", \"horikovi_77\", \"o\", \"NaN\", 1, )\n",
    "\n",
    "# name_i = ('slac', 'relovalu_12', 'oh', 24.0, 2)\n",
    "\n",
    "# df = df_jobs\n",
    "# df = df[\n",
    "#     (df[\"compenv\"] == name_i[0]) &\n",
    "#     (df[\"slab_id\"] == name_i[1]) &\n",
    "#     (df[\"ads\"] == name_i[2]) &\n",
    "#     (df[\"active_site\"] == name_i[3]) &\n",
    "#     (df[\"att_num\"] == name_i[4]) &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df_jobs_i = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", ]\n",
    "grouped = df_jobs_i.groupby(group_cols)\n",
    "# #########################################################\n",
    "groups_list = []\n",
    "for i_cnt, (name_i, group_i) in enumerate(grouped):\n",
    "    groups_list.append(group_i)\n",
    "\n",
    "len(groups_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "group_cols = [\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", ]\n",
    "grouped = df_jobs_i.groupby(group_cols)\n",
    "# #########################################################\n",
    "for i_cnt, (name_i, group_i) in enumerate(grouped):\n",
    "\n",
    "    init_true = check_ccf_data_present(\n",
    "        name_tup=name_i,\n",
    "        init_or_final=\"init\",\n",
    "        intact=True)\n",
    "\n",
    "    init_false = check_ccf_data_present(\n",
    "        name_tup=name_i,\n",
    "        init_or_final=\"init\",\n",
    "        intact=False)\n",
    "\n",
    "    final_true = check_ccf_data_present(\n",
    "        name_tup=name_i,\n",
    "        init_or_final=\"final\",\n",
    "        intact=True)\n",
    "\n",
    "    final_false = check_ccf_data_present(\n",
    "        name_tup=name_i,\n",
    "        init_or_final=\"final\",\n",
    "        intact=False)\n",
    "\n",
    "    all_files_present = False\n",
    "    if init_false and init_true and final_false and final_true:\n",
    "        all_files_present = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "data_dict_list = []\n",
    "# #########################################################\n",
    "group_cols = [\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", ]\n",
    "grouped = df_jobs_i.groupby(group_cols)\n",
    "# #########################################################\n",
    "num_groups_processed = 0\n",
    "for i_cnt, (name_i, group_i) in enumerate(grouped):\n",
    "    # print(name_i)\n",
    "    # #####################################################\n",
    "    data_dict_i = dict()\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(group_cols, name_i))\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    # #########################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    ads_i = name_i[2]\n",
    "    active_site_i = name_i[3]\n",
    "    att_num_i = name_i[4]\n",
    "    # #########################################################\n",
    "\n",
    "    # #########################################################\n",
    "    row_anal_i = df_jobs_anal.loc[name_i]\n",
    "    # #########################################################\n",
    "    job_completely_done_i = row_anal_i.job_completely_done\n",
    "    # #########################################################\n",
    "\n",
    "    # print(job_completely_done_i)\n",
    "\n",
    "    if job_completely_done_i:\n",
    "        num_groups_processed += 1\n",
    "\n",
    "        # print(\"TEMP | \")\n",
    "        # if num_groups_processed > 1:\n",
    "        #     break\n",
    "\n",
    "        # #################################################\n",
    "        # Findind mix/max job_ids\n",
    "        rev_max = group_i.rev_num.max()\n",
    "        rev_min = 1\n",
    "\n",
    "\n",
    "        if rev_max != group_i.shape[0]:\n",
    "            print(\"s9sdufjs9f09sui\", name_i)\n",
    "            continue\n",
    "\n",
    "        row_max_i = group_i[group_i.rev_num == rev_max]\n",
    "        assert row_max_i.shape[0] == 1, \"ISDJFISj\"\n",
    "        row_max_i = row_max_i.iloc[0]\n",
    "        job_id_max = row_max_i.name\n",
    "\n",
    "        row_min_i = group_i[group_i.rev_num == rev_min]\n",
    "        assert row_min_i.shape[0] == 1, \"ISDJFISj\"\n",
    "        row_min_i = row_min_i.iloc[0]\n",
    "        job_id_min = row_min_i.name\n",
    "\n",
    "        # #################################################\n",
    "        row_data_i = df_jobs_data.loc[job_id_max]\n",
    "        # #################################################\n",
    "        atoms_final = row_data_i.final_atoms\n",
    "        # #################################################\n",
    "\n",
    "        # #####################################################\n",
    "        row_atoms_sorted_i = df_atoms_sorted_ind[\n",
    "            df_atoms_sorted_ind.job_id == job_id_max]\n",
    "        row_atoms_sorted_i = row_atoms_sorted_i.iloc[0]\n",
    "        # #####################################################\n",
    "        atoms_final_sorted = row_atoms_sorted_i.atoms_sorted_good\n",
    "        failed_to_sort_i = row_atoms_sorted_i.failed_to_sort\n",
    "        # #####################################################\n",
    "\n",
    "        # #################################################\n",
    "        row_init_min_i = df_init_slabs[df_init_slabs.job_id_min == job_id_min]\n",
    "        row_init_min_i = row_init_min_i.iloc[0]\n",
    "        # #################################################\n",
    "        atoms_init = row_init_min_i.init_atoms\n",
    "        # #################################################\n",
    "\n",
    "        atoms_init_non_constr = remove_constrained_atoms(atoms_init)\n",
    "        atoms_final_non_constr = remove_constrained_atoms(atoms_final)\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        out_ccf_data_dict = get_all_ccf_data(\n",
    "            atoms_init=atoms_init,\n",
    "            atoms_final=atoms_final,\n",
    "            atoms_init_part=atoms_init_non_constr,\n",
    "            atoms_final_part=atoms_final_non_constr,\n",
    "            name_i=name_i,\n",
    "            r_cut_off=r_cut_off,\n",
    "            r_vector=r_vector,\n",
    "            )\n",
    "        # #################################################\n",
    "        ccf_init = out_ccf_data_dict[\"ccf_init\"]\n",
    "        ccf_init_2 = out_ccf_data_dict[\"ccf_init_2\"]\n",
    "        ccf_final = out_ccf_data_dict[\"ccf_final\"]\n",
    "        ccf_final_2 = out_ccf_data_dict[\"ccf_final_2\"]\n",
    "        # #################################################\n",
    "\n",
    "        d_i = cal_ccf_d(ccf_init, ccf_final)\n",
    "        d_i_2 = cal_ccf_d(ccf_init_2, ccf_final_2)\n",
    "\n",
    "        ave_dist_pa = None\n",
    "        if not failed_to_sort_i:\n",
    "            ave_dist_pa = get_ave_drift__wrapper(\n",
    "                atoms_init=atoms_init,\n",
    "                atoms_final=atoms_final_sorted,\n",
    "                name_i=name_i,\n",
    "                )\n",
    "\n",
    "\n",
    "        # #################################################\n",
    "        data_dict_i.update(name_dict_i)\n",
    "        # #################################################\n",
    "        data_dict_i[\"job_id_min\"] = job_id_min\n",
    "        data_dict_i[\"job_id_max\"] = job_id_max\n",
    "        data_dict_i[\"init_final_simil\"] = d_i\n",
    "        data_dict_i[\"init_final_simil_part\"] = d_i_2\n",
    "        data_dict_i[\"ave_dist_pa\"] = ave_dist_pa\n",
    "        data_dict_i[\"atoms_init_part\"] = atoms_init_non_constr\n",
    "        data_dict_i[\"atoms_final_part\"] = atoms_final_non_constr\n",
    "        # #################################################\n",
    "        data_dict_list.append(data_dict_i)\n",
    "        # #################################################\n",
    "\n",
    "# #########################################################\n",
    "df_struct_drift = pd.DataFrame(data_dict_list)\n",
    "\n",
    "# df_struct_drift = df_struct_drift.sort_values(\n",
    "#     \"init_final_simil\", ascending=False)\n",
    "# df_struct_drift = df_struct_drift.sort_values(\"init_final_simil_part\", ascending=False)\n",
    "df_struct_drift = df_struct_drift.sort_values(\"ave_dist_pa\", ascending=False)\n",
    "\n",
    "df_struct_drift = df_struct_drift.set_index(\n",
    "    [\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", ])\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_struct_drift[df_struct_drift.ave_dist_pa.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_struct_drift.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting similarity column"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "# y_array = df_struct_drift_i.init_final_simil_part\n",
    "y_array = df_struct_drift.ave_dist_pa\n",
    "\n",
    "trace = go.Scatter(\n",
    "    y=y_array,\n",
    "    mode=\"markers\",\n",
    "    )\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_struct_drift.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def method(row_i, argument_0, optional_arg=None):\n",
    "# def method(row_i):\n",
    "\n",
    "# # df_struct_drift[\"column_name\"] = \n",
    "# df_struct_drift.apply(\n",
    "#     method,\n",
    "#     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_i = df_struct_drift.iloc[0]\n",
    "\n",
    "# name_tup_i = row_i.name\n",
    "\n",
    "# name_list = []\n",
    "# for i in name_tup_i:\n",
    "#     if type(i) == int or type(i) == float:\n",
    "#         name_list.append(str(int(i)))\n",
    "#     elif type(i) == str:\n",
    "#         name_list.append(i)\n",
    "#     else:\n",
    "#         name_list.append(str(i))\n",
    "# name_i = \"__\".join(name_list)\n",
    "# # name_i += \"___\" + init_or_final + \"___\" + str(intact) + \".pickle\"\n",
    "# name_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing pairs to file for viewing"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/slab_struct_drift\",\n",
    "    \"out_data/most_dissimilar_pairs\")\n",
    "\n",
    "shutil.rmtree(dir_path)\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_struct_drift_i = df_struct_drift.iloc[0:15]\n",
    "\n",
    "# df_struct_drift_i = df_struct_drift\n",
    "\n",
    "files_to_open = []\n",
    "for i_cnt, (name_i, row_i) in enumerate(df_struct_drift_i.iterrows()):\n",
    "    # #####################################################\n",
    "    job_id_min_i = row_i.job_id_min\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    # #####################################################\n",
    "    atoms_init_part_i = row_i.atoms_init_part\n",
    "    atoms_final_part_i = row_i.atoms_final_part\n",
    "    # #####################################################\n",
    "\n",
    "    row_paths_min_i = df_jobs_paths.loc[job_id_min_i]\n",
    "    row_paths_max_i = df_jobs_paths.loc[job_id_max_i]\n",
    "\n",
    "    gdrive_path_min_i = row_paths_min_i.gdrive_path\n",
    "    gdrive_path_max_i = row_paths_max_i.gdrive_path\n",
    "\n",
    "    init_path = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer_gdrive\"],\n",
    "        gdrive_path_min_i,\n",
    "        \"init.traj\")\n",
    "\n",
    "    final_path = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer_gdrive\"],\n",
    "        gdrive_path_max_i,\n",
    "        \"out.cif\")\n",
    "\n",
    "    name_tup = name_i\n",
    "    name_list = []\n",
    "    for i in name_tup:\n",
    "        if type(i) == int or type(i) == float:\n",
    "            name_list.append(str(int(i)))\n",
    "        elif type(i) == str:\n",
    "            name_list.append(i)\n",
    "        else:\n",
    "            name_list.append(str(i))\n",
    "\n",
    "    dir_name = \"__\".join(name_list)\n",
    "    dir_name = str(i_cnt).zfill(3) + \"__\" + dir_name\n",
    "\n",
    "    dir_path = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"dft_workflow/job_analysis/slab_struct_drift\",\n",
    "        \"out_data/most_dissimilar_pairs\",\n",
    "        dir_name)\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    # final_cif_path = os.path.join(final_path, \"final.cif\")\n",
    "    my_file = Path(final_path)\n",
    "    if my_file.is_file():\n",
    "\n",
    "        my_file = Path(dir_path)\n",
    "        if not my_file.is_dir():\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "        shutil.copyfile(\n",
    "            final_path,\n",
    "            os.path.join(dir_path, str(i_cnt).zfill(3) + \"_final.cif\"))\n",
    "\n",
    "        atoms_init = io.read(init_path)\n",
    "        atoms_init.write(\n",
    "            os.path.join(dir_path, str(i_cnt).zfill(3) + \"_init.cif\")\n",
    "            )\n",
    "\n",
    "        atoms_init_part_i.write(\n",
    "            os.path.join(dir_path, str(i_cnt).zfill(3) + \"_part_init.cif\")\n",
    "            )\n",
    "        atoms_final_part_i.write(\n",
    "            os.path.join(dir_path, str(i_cnt).zfill(3) + \"_part_final.cif\")\n",
    "            )\n",
    "\n",
    "\n",
    "        files_to_open.append(\n",
    "            os.path.join(dir_path, str(i_cnt).zfill(3) + \"_part_init.cif\"),\n",
    "            )\n",
    "        files_to_open.append(\n",
    "            os.path.join(dir_path, str(i_cnt).zfill(3) + \"_part_final.cif\"),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VESTA \\\\\")\n",
    "for i in files_to_open:\n",
    "    tmp = 42\n",
    "    print(\n",
    "        i,\n",
    "        \"\\\\\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "import os; import pickle\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/slab_struct_drift\",\n",
    "    \"out_data\")\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_struct_drift.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_struct_drift, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_struct_drift\n",
    "df_tmp = get_df_struct_drift()\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"slab_struct_drift.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# # #####################################################\n",
    "# row_atoms_sorted_i = df_atoms_sorted_ind[\n",
    "#     df_atoms_sorted_ind.job_id == job_id_max]\n",
    "# # row_atoms_sorted_i = row_atoms_sorted_i.iloc[0]\n",
    "# # # #####################################################\n",
    "# # atoms_final_sorted = row_atoms_sorted_i.atoms_sorted_good\n",
    "# # failed_to_sort_i = row_atoms_sorted_i.failed_to_sort\n",
    "# # # #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# job_id_max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
