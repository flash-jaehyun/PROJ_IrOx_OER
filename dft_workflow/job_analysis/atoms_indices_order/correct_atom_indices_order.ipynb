{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct the atom indices of post-DFT atoms with `ase-sort.dat`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/job_analysis/atoms_indices_order\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from ase import io\n",
    "\n",
    "# #########################################################\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from vasp.vasp_methods import read_ase_sort_dat\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_paths,\n",
    "    are_dicts_the_same,\n",
    "    get_df_jobs_anal,\n",
    "    get_df_jobs_data,\n",
    "    get_df_slab,\n",
    "    get_df_init_slabs,\n",
    "    )\n",
    "\n",
    "# #########################################################\n",
    "from local_methods import (\n",
    "    get_unique_job_ids_ase_sort,\n",
    "    all_keys_equal_to_vals,\n",
    "    get_df_atoms_ind,\n",
    "    unique_ids_with_no_equal,\n",
    "    atoms_distance_comparison,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "df_jobs = get_df_jobs()\n",
    "\n",
    "# #########################################################\n",
    "df_slab = get_df_slab()\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_paths = get_df_jobs_paths()\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_data = get_df_jobs_data()\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_jobs_anal_completed = df_jobs_anal[df_jobs_anal.job_completely_done == True]\n",
    "\n",
    "# #########################################################\n",
    "df_init_slabs = get_df_init_slabs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_list = []\n",
    "grouped = df_jobs_anal_completed.groupby([\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", ])\n",
    "for name, df_jobs_anal_i in grouped:\n",
    "    data_dict_i = dict()\n",
    "    # display(df_jobs_anal_i)\n",
    "\n",
    "    # #########################################################\n",
    "    compenv_i = name[0]\n",
    "    slab_id_i = name[1]\n",
    "    ads_i = name[2]\n",
    "    active_site_i = name[3]\n",
    "    att_num_i = name[4]\n",
    "    # #########################################################\n",
    "\n",
    "\n",
    "    # #########################################################\n",
    "    df_jobs_groups = df_jobs.groupby([\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\", ])\n",
    "    df_jobs_i = df_jobs_groups.get_group(name)\n",
    "    # #########################################################\n",
    "\n",
    "\n",
    "\n",
    "    df_atoms_ind_i = get_df_atoms_ind(\n",
    "        df_jobs_i=df_jobs_i,\n",
    "        df_jobs_paths=df_jobs_paths,\n",
    "        )\n",
    "\n",
    "    # #########################################################\n",
    "    job_ids = df_atoms_ind_i.job_id.tolist()\n",
    "    unique_job_ids = get_unique_job_ids_ase_sort(job_ids, df_atoms_ind_i)\n",
    "\n",
    "    # #########################################################\n",
    "    unique_ids_with_no_equal_i = unique_ids_with_no_equal(\n",
    "        unique_job_ids=unique_job_ids,\n",
    "        df_atoms_ind_i=df_atoms_ind_i,\n",
    "        )\n",
    "    if len(unique_ids_with_no_equal_i) > 1:\n",
    "        print(\"Big problem, I think there should only be one unique atoms mapping for any job\")\n",
    "\n",
    "    unique_id = unique_ids_with_no_equal_i[0]\n",
    "\n",
    "    # #########################################################\n",
    "    row_i = df_atoms_ind_i.loc[unique_id]\n",
    "    # #########################################################\n",
    "    atom_index_mapping_i = row_i.atom_index_mapping\n",
    "    sort_list_i = row_i.sort_list\n",
    "    resort_list_i = row_i.resort_list\n",
    "    # #########################################################\n",
    "\n",
    "\n",
    "    # #########################################################\n",
    "    data_dict_i[\"compenv\"] = compenv_i\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "    data_dict_i[\"ads\"] = ads_i\n",
    "    data_dict_i[\"active_site\"] = active_site_i\n",
    "    data_dict_i[\"att_num\"] = att_num_i\n",
    "    data_dict_i[\"atom_index_mapping\"] = atom_index_mapping_i\n",
    "    data_dict_i[\"sort_list\"] = sort_list_i\n",
    "    data_dict_i[\"resort_list\"] = resort_list_i\n",
    "    # #########################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "\n",
    "# #############################################################\n",
    "df_atoms_index = pd.DataFrame(data_dict_list)\n",
    "\n",
    "index_cols = [\n",
    "    \"compenv\", \"slab_id\",\n",
    "    \"ads\", \"active_site\", \"att_num\"]\n",
    "\n",
    "df_atoms_index = df_atoms_index.set_index(index_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs_i\n",
    "# name\n",
    "\n",
    "# df_jobs_anal_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_i = df_jobs_paths.loc[\"hutoruwa_20\"]\n",
    "\n",
    "# row_i.gdrive_path"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating atoms objects with correct index order and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_0 = []\n",
    "list_1 = []\n",
    "\n",
    "data_dict_list = []\n",
    "for name_i, row_i in df_jobs_anal_completed.iterrows():\n",
    "    if verbose:\n",
    "        print(40 * \"=\")\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    # #########################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    ads_i = name_i[2]\n",
    "    active_site_i = name_i[3]\n",
    "    att_num_i = name_i[4]\n",
    "    # #########################################################\n",
    "\n",
    "    # #########################################################\n",
    "    job_id_max_i = row_i.job_id_max\n",
    "    # #########################################################\n",
    "\n",
    "    # #########################################################\n",
    "    df_jobs_data_i = df_jobs_data[df_jobs_data.compenv == compenv_i]\n",
    "    row_data_i = df_jobs_data_i[df_jobs_data_i.job_id == job_id_max_i].iloc[0]\n",
    "    # #########################################################\n",
    "    final_atoms_i = row_data_i.final_atoms\n",
    "    # #########################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_atoms_index_i = df_atoms_index.loc[name_i]\n",
    "    # #####################################################\n",
    "    atom_index_mapping_i = row_atoms_index_i.atom_index_mapping\n",
    "    sort_list_i = row_atoms_index_i.sort_list\n",
    "    resort_list_i = row_atoms_index_i.resort_list\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_init_slabs_i = df_init_slabs.loc[\n",
    "        (compenv_i, slab_id_i, ads_i, active_site_i, att_num_i)]\n",
    "    # #####################################################\n",
    "    init_atoms_i = row_init_slabs_i.init_atoms\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(\"final_atoms_i.get_global_number_of_atoms():\", final_atoms_i.get_global_number_of_atoms())\n",
    "    atoms_distance_0 = atoms_distance_comparison(init_atoms_i, final_atoms_i)\n",
    "\n",
    "\n",
    "    was_sorted = False\n",
    "    atoms_sorted_good = None\n",
    "    if atoms_distance_0 > 2:\n",
    "        # print(\"len(resort_list_i):\", len(resort_list_i))\n",
    "\n",
    "        atoms_sorted = final_atoms_i[resort_list_i]\n",
    "\n",
    "        # atoms_tmp.write(\"__temp__/\" + slab_id_i + \"_\" + \"slab_final_corr.traj\")\n",
    "\n",
    "        magmoms_sorted = final_atoms_i.get_magnetic_moments()\n",
    "        magmoms_sorted = magmoms_sorted[resort_list_i]\n",
    "\n",
    "        # atoms_distance_1 = atoms_distance_comparison(slab_final_i, atoms_sorted)\n",
    "        atoms_distance_1 = atoms_distance_comparison(init_atoms_i, atoms_sorted)\n",
    "        # print(\"atoms_distance_1:\", atoms_distance_1)\n",
    "        if atoms_distance_1 < 1.5:\n",
    "            atoms_sorted_good = atoms_sorted\n",
    "            magmoms_sorted_good = magmoms_sorted\n",
    "\n",
    "            atoms_sorted_good.set_initial_magnetic_moments(magmoms_sorted_good)\n",
    "            was_sorted = True\n",
    "\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"The sorted atoms and the initial slab aren't too similar\")\n",
    "                print(\"Look into this manually\")\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        atoms_sorted_good = final_atoms_i\n",
    "        atoms_distance_1 = None\n",
    "        magmoms_sorted_good = None\n",
    "\n",
    "        if verbose:\n",
    "            print(atoms_distance_0)\n",
    "            print(\"Look into this manually if the atoms_distance is less than 2\")\n",
    "            print(\"I currently think that every single atoms object's indices are shuffled after DFT\")\n",
    "\n",
    "\n",
    "    list_0.append(atoms_distance_0)\n",
    "    list_1.append(atoms_distance_1)\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"compenv\"] = compenv_i\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "    data_dict_i[\"ads\"] = ads_i\n",
    "    data_dict_i[\"active_site\"] = active_site_i\n",
    "    data_dict_i[\"att_num\"] = att_num_i\n",
    "\n",
    "    data_dict_i[\"job_id\"] = job_id_max_i\n",
    "    data_dict_i[\"was_sorted\"] = was_sorted\n",
    "    data_dict_i[\"atoms_sorted_good\"] = atoms_sorted_good\n",
    "    data_dict_i[\"atoms_distance_before_sorting\"] = atoms_distance_0\n",
    "    data_dict_i[\"atoms_distance_after_sorting\"] = atoms_distance_1\n",
    "    data_dict_i[\"magmoms_sorted_good\"] = magmoms_sorted_good\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_atoms_sorted = pd.DataFrame(data_dict_list)\n",
    "\n",
    "index_cols = [\n",
    "    \"compenv\", \"slab_id\",\n",
    "    \"ads\", \"active_site\", \"att_num\"]\n",
    "df_atoms_sorted = df_atoms_sorted.set_index(index_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # row_init_slabs_i = \n",
    "# df_init_slabs.loc[\n",
    "#     (compenv_i, slab_id_i, ads_i, active_site_i, att_num_i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb_i = pd.concat(\n",
    "    [\n",
    "        df_atoms_index,\n",
    "        df_atoms_sorted,\n",
    "        ],\n",
    "    axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling `df_atoms_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "\n",
    "# /home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/\n",
    "directory = \"out_data\"\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/atoms_indices_order\",\n",
    "    \"out_data\")\n",
    "\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(os.path.join(directory, \"df_atoms_sorted_ind.pickle\"), \"wb\") as fle:\n",
    "    pickle.dump(df_comb_i, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read `df_atoms_index` with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import get_df_atoms_sorted_ind\n",
    "# df_atoms_sorted_ind =\n",
    "tmp = get_df_atoms_sorted_ind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "All done!\n",
      "analyse_jobs.ipynb\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"analyse_jobs.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# row_init_slabs_i = df_init_slabs.loc[\n",
    "#     (compenv_i, slab_id_i, ads_i, active_site_i, att_num_i)]\n",
    "\n",
    "# df_init_slabs.index.to_frame().ads.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# assert False"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
