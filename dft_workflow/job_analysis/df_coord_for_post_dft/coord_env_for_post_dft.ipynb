{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze neighbor environments for post-DFT optimized slabs\n",
    "---"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "# #########################################################\n",
    "from methods import get_structure_coord_df, get_df_coord\n",
    "\n",
    "from methods import (\n",
    "    get_df_jobs_anal,\n",
    "    get_df_atoms_sorted_ind,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dft = get_df_dft()\n",
    "# df_slab = get_df_slab()\n",
    "# structure_coord_df = get_structure_coord_df()\n",
    "# df_jobs = get_df_jobs()\n",
    "# df_jobs_paths = get_df_jobs_paths()\n",
    "# df_jobs_data = get_df_jobs_data()\n",
    "# df_jobs_data_clusters = get_df_jobs_data_clusters()\n",
    "df_jobs_anal = get_df_jobs_anal()\n",
    "df_atoms_sorted_ind = get_df_atoms_sorted_ind()\n",
    "# df_slab_ids = get_df_slab_ids()\n",
    "# df_job_ids = get_df_job_ids()\n",
    "# df_slabs_to_run = get_df_slabs_to_run()\n",
    "# df_coord = get_df_coord()\n",
    "# df_active_sites = get_df_active_sites()\n",
    "# slab_id = get_slab_id()\n",
    "# job_id = get_job_id()\n",
    "# slab_thickness = get_slab_thickness()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "# df_jobs_anal_i = df_jobs_anal_i.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = \"out_data/df_coord_files\"\n",
    "\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_analysis/df_coord_for_post_dft\",\n",
    "    \"out_data/df_coord_files\")\n",
    "\n",
    "# /home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/\n",
    "# dft_workflow/job_analysis/df_coord_for_post_dft\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs_anal_i = df_jobs_anal[df_jobs_anal.job_completely_done == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_i, row_i in df_jobs_anal_i.iterrows():\n",
    "    if verbose:\n",
    "        print(40 * \"=\")\n",
    "\n",
    "    # #####################################################\n",
    "    compenv_i = name_i[0]\n",
    "    slab_id_i = name_i[1]\n",
    "    ads_i = name_i[2]\n",
    "    active_site_i = name_i[3]\n",
    "    att_num_i = name_i[4]\n",
    "    # #####################################################\n",
    "    name_dict_i = dict(zip(list(df_jobs_anal_i.index.names), name_i))\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    row_atoms_sorted_i = df_atoms_sorted_ind.loc[name_i]\n",
    "    # #####################################################\n",
    "    atoms_sorted_good_i = row_atoms_sorted_i.atoms_sorted_good\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "    df_coord_i = get_df_coord(\n",
    "        mode=\"post-dft\",  # 'bulk', 'slab', 'post-dft'\n",
    "        post_dft_name_tuple=name_i,\n",
    "        )\n",
    "    if df_coord_i is None:\n",
    "        # #################################################\n",
    "        # Get df_coord for post-dft, sorted slab\n",
    "        df_coord_i = get_structure_coord_df(atoms_sorted_good_i)\n",
    "\n",
    "        # Pickling data ###################################\n",
    "        file_name_i = \"_\".join([str(i) for i in list(name_i)]) + \".pickle\"\n",
    "        file_path_i = os.path.join(directory, file_name_i)\n",
    "        print(file_path_i)\n",
    "        with open(file_path_i, \"wb\") as fle:\n",
    "            pickle.dump(df_coord_i, fle)\n",
    "        # #################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_atoms_sorted_i = \n",
    "df_atoms_sorted_ind\n",
    "# .loc[name_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_i, row_i in df_jobs_anal_i.iterrows():\n",
    "\n",
    "    tmp = get_df_coord(\n",
    "        slab_id=None,\n",
    "        bulk_id=None,\n",
    "        mode=\"post-dft\",  # 'bulk', 'slab', 'post-dft'\n",
    "        slab=None,\n",
    "        post_dft_name_tuple=name_i,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"analyse_jobs.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# data_dict_i.extend(name_dict_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# data_dict_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_jobs_anal_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# df_coord_i"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
