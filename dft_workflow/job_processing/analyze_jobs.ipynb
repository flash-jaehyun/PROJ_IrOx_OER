{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing job sets (everything within a `02_attempt` dir for example)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/job_processing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import time; ti = time.time()\n",
    "\n",
    "import pickle\n",
    "import dictdiffer\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "from ase import io\n",
    "\n",
    "# #########################################################\n",
    "from IPython.display import display\n",
    "\n",
    "# #########################################################\n",
    "from methods import (\n",
    "    get_df_jobs_data,\n",
    "    get_df_jobs,\n",
    "    get_df_jobs_paths,\n",
    "    cwd,\n",
    "    )\n",
    "\n",
    "from dft_workflow_methods import (\n",
    "    is_job_understandable,\n",
    "    job_decision,\n",
    "    transfer_job_files_from_old_to_new,\n",
    "    is_job_compl_done,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import isnotebook    \n",
    "isnotebook_i = isnotebook()\n",
    "if isnotebook_i:\n",
    "    from tqdm.notebook import tqdm\n",
    "    verbose = True\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_no_file_ops = True  # True if just testing around, False for production mode\n",
    "# TEST_no_file_ops = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_jobs.shape: \t\t (2630, 12)\n",
      "df_jobs_data.shape: \t (2630, 39)\n"
     ]
    }
   ],
   "source": [
    "df_jobs = get_df_jobs()\n",
    "if verbose:\n",
    "    print(\"df_jobs.shape:\", 2 * \"\\t\", df_jobs.shape)\n",
    "\n",
    "df_jobs_data = get_df_jobs_data(drop_cols=False)\n",
    "if verbose:\n",
    "    print(\"df_jobs_data.shape:\", 1 * \"\\t\", df_jobs_data.shape)\n",
    "    \n",
    "df_jobs_paths = get_df_jobs_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique jobs : (1737, 12)\n",
      "^^ Only counting hightest rev_num\n"
     ]
    }
   ],
   "source": [
    "group_cols = [\"compenv\", \"slab_id\", \"att_num\", \"ads\", \"active_site\"]\n",
    "# group_cols = [\"compenv\", \"slab_id\", \"att_num\", ]\n",
    "grouped = df_jobs.groupby(group_cols)\n",
    "max_job_row_list = []\n",
    "data_dict_list = []\n",
    "for name, group in grouped:\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    max_job = group[group.rev_num == group.rev_num.max()]\n",
    "    max_job_row_list.append(max_job.iloc[0])\n",
    "\n",
    "    compenv_i = name[0]\n",
    "    slab_id_i = name[1]\n",
    "    att_num_i = name[2]\n",
    "\n",
    "    data_dict_i[\"compenv\"] = compenv_i\n",
    "    data_dict_i[\"slab_id\"] = slab_id_i\n",
    "    data_dict_i[\"att_num\"] = att_num_i\n",
    "    data_dict_i[\"group_key\"] = name\n",
    "\n",
    "    data_dict_list.append(data_dict_i)\n",
    "\n",
    "df_max_group_keys = pd.DataFrame(data_dict_list)\n",
    "df_jobs_max = pd.DataFrame(max_job_row_list)\n",
    "\n",
    "if verbose:\n",
    "    print(\"Number of unique jobs :\", df_jobs_max.shape)\n",
    "    print(\"^^ Only counting hightest rev_num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering `df_jobs` by rows that are present in `df_jobs_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These job_ids weren't in df_jobs_data:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "df_jobs_i = df_jobs.loc[\n",
    "    df_jobs.index.intersection(df_jobs_data.index)\n",
    "    ]\n",
    "\n",
    "if verbose:\n",
    "    print(\n",
    "        \"These job_ids weren't in df_jobs_data:\",\n",
    "        \"\\n\",\n",
    "        df_jobs.index.difference(df_jobs_data.index).tolist(), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | TEMP | \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bulk_id</th>\n",
       "      <th>slab_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>facet</th>\n",
       "      <th>compenv</th>\n",
       "      <th>ads</th>\n",
       "      <th>active_site</th>\n",
       "      <th>att_num</th>\n",
       "      <th>rev_num</th>\n",
       "      <th>compenv_origin</th>\n",
       "      <th>submitted</th>\n",
       "      <th>num_revs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toberotu_75</th>\n",
       "      <td>v1xpx482ba</td>\n",
       "      <td>miforike_08</td>\n",
       "      <td>toberotu_75</td>\n",
       "      <td>010</td>\n",
       "      <td>sherlock</td>\n",
       "      <td>o</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>wsl</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bulk_id      slab_id       job_id facet   compenv ads  \\\n",
       "job_id                                                                  \n",
       "toberotu_75  v1xpx482ba  miforike_08  toberotu_75   010  sherlock   o   \n",
       "\n",
       "            active_site  att_num  rev_num compenv_origin submitted  num_revs  \n",
       "job_id                                                                        \n",
       "toberotu_75          50        1        1            wsl      True         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(40 * \"TEMP | \")\n",
    "\n",
    "# # name_i = (\"nafupemu_49\", \"o\", 48., 1)\n",
    "# # name_i = (\"relovalu_12\", \"o\", \"NaN\", 1)\n",
    "# # name_i = ('sherlock', 'miforike_08', 1, 'o', 50.0)\n",
    "# name_i = ('miforike_08', 'o', 50.0, 1, )\n",
    "\n",
    "# df = df_jobs_i\n",
    "# df = df[\n",
    "#     (df[\"slab_id\"] == name_i[0]) &\n",
    "#     (df[\"ads\"] == name_i[1]) &\n",
    "#     (df[\"active_site\"] == name_i[2]) &\n",
    "#     (df[\"att_num\"] == name_i[3]) &\n",
    "#     [True for i in range(len(df))]\n",
    "#     ]\n",
    "# df_jobs_i = df\n",
    "\n",
    "# df_jobs_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "name: ('sherlock', 'miforike_08', 1, 'o', 50.0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-35e06f95fb8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mnum_nonconv_scf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nonconv_scf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_conv_scf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_conv_scf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mtrue_false_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_false_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrac_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         job_completely_done=job_completely_done, )\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mdecision_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_decision_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decision\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mdft_params_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_decision_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dft_params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/f/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/dft_workflow_methods.py\u001b[0m in \u001b[0;36mjob_decision\u001b[0;34m(error, error_type, timed_out, completed, submitted, job_understandable, ediff_conv_reached, incar_params, brmix_issue, num_nonconv_scf, num_conv_scf, true_false_ratio, frac_true, job_state, job_completely_done)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m#| - If completed and ISPIN < 2 then resubmit with ISPIN=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mispin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincar_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ISPIN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# I added inequality because I accidentally ran a ISPIN=0 job, which defaults to ISPIN=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mispin\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "data_dict_list = []\n",
    "group_cols = [\"compenv\", \"slab_id\", \"att_num\", \"ads\", \"active_site\"]\n",
    "grouped = df_jobs_i.groupby(group_cols)\n",
    "for name, group in grouped:\n",
    "\n",
    "    data_dict_i = dict()\n",
    "\n",
    "    if verbose:\n",
    "        print(40 * \"#\")\n",
    "        print(\"name:\", name)\n",
    "\n",
    "    # #####################################################\n",
    "    compenv_i = name[0]\n",
    "    slab_id = name[1]\n",
    "    att_num = name[2] \n",
    "    ads_i = name[3]\n",
    "    active_site_i = name[4]\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    max_job = group[group.rev_num == group.rev_num.max()]\n",
    "    assert max_job.shape[0] == 1, \"Must only have 1 there\"\n",
    "    row_max_i = max_job.iloc[0]\n",
    "    # #####################################################\n",
    "    job_id_max_i = row_max_i.job_id\n",
    "    submitted_i = row_max_i.submitted\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    df_jobs_paths_i = df_jobs_paths[df_jobs_paths.compenv == compenv_i]\n",
    "    row_paths_max_i = df_jobs_paths_i.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    path_job_root_w_att_rev = row_paths_max_i.path_job_root_w_att_rev\n",
    "    path_rel_to_proj = row_paths_max_i.path_rel_to_proj\n",
    "    # #####################################################\n",
    "\n",
    "    # #####################################################\n",
    "    df_jobs_data_i = df_jobs_data[df_jobs_data.compenv == compenv_i]\n",
    "    row_data_max_i = df_jobs_data_i.loc[job_id_max_i]\n",
    "    # #####################################################\n",
    "    timed_out = row_data_max_i.timed_out\n",
    "    completed = row_data_max_i.completed\n",
    "    ediff_conv_reached = row_data_max_i.ediff_conv_reached\n",
    "    brmix_issue = row_data_max_i.brmix_issue\n",
    "    num_nonconv_scf = row_data_max_i.num_nonconv_scf\n",
    "    num_conv_scf = row_data_max_i.num_conv_scf\n",
    "    true_false_ratio = row_data_max_i.true_false_ratio\n",
    "    frac_true = row_data_max_i.frac_true\n",
    "    error = row_data_max_i.error\n",
    "    error_type = row_data_max_i.error_type\n",
    "    job_state = row_data_max_i.job_state\n",
    "    incar_params = row_data_max_i.incar_params\n",
    "    # #####################################################\n",
    "    if incar_params is not None:\n",
    "        ispin = incar_params.get(\"ISPIN\", None)\n",
    "    else:\n",
    "        ispin = None\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "    job_completely_done = is_job_compl_done(\n",
    "        ispin=ispin, completed=completed)\n",
    "\n",
    "    # #####################################################\n",
    "    job_understandable = is_job_understandable(\n",
    "        timed_out=timed_out, completed=completed, error=error,\n",
    "        job_state=job_state, )\n",
    "    # #####################################################\n",
    "    job_decision_i = job_decision(\n",
    "        error=error, error_type=error_type,\n",
    "        timed_out=timed_out, completed=completed, submitted=submitted_i,\n",
    "        job_understandable=job_understandable, ediff_conv_reached=ediff_conv_reached,\n",
    "        incar_params=incar_params, brmix_issue=brmix_issue,\n",
    "        num_nonconv_scf=num_nonconv_scf, num_conv_scf=num_conv_scf,\n",
    "        true_false_ratio=true_false_ratio, frac_true=frac_true, job_state=job_state,\n",
    "        job_completely_done=job_completely_done, )\n",
    "    decision_i = job_decision_i[\"decision\"]\n",
    "    dft_params_i = job_decision_i[\"dft_params\"]\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "\n",
    "    # #####################################################\n",
    "    data_dict_i[\"ads\"] = ads_i\n",
    "    data_dict_i[\"active_site\"] = active_site_i\n",
    "    data_dict_i[\"job_understandable\"] = job_understandable\n",
    "    data_dict_i[\"compenv\"] = compenv_i\n",
    "    data_dict_i[\"slab_id\"] = slab_id\n",
    "    data_dict_i[\"att_num\"] = att_num\n",
    "    data_dict_i[\"job_id_max\"] = job_id_max_i\n",
    "    data_dict_i[\"path_rel_to_proj\"] = path_rel_to_proj\n",
    "    data_dict_i[\"timed_out\"] = timed_out\n",
    "    data_dict_i[\"completed\"] = completed\n",
    "    data_dict_i[\"brmix_issue\"] = brmix_issue\n",
    "    data_dict_i[\"decision\"] = decision_i\n",
    "    data_dict_i[\"dft_params_new\"] = dft_params_i\n",
    "    data_dict_i[\"job_completely_done\"] = job_completely_done\n",
    "    # #####################################################\n",
    "    data_dict_list.append(data_dict_i)\n",
    "    # #####################################################\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "df_jobs_anal = pd.DataFrame(data_dict_list)\n",
    "df_jobs_anal = df_jobs_anal.sort_values([\"compenv\", \"slab_id\", \"path_rel_to_proj\"])\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bulk_id                                    v1xpx482ba\n",
       "slab_id                                   miforike_08\n",
       "job_id                                    toberotu_75\n",
       "facet                                             010\n",
       "ads                                                 o\n",
       "compenv                                      sherlock\n",
       "active_site                                        50\n",
       "att_num                                             1\n",
       "rev_num                                             1\n",
       "timed_out                                        None\n",
       "error                                            None\n",
       "error_type                                       None\n",
       "brmix_issue                                      None\n",
       "completed                                        True\n",
       "submitted                                        True\n",
       "isif                                                2\n",
       "num_steps                                          29\n",
       "ediff_conv_reached                               None\n",
       "ediff_conv_reached_dict                          None\n",
       "num_scf_cycles                                    NaN\n",
       "N_tot                                             NaN\n",
       "true_false_ratio                                  NaN\n",
       "num_nonconv_scf                                   NaN\n",
       "num_conv_scf                                      NaN\n",
       "run_start_time                                   None\n",
       "time_str                                         None\n",
       "run_time                                          NaN\n",
       "incar_params                                     None\n",
       "irr_kpts                                          NaN\n",
       "init_atoms                                       None\n",
       "final_atoms                                      None\n",
       "magmoms                                          None\n",
       "frac_true                                         NaN\n",
       "frac_false                                        NaN\n",
       "unique_key                 (sherlock, toberotu_75, 1)\n",
       "pot_e                                             NaN\n",
       "job_started                                      True\n",
       "rerun_from_oh                                     NaN\n",
       "job_state                                         NaN\n",
       "Name: toberotu_75, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_data_max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordering `df_jobs_anal` and setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_modules.pandas_methods import reorder_df_columns\n",
    "\n",
    "col_order_list = [\n",
    "    \"compenv\",\n",
    "    \"slab_id\",\n",
    "    \"att_num\",\n",
    "    \"ads\",\n",
    "    \"active_site\",\n",
    "    \"job_id_max\",\n",
    "\n",
    "    \"path_short\",\n",
    "\n",
    "    \"timed_out\",\n",
    "    \"completed\",\n",
    "    \"brmix_issue\",\n",
    "    \"job_understandable\",\n",
    "\n",
    "    \"decision\",\n",
    "    \"dft_params_new\",\n",
    "\n",
    "    \"path_rel_to_proj\",\n",
    "    ]\n",
    "df_jobs_anal = reorder_df_columns(col_order_list, df_jobs_anal)\n",
    "df_jobs_anal = df_jobs_anal.drop(columns=[\"path_rel_to_proj\", ])\n",
    "\n",
    "# #########################################################\n",
    "# Setting index\n",
    "index_keys = [\"compenv\", \"slab_id\", \"ads\", \"active_site\", \"att_num\"]\n",
    "df_jobs_anal = df_jobs_anal.set_index(index_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs_anal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling data ###########################################\n",
    "directory = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/job_processing/out_data\")\n",
    "file_name_i = \"df_jobs_anal.pickle\"\n",
    "path_i = os.path.join(directory, file_name_i)\n",
    "if not os.path.exists(directory): os.makedirs(directory)\n",
    "with open(path_i, \"wb\") as fle:\n",
    "    pickle.dump(df_jobs_anal, fle)\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################\n",
    "print(20 * \"# # \")\n",
    "print(\"All done!\")\n",
    "print(\"Run time:\", np.round((time.time() - ti) / 60, 3), \"min\")\n",
    "print(\"analyse_jobs.ipynb\")\n",
    "print(20 * \"# # \")\n",
    "# #########################################################"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
