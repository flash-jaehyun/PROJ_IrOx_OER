{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ase import io\n",
    "\n",
    "# #########################################################\n",
    "from dft_workflow_methods import get_path_rel_to_proj\n",
    "from dft_workflow_methods import get_job_paths_info\n",
    "from dft_workflow_methods import get_job_spec_dft_params, get_job_spec_scheduler_params\n",
    "from dft_workflow_methods import submit_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "\n",
    "compenv = os.environ[\"COMPENV\"]\n",
    "\n",
    "if compenv == \"wsl\":\n",
    "    root_dir = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer_gdrive\"],\n",
    "        \"dft_workflow\")    \n",
    "        # \"dft_workflow/run_slabs/run_o_covered\")    \n",
    "        # \"dft_workflow/run_slabs/run_o_covered/out_data.old/dft_jobs/slac\")    \n",
    "\n",
    "\n",
    "# slac_sub_queue = \"suncat\"  # 'suncat', 'suncat2', 'suncat3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"sys.argv:\", \"\\n\", sys.argv)\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"sys.argv:\")\n",
    "# tmp = [print(i) for i in sys.argv]\n",
    "# print(\"\")\n",
    "# print(\"What is this one?\", sys.argv[-1])\n",
    "# print(\"\")\n",
    "\n",
    "\n",
    "# if sys.argv[-1] == \"run\":\n",
    "#     run_jobs = True\n",
    "#     print(\"running job isdjifjsiduf89usd089ufg089sady890gyasd9p8yf978asdy89fyasd89yf890asd7890f7890asd7f89sd\")\n",
    "# else:\n",
    "#     run_jobs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dft_workflow_methods import parse_job_dirs\n",
    "\n",
    "df = parse_job_dirs(root_dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def method(row_i, argument_0, optional_arg=None):\n",
    "def method(row_i):\n",
    "    new_column_values_dict = {\n",
    "        \"compenv\": None,\n",
    "        }\n",
    "\n",
    "    cand_clusters = []\n",
    "    clusters_list = [\"nersc\", \"sherlock\", \"slac\", ]\n",
    "    for i in row_i.path_job_root.split(\"/\"):\n",
    "        if i in clusters_list:\n",
    "            cand_clusters.append(i)\n",
    "\n",
    "    if len(cand_clusters) == 1:\n",
    "        cluster_i = cand_clusters[0]\n",
    "        new_column_values_dict[\"compenv\"] = cluster_i\n",
    "    else:\n",
    "        print(\"Couldn't parse cluster from path\")\n",
    "        print(cand_clusters)\n",
    "\n",
    "    # #####################################################\n",
    "    for key, value in new_column_values_dict.items():\n",
    "        row_i[key] = value\n",
    "    return(row_i)\n",
    "\n",
    "df_i = df\n",
    "df_i = df_i.apply(\n",
    "    method,\n",
    "    axis=1)\n",
    "df = df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc_modules.pandas_methods import reorder_df_columns\n",
    "\n",
    "col_order = [\n",
    "    \"compenv\",\n",
    "    \"is_submitted\",\n",
    "    \"att_num\",\n",
    "    \"rev_num\",\n",
    "    \"is_rev_dir\",\n",
    "    \"is_attempt_dir\",\n",
    "\n",
    "    \"path_full\",\n",
    "    \"path_rel_to_proj\",\n",
    "    \"path_job_root\",\n",
    "    \"path_job_root_w_att_rev\",\n",
    "    \"path_job_root_w_att\",\n",
    "    \"gdrive_path\",\n",
    "    ]\n",
    "df = reorder_df_columns(col_order, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "nersc\n",
      "========================================\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/nersc/b5cgvsb16w/111/oh/active_site__71/01_attempt/_02 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/b5cgvsb16w/111/oh/active_site__71/01_attempt/_02\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/nersc/b5cgvsb16w/111/oh/active_site__71/02_attempt/_02 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/b5cgvsb16w/111/oh/active_site__71/02_attempt/_02\n",
      "\n",
      "========================================\n",
      "sherlock\n",
      "========================================\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/sherlock/cy94mecq6g/010/bare/active_site__16/02_attempt/_02 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/cy94mecq6g/010/bare/active_site__16/02_attempt/_02\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/sherlock/cy94mecq6g/010/02_attempt/_02 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/cy94mecq6g/010/02_attempt/_02\n",
      "\n",
      "========================================\n",
      "slac\n",
      "========================================\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/slac/81meck64ba/110/bare/active_site__63/02_attempt/_01 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/81meck64ba/110/bare/active_site__63/02_attempt/_01\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/slac/vhnkve7ev1/001/bare/active_site__33/02_attempt/_02 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/vhnkve7ev1/001/bare/active_site__33/02_attempt/_02\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/slac/z36lb3bdcq/001/bare/active_site__50/02_attempt/_02 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_bare_oh_covered/out_data/dft_jobs/z36lb3bdcq/001/bare/active_site__50/02_attempt/_02\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/slac/b5cgvsb16w/111/oh/active_site__71/00_attempt/_09 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/b5cgvsb16w/111/oh/active_site__71/00_attempt/_09\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/slac/b5cgvsb16w/111/oh/active_site__73/03_attempt/_09 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/b5cgvsb16w/111/oh/active_site__73/03_attempt/_09\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/slac/81meck64ba/110/oh/active_site__62/00_attempt/_10 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/81meck64ba/110/oh/active_site__62/00_attempt/_10\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/slac/vhnkve7ev1/001/oh/active_site__32/00_attempt/_08 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_oh_covered/out_data/dft_jobs/vhnkve7ev1/001/oh/active_site__32/00_attempt/_08\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/slac/zw9pbrnabj/010/01_attempt/_10 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/zw9pbrnabj/010/01_attempt/_10\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/slac/vhnkve7ev1/001/02_attempt/_02 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/vhnkve7ev1/001/02_attempt/_02\n",
      "rclone copy  \\\n",
      "$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/slac/z36lb3bdcq/001/02_attempt/_02 \\\n",
      "$PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/z36lb3bdcq/001/02_attempt/_02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i = df[df.is_submitted == False]\n",
    "\n",
    "bash_comm_files_line_list = []\n",
    "\n",
    "grouped = df_i.groupby([\"compenv\", ])\n",
    "for i_cnt, (name, group) in enumerate(grouped):\n",
    "    print(40 * \"=\")\n",
    "    print(name)\n",
    "    print(40 * \"=\")\n",
    "\n",
    "    # if [[ \"$COMPENV\" == \"wsl\" ]]; then\n",
    "    if i_cnt == 0:\n",
    "        bash_if_statement = 'if [[ \"$COMPENV\" == \"' + name + '\" ]]; then'\n",
    "    else:\n",
    "        bash_if_statement = 'elif [[ \"$COMPENV\" == \"' + name + '\" ]]; then'\n",
    "\n",
    "    bash_comm_files_line_list.append(bash_if_statement)\n",
    "\n",
    "    for name_i, row_i in group.iterrows():\n",
    "\n",
    "        # #########################################################\n",
    "        path_job_root_w_att_rev = row_i.path_job_root_w_att_rev\n",
    "        # #########################################################\n",
    "\n",
    "        # #########################################################\n",
    "        # Constructing path on cluster (remove cluster from path)\n",
    "        clust_path_list = []\n",
    "        for i in path_job_root_w_att_rev.split(\"/\"):\n",
    "            clusters_list = [\"nersc\", \"sherlock\", \"slac\", ]\n",
    "\n",
    "            if i not in clusters_list:\n",
    "                clust_path_list.append(i)\n",
    "\n",
    "        clust_path = \"/\".join(clust_path_list)\n",
    "\n",
    "        # #########################################################\n",
    "        # Constructing Rclone command\n",
    "        rclone_comm = \"\" + \\\n",
    "            \"rclone copy \" + \\\n",
    "            \" \\\\\" + \\\n",
    "            \"\\n\" + \\\n",
    "            \"$rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/\" + \\\n",
    "            path_job_root_w_att_rev + \\\n",
    "            \" \\\\\" + \\\n",
    "            \"\\n\" + \\\n",
    "            \"$PROJ_irox_oer/\" + \\\n",
    "            clust_path + \\\n",
    "            \"\"\n",
    "\n",
    "            # \" \\\\\" + \\\n",
    "\n",
    "        # bash_comm_files_line_list.append(\"    \" + rclone_comm)\n",
    "        bash_comm_files_line_list.append(rclone_comm)\n",
    "\n",
    "        print(rclone_comm)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_comm_files_line_list.append(\"fi\")\n",
    "\n",
    "my_list = bash_comm_files_line_list\n",
    "out_path = os.path.join(\n",
    "    os.environ[\"PROJ_irox_oer\"],\n",
    "    \"dft_workflow/bin\")\n",
    "out_file = os.path.join(\n",
    "    out_path,\n",
    "    \"out_data/bash_sync_out.sh\")\n",
    "with open(out_file, \"w\") as fle:\n",
    "    for item in my_list:\n",
    "        fle.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"rclone copy $rclone_gdrive_stanford:norskov_research_storage/00_projects/PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/nersc/b19q9p6k72/101/01_attempt/_02 $PROJ_irox_oer/dft_workflow/run_slabs/run_o_covered/out_data/dft_jobs/b19q9p6k72/101/01_attempt/_02\"\n",
    "\n",
    "# # $rclone_gdrive_stanford\n",
    "# # raul_gdrive_stanford"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_i.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# row_i = df.iloc[0]\n",
    "\n",
    "# cand_clusters = []\n",
    "# clusters_list = [\"nersc\", \"sherlock\", \"slac\", ]\n",
    "# for i in row_i.path_job_root.split(\"/\"):\n",
    "#     if i in clusters_list:\n",
    "#         cand_clusters.append(i)\n",
    "\n",
    "# if len(cand_clusters) == 1:\n",
    "#     cluster_i = cand_clusters[0]\n",
    "# else:\n",
    "#     print(\"Couldn't parse cluster from path\")\n",
    "#     print(cand_clusters)\n",
    "\n",
    "# cluster_i"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
