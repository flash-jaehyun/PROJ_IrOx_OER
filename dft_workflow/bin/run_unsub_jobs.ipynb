{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raulf2012/Dropbox/01_norskov/00_git_repos/PROJ_IrOx_OER/dft_workflow/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ase import io\n",
    "\n",
    "# #########################################################\n",
    "from dft_workflow_methods import get_path_rel_to_proj\n",
    "from dft_workflow_methods import get_job_paths_info\n",
    "from dft_workflow_methods import get_job_spec_dft_params, get_job_spec_scheduler_params\n",
    "from dft_workflow_methods import submit_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "\n",
    "compenv = os.environ[\"COMPENV\"]\n",
    "\n",
    "if compenv == \"wsl\":\n",
    "    root_dir = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer_gdrive\"],\n",
    "        \"dft_workflow/run_slabs/run_o_covered\")    \n",
    "\n",
    "slac_sub_queue = \"suncat2\"  # 'suncat', 'suncat2', 'suncat3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Usage:\n",
      "  PROJ_irox_oer__comm_jobs_run_unsub_jobs run frac_of_jobs_to_run=0.2\n",
      "\n",
      "Run script with 'run' flag\n",
      "run_unsub_jobs run\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Usage:\")\n",
    "print(\"  PROJ_irox_oer__comm_jobs_run_unsub_jobs run frac_of_jobs_to_run=0.2\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"sys.argv:\", sys.argv)\n",
    "print(\"\")\n",
    "\n",
    "# if sys.argv[-1] == \"run\":\n",
    "if \"run\" in sys.argv:\n",
    "    run_jobs = True\n",
    "    print(\"running unsubmitted jobs\")\n",
    "else:\n",
    "    print(\"Run script with 'run' flag\")\n",
    "    print(\"run_unsub_jobs run\")\n",
    "    run_jobs = False\n",
    "\n",
    "frac_of_jobs_to_run = 1.\n",
    "for i in sys.argv:\n",
    "    # i = \"frac_of_jobs_to_run=0.2\"\n",
    "    if \"frac_of_jobs_to_run\" in i:\n",
    "        frac_of_jobs_to_run = i.split(\"=\")[-1]\n",
    "        frac_of_jobs_to_run = float(frac_of_jobs_to_run)\n",
    "\n",
    "# frac_of_jobs_to_run = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "frac_of_jobs_to_run: 1.0\n",
      "run_jobs: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"frac_of_jobs_to_run:\", frac_of_jobs_to_run)\n",
    "print(\"run_jobs:\", run_jobs)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dft_workflow_methods import parse_job_dirs\n",
    "\n",
    "df = parse_job_dirs(root_dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Jobs to submit:\n",
      "run_o_covered/out_data/dft_jobs/slac/8fxi6rmp75/101/01_attempt/_04\n",
      "run_o_covered/out_data/dft_jobs/sherlock/9uxemw7rv2/101/01_attempt/_02\n",
      "run_o_covered/out_data/dft_jobs/sherlock/na9exovani/131/01_attempt/_03\n"
     ]
    }
   ],
   "source": [
    "df_not_sub = df[df.is_submitted == False]\n",
    "\n",
    "out_dict = get_job_spec_scheduler_params(compenv=compenv)\n",
    "wall_time_factor = out_dict[\"wall_time_factor\"]\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Jobs to submit:\")\n",
    "for path_i in df_not_sub.path_job_root_w_att_rev.tolist():\n",
    "    print(path_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs to submit: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Jobs to submit:\", df_not_sub.shape[0])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_cnt, row_i in df_not_sub.iterrows():\n",
    "    # #######################################\n",
    "    path_i = row_i.path_full\n",
    "    path_job_root_w_att_rev = row_i.path_job_root_w_att_rev\n",
    "    # #######################################\n",
    "\n",
    "    atoms_path_i = os.path.join(path_i, \"init.traj\")\n",
    "    atoms = io.read(atoms_path_i)\n",
    "    num_atoms = atoms.get_global_number_of_atoms()\n",
    "\n",
    "    # #####################################################\n",
    "    if random.random() <= frac_of_jobs_to_run:\n",
    "        run_job_i = True\n",
    "    else:\n",
    "        run_job_i = False\n",
    "\n",
    "    if run_jobs and run_job_i:\n",
    "\n",
    "        print(40 * \"*\")\n",
    "        print(\"Submitting:\", path_job_root_w_att_rev)\n",
    "        submit_job(\n",
    "            path_i=path_i,\n",
    "            num_atoms=num_atoms,\n",
    "            wall_time_factor=wall_time_factor,\n",
    "            queue=slac_sub_queue,\n",
    "            )\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print(\"IIJIDFJIJISDF(SD*(DF(S(JS(DF)(SIDFD)))))\")\n",
    "# print(\"\")\n",
    "\n",
    "# tmp = [print(i) for i in df.path_rel_to_proj.tolist()]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
