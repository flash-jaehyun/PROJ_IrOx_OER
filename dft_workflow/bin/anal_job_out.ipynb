{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "# #########################################################\n",
    "from vasp.vasp_methods import parse_incar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compenv = os.environ[\"COMPENV\"]\n",
    "\n",
    "vasp_dir = \".\"\n",
    "\n",
    "# For testing purposes\n",
    "if compenv == \"wsl\":\n",
    "    vasp_dir = os.path.join(\n",
    "        os.environ[\"PROJ_irox_oer\"],\n",
    "        \"__test__/anal_job_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vasp.parse_oszicar import parse_oszicar\n",
    "\n",
    "out_dict = parse_oszicar(vasp_dir=vasp_dir)\n",
    "\n",
    "ion_step_conv_dict = out_dict[\"ion_step_conv_dict\"]\n",
    "N_tot = out_dict[\"N_tot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_i = os.path.join(\n",
    "    vasp_dir,\n",
    "    \"INCAR\")\n",
    "my_file = Path(path_i)\n",
    "if my_file.is_file():\n",
    "    with open(path_i, \"r\") as f:\n",
    "        incar_lines = f.read().splitlines()\n",
    "    incar_dict = parse_incar(incar_lines)\n",
    "\n",
    "nelm_i = incar_dict[\"NELM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_plot_quant = \"E\"\n",
    "# y_plot_quant = \"dE\"\n",
    "y_plot_quant = \"dE_abs\"\n",
    "\n",
    "# spacing = N_tot / 15\n",
    "# spacing = N_tot / 10\n",
    "spacing = int(N_tot / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "x_axis_cum = 0\n",
    "for i_cnt, ion_step_i in enumerate(list(ion_step_conv_dict.keys())):\n",
    "\n",
    "    # if i_cnt == 2:\n",
    "    #     break\n",
    "\n",
    "    df_i = ion_step_conv_dict[ion_step_i]\n",
    "\n",
    "    \n",
    "\n",
    "    num_N_i = df_i.N.max() - df_i.N.min()\n",
    "    print(\"\")\n",
    "    print(\"num_N_i:\", num_N_i)\n",
    "\n",
    "    extra_spacing = nelm_i - num_N_i - spacing\n",
    "    print(\"extra_spacing:\", extra_spacing)\n",
    "\n",
    "\n",
    "    df_i[\"below_0\"] = df_i.dE < 0. \n",
    "    df_i[\"dE_abs\"] = np.abs(df_i[\"dE\"])\n",
    "\n",
    "    # x_array = df_i.N + x_axis_cum + 50\n",
    "    x_array = df_i.N + x_axis_cum\n",
    "\n",
    "    # y_array = df_i.E\n",
    "    y_array = df_i[y_plot_quant]\n",
    "\n",
    "    color_array = df_i[\"below_0\"]\n",
    "\n",
    "    color_array_2 = []\n",
    "    for i in color_array:\n",
    "        if i:\n",
    "            color_array_2.append(\"red\")\n",
    "        else:\n",
    "            color_array_2.append(\"black\")\n",
    "\n",
    "    num_N = df_i.N.max()\n",
    "    # x_axis_cum += num_N + 100\n",
    "    # x_axis_cum += num_N + spacing + extra_spacing\n",
    "    x_axis_cum += num_N + (nelm_i - num_N_i) + spacing\n",
    "\n",
    "    # #####################################################\n",
    "    trace_i = go.Scatter(\n",
    "        x=x_array,\n",
    "        y=y_array,\n",
    "        mode=\"markers\",\n",
    "        opacity=0.8,\n",
    "        marker_color=color_array_2,\n",
    "        )\n",
    "    data.append(trace_i)\n",
    "\n",
    "    # #####################################################\n",
    "    trace_i = go.Scatter(\n",
    "        x=2 * [x_array[0] + nelm_i],\n",
    "        y=[1e-10, 1e10],\n",
    "        mode=\"lines\",\n",
    "        line_color=\"grey\",\n",
    "        # opacity=0.8,\n",
    "        # marker_color=color_array_2,\n",
    "        )\n",
    "    data.append(trace_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "min_list = []\n",
    "for i_cnt, ion_step_i in enumerate(list(ion_step_conv_dict.keys())):\n",
    "    df_i = ion_step_conv_dict[ion_step_i]\n",
    "\n",
    "    max_dE = df_i.dE_abs.max()\n",
    "    min_dE = df_i.dE_abs.min()\n",
    "\n",
    "    # print(\"\")\n",
    "    # print(\"max_dE:\", max_dE)\n",
    "    # print(\"min_dE:\", min_dE)\n",
    "\n",
    "    max_list.append(max_dE)\n",
    "    min_list.append(min_dE)\n",
    "\n",
    "max_y = np.max(max_list)\n",
    "min_y = np.min(min_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_N_i = df_i.N.max() - df_i.N.min()\n",
    "\n",
    "print(\"num_N_i:\", num_N_i)\n",
    "\n",
    "extra_spacing = nelm_i - num_N_i - spacing\n",
    "print(\"extra_spacing:\", extra_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=data)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=os.getcwd(),\n",
    "\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=\"dE\",\n",
    "        ),\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=\"N\",\n",
    "        type=\"log\",\n",
    "        # range=[min_y, max_y],\n",
    "        range=[-7, 6],\n",
    "        ),\n",
    "\n",
    "    # xaxis_type=\"log\",\n",
    "    # yaxis_type=\"log\",\n",
    "    )\n",
    "\n",
    "\n",
    "if compenv == \"wsl\":\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting.my_plotly import my_plotly_plot\n",
    "\n",
    "if compenv != \"wsl\":\n",
    "    write_png = True\n",
    "else:\n",
    "    write_png = False\n",
    "\n",
    "my_plotly_plot(\n",
    "    figure=fig,\n",
    "    plot_name=\"scf_convergence\",\n",
    "    write_html=True,\n",
    "    write_png=write_png,\n",
    "    # png_scale=6.0,\n",
    "    # write_pdf=False,\n",
    "    # write_svg=False,\n",
    "    try_orca_write=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy figure html file to Dropbox with rclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclone_comm = \"rclone copy out_plot/scf_convergence.html \" + os.environ[\"rclone_dropbox\"] + \":__temp__/\"\n",
    "\n",
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    rclone_comm.split(\" \"),\n",
    "    stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(40 * \"*\")\n",
    "print(\"*** Script finished running \" + 12 * \"*\")\n",
    "print(40 * \"*\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {}
   },
   "outputs": [],
   "source": [
    "# root_dir = \".\"\n",
    "\n",
    "# # path_i = \"./job.out\"\n",
    "# path_i = os.path.join(root_dir, \"OSZICAR\")\n",
    "\n",
    "# compenv = os.environ[\"COMPENV\"]\n",
    "\n",
    "# if compenv == \"wsl\":\n",
    "#     root_dir = os.path.join(\n",
    "#         os.environ[\"PROJ_irox_oer\"],\n",
    "#         \"__test__/anal_job_out\")\n",
    "\n",
    "#     # path_i = \"./OSZICAR\"\n",
    "#     # path_i = \"./OSZICAR.new\"\n",
    "#     path_i = os.path.join(\n",
    "#         root_dir,\n",
    "#         # os.environ[\"PROJ_irox_oer\"],\n",
    "#         # \"__test__/anal_job_out/OSZICAR.new\",\n",
    "#         \"OSZICAR\",\n",
    "#         )\n",
    "# with open(path_i, \"r\") as f:\n",
    "#     oszicar_lines = f.read().splitlines()\n",
    "\n",
    "# from vasp.vasp_methods import parse_incar\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# path_i = os.path.join(\n",
    "#     root_dir,\n",
    "#     \"INCAR\")\n",
    "# my_file = Path(path_i)\n",
    "# if my_file.is_file():\n",
    "#     with open(path_i, \"r\") as f:\n",
    "#         incar_lines = f.read().splitlines()\n",
    "\n",
    "#     incar_dict = parse_incar(incar_lines)\n",
    "\n",
    "#     nsw_i = incar_dict[\"NSW\"]\n",
    "#     nelm_i = incar_dict[\"NELM\"]\n",
    "#     incar_parsed = True\n",
    "# else:\n",
    "#     incar_parsed = False\n",
    "\n",
    "# line_beginnings = [\"DAV:\", \"RMM:\", ]\n",
    "\n",
    "# lines_groups = []\n",
    "\n",
    "# group_lines_i = []\n",
    "# for line_i in oszicar_lines:\n",
    "\n",
    "#     if line_i[0:4] in line_beginnings:\n",
    "#         group_lines_i.append(line_i)\n",
    "\n",
    "#     if \"F= \" in line_i:\n",
    "#         # print(\"IDJIFSD\")\n",
    "#         lines_groups.append(group_lines_i)\n",
    "#         group_lines_i = []\n",
    "\n",
    "# # This should add the final group_lines in the case that it hasn't finished yet\n",
    "# if \"F= \" not in oszicar_lines[-1]:\n",
    "#     lines_groups.append(group_lines_i)\n",
    "\n",
    "# N_tot = 0.\n",
    "\n",
    "# ion_step_conv_dict = dict()\n",
    "# for ion_step_i, lines_group_i in enumerate(lines_groups):\n",
    "\n",
    "#     data_dict_list = []\n",
    "#     for line_i in lines_group_i:\n",
    "#         data_dict_i = dict()\n",
    "\n",
    "#         line_list_i = [i for i in line_i.split(\" \") if i != \"\"]\n",
    "\n",
    "#         N_i = line_list_i[1]\n",
    "#         data_dict_i[\"N\"] = int(N_i)\n",
    "\n",
    "#         E_i = line_list_i[2]\n",
    "#         data_dict_i[\"E\"] = float(E_i)\n",
    "\n",
    "#         dE_i = line_list_i[3]\n",
    "#         data_dict_i[\"dE\"] = float(dE_i)\n",
    "\n",
    "#         d_eps_i = line_list_i[4]\n",
    "#         data_dict_i[\"d_eps\"] = float(d_eps_i)\n",
    "\n",
    "#         ncg_i = line_list_i[5]\n",
    "#         data_dict_i[\"ncg\"] = int(ncg_i)\n",
    "\n",
    "#         rms_i = line_list_i[6]\n",
    "#         data_dict_i[\"rms\"] = float(rms_i)\n",
    "\n",
    "#         if len(line_list_i) > 7:\n",
    "#             rms_c_i = line_list_i[7]\n",
    "#             data_dict_i[\"rms_c\"] = float(rms_c_i)\n",
    "\n",
    "#         # #################################################\n",
    "#         data_dict_list.append(data_dict_i)\n",
    "\n",
    "#     df_i = pd.DataFrame(data_dict_list)\n",
    "#     # print(N_tot)\n",
    "#     N_tot += df_i.N.max()\n",
    "\n",
    "#     ion_step_conv_dict[ion_step_i] = df_i\n",
    "\n",
    "# print(\"N_tot\", N_tot)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PROJ_irox_oer] *",
   "language": "python",
   "name": "conda-env-PROJ_irox_oer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
